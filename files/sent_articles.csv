title,link,published,retrieved_at,relevanceSource,author,abstract,category
Tighter yet more tractable relaxations and nontrivial instance generation for sparse standard quadratic optimization,https://arxiv.org/abs/2406.01239,,06/04/2024 09:20,Manual,"Immanuel Bomze, Bo Peng, Yuzhou Qiu, E. Alper Yildirim","The Standard Quadratic optimization Problem (StQP), arguably the simplest among all classes of NP-hard optimization problems, consists of extremizing a quadratic form (the simplest nonlinear polynomial) over the standard simplex (the simplest polytope/compact feasible set). As a problem class, StQPs may be nonconvex with an exponential number of inefficient local solutions. StQPs arise in a multitude of applications, among them mathematical finance, machine learning (clustering), and modeling in biosciences (e.g., selection and ecology). This paper deals with such StQPs under an additional sparsity or cardinality constraint, which, even for convex objectives, renders NP-hard problems. One motivation to study StQPs under such sparsity restrictions is the high-dimensional portfolio selection problem with too many assets to handle, in particular, in the presence of transaction costs. Here, relying on modern conic optimization techniques, we present tractable convex relaxations for this relevant but difficult problem. We propose novel equivalent reformulations of these relaxations with significant dimensional reduction, which is essential for the tractability of these relaxations when the problem size grows. Moreover, we propose an instance generation procedure which systematically avoids too easy instances. Our extensive computational results illustrate the high quality of the relaxation bounds in a significant number of instances. Furthermore, in contrast with exact mixed-integer quadratic programming models, the solution time of the relaxations is very robust to the choices of the problem parameters. In particular, the reduced formulations achieve significant improvements in terms of the solution time over their counterparts.",math.OC
Ponzi Funds,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4834390,5/20/2024 18:35,05/20/2024 18:35,Manual,"Philippe van der Beck, Jean-Philippe  Bouchaud, Dario Villamaina","Many active funds hold concentrated portfolios. Flow-driven trading in these securities causes price pressure, which pushes up the funds' existing positions resulting in realized returns. We decompose fund returns into a price pressure (self-inflated) and a fundamental component and show that when allocating capital across funds, investors are unable to identify whether realized returns are self-inflated or fundamental. Because investors chase self-inflated fund returns at a high frequency, even short-lived impact meaningfully affects fund flows at longer time scales. The combination of price impact and return chasing causes an endogenous feedback loop and a reallocation of wealth to early fund investors, which unravels once the price pressure reverts. We find that flows chasing self-inflated returns predict bubbles in ETFs and their subsequent crashes, and lead to a \textit{daily} wealth reallocation of \$500 Million from ETFs alone. We provide a simple regulatory reporting measure -- fund illiquidity -- which captures a fund's potential for self-inflated returns.",
Stock-Bond Correlation: Theory &amp; Empirical Results,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4823094,5/11/2024 12:58,05/11/2024 12:58,Manual,"Lorenzo Portelli, Thierry Roncalli","Stock-bond correlation is an important component of portfolio allocation. It is widely used by institutional investors to determine strategic asset allocation, and is carefully monitored by multi-asset fund managers to implement tactical asset allocation. Over the past 20 years, the correlation between stock and bond returns in the US has been negative, while it was largely positive prior to the dot-com crisis. Investors currently believe that a negative stock-bond correlation is more beneficial than a positive stock-bond correlation because it reduces the risk of a balanced portfolio and limits drawdowns during periods of equity market distress. <br /><br />In this study, we provide an overview of stock-bond correlation modeling. In the first part, we present several theoretical models related to the comovement of stock and bond returns. We distinguish between performance and hedging assets and show that negative correlation implies a negative bond risk premium due to the covariance risk premium component. In contrast, the payoff approach can explain that bonds can be both performance and hedging assets. In addition, a good understanding of the stock-bond correlation requires an assessment of the relationship between the aggregate stock-bond correlation at the portfolio level and the individual stock-bond correlation at the asset level. Macroeconomic models are also useful in interpreting the sign of the stock-bond correlation. They can be divided into three categories: inflation-centric, real-centric, and inflation-growth based. <br /><br />The second part presents the empirical results. We find that the joint dynamics of stock and bond returns differ across countries. The negative stock-bond correlation is mainly associated with the North American market and the European market before the European debt crisis. When sovereign credit risk is a concern, we generally observe a positive stock-bond correlation. However, even in the US, we cannot speak of a unique stock-bond correlation, as the level depends strongly on the composition of the equity portfolio. We also confirm the influence of the inflation factor, but the results for the growth factor are not robust. Finally, we show that the stock-bond correlation is mainly explained by the extreme market regimes, since the stock-bond correlation can be assumed to be zero in normal market regimes.",
Quantities and Covered-Interest Parity,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4820243,5/7/2024 20:38,05/07/2024 20:38,Manual,"Tobias J. Moskowitz, Chase P. Ross, Sharon Y. Ross, Kaushik Vasudevan","Studies of intermediated arbitrage argue that bank balance sheets are an important consideration, yet little evidence exists on banks' positioning in this context. Using confidential supervisory data—covering $25 trillion in daily notional exposures—we examine banks' positions in connection with covered-interest parity (CIP) deviations. Exploiting cross-sectional variation in CIP deviations that has largely presented a puzzle to existing theories, we document the importance of three novel forces: 1) foreign safe asset scarcity, 2) market power and segmentation of banks specializing in different markets, and 3) concentration of demand. Our findings shed empirical light on the interplay of frictions influencing banks' global provision of dollar funding.",
Riding Wavelets: A Method to Discover New Classes of Price Jumps,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4808382,4/26/2024 18:05,04/26/2024 18:05,Manual,"Cecilia Aubrun, Rudy Morel, Michael Benzaquen, Jean-Philippe Bouchaud","Cascades of events and extreme occurrences have garnered significant attention across diverse domains such as financial markets, seismology, and social physics.  <br />Such events can stem either from the internal dynamics inherent to the system (endogenous), or from external shocks (exogenous). The possibility of separating these events into two classes has critical implications for professionals in those fields. We introduce an unsupervised framework leveraging a representation of jump time-series based on wavelet coefficients and apply it to stock price jumps. In line with previous work, we recover the fact that the time-asymmetry of volatility is a major feature. Mean-reversion and trend are found to be two additional key features, allowing us to identify new classes of jumps. Furthermore, thanks to our wavelet-based representation, we investigate the reflexive properties of co-jumps, which occur when multiple stocks experience price jumps within the same minute. We argue that a significant fraction of co-jumps results from an endogenous contagion mechanism.",
Cutting to the Chase on ESG,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4797597,4/17/2024 13:27,04/17/2024 13:27,Manual,"Guillaume Burnichon, Frederic Lepetit, Th&amp;eacute;o Le Guenedal, Takaya Sekine, Rapha&euml;l Semet, Lauren Stagnol","In this study we conduct a thorough analysis of the performance metrics associated with the sub-criteria that comprise environmental, social, and governance (ESG) pillars, focusing on equity markets. Our research reveals that, in a context of growing mistrust in ESG, the aggregation of extra-financial indicators and the reliance on a global ESG score may conceal opportunities at a more granular level. Indeed we showcase that sub-pillars of E, S and G yield more differentiating returns compared to global ESG score, which holds across Eurozone, North America and Emerging Asia since 2021. In North America, the Waste and Biodiversity pillar rallied over the period. In Eurozone and Emerging Asia we point at a dependence from the Emissions and Energy performance on commodity prices: companies with controlled emissions profile outperform their browner peers when commodity prices are high. This emerging selectivity is also reflected in flows. While responsible investment funds experienced a net outflow in 2022 and 2023 for the first time since ESG inception in the early 2010s, the strategies with the highest levels of conviction were the most resilient in terms of flows.",
Eggs in a Basket: Harry Markowitz’s Contribution and How I Achieved Erdős 3,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4753156,3/18/2024 22:42,03/18/2024 22:42,Manual,Campbell R. Harvey,"How many times have you heard: ""Don't put all your eggs in one basket"" when referring to stock investments? That is Harry Markowitz's foundational contribution. Many of my research ideas were a direct result his insights. In his famous 1952 paper, he realized that the mean-variance efficient portfolio was only optimal if there was no preference for skewness. This led to my work in the Journal of Finance expanding the definition of risk to include skewness and estimating mean-variance-skewness efficient portfolios. The 1952 paper also assumes static probability beliefs. This inspired a line of research looking at dynamic probability beliefs with time-varying risk and expected returns. Finally, in the Markowitz framework, the expected returns, variances and covariances are assumed to be exactly known. My work on Bayesian portfolio optimization relaxes this assumption and allows for uncertainty in the inputs. My research epitaph might read: He was a careful reader of Harry Markowitz's footnotes.",
Course 2023-2024 in Sustainable Finance &amp; Climate Change,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730853,3/18/2024 18:29,03/18/2024 18:29,Manual,Thierry Roncalli,"These lectures notes have been written for the course in Sustainable Finance given at the University of Paris-Saclay. The slides cover the following topics: 1. Introduction, 2. ESG Scoring,3. Impact of ESG Investing on Asset Prices and Portfolio Returns, 4. Sustainable Financial Products,5. Impact Investing, 6. Engagement &amp; Voting Policy, 7. Extra-financial Accounting, 8. Awareness of Climate Change Impacts, 9. The Ecosystem of Climate Change, 10. Economic Models \&amp; Climate Change, 11. Climate Risk Measures, 12. Transition Risk Modeling, 13. Climate Portfolio Construction. 14. Physical Risk Modeling and 15. Climate Stress Testing &amp; Risk Management",
Can Machines Learn Weak Signals?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4748784,3/6/2024 21:43,03/06/2024 21:43,Manual,"Zhouyu Shen, Dacheng Xiu","In high-dimensional regression scenarios with low signal-to-noise ratios, we assess the predictive performance of several machine learning algorithms. Theoretical insights show Ridge regression’s superiority in exploiting weak signals, surpassing a zero benchmark. In contrast, Lasso fails to exceed this baseline, indicating its learning limitations. Simulations reveal that Random Forest generally outperforms Gradient Boosted Regression Trees when signals are weak. Moreover, Neural Networks with ℓ2-regularization excel in capturing nonlinear functions of weak signals. Our empirical analysis across six economic datasets suggests that the weakness of signals, not necessarily the absence of sparsity, may be Lasso’s major limitation in economic predictions.",
Machine Learning Methods for Pricing Financial Derivatives,https://arxiv.org/abs/2406.00459,,06/04/2024 09:20,Manual,"Lei Fan, Justin Sirignano","Stochastic differential equation (SDE) models are the foundation for pricing and hedging financial derivatives. The drift and volatility functions in SDE models are typically chosen to be algebraic functions with a small number (less than 5) parameters which can be calibrated to market data. A more flexible approach is to use neural networks to model the drift and volatility functions, which provides more degrees-of-freedom to match observed market data. Training of models requires optimizing over an SDE, which is computationally challenging. For European options, we develop a fast stochastic gradient descent (SGD) algorithm for training the neural network-SDE model. Our SGD algorithm uses two independent SDE paths to obtain an unbiased estimate of the direction of steepest descent. For American options, we optimize over the corresponding Kolmogorov partial differential equation (PDE). The neural network appears as coefficient functions in the PDE. Models are trained on large datasets (many contracts), requiring either large simulations (many Monte Carlo samples for the stock price paths) or large numbers of PDEs (a PDE must be solved for each contract). Numerical results are presented for real market data including S&amp;P 500 index options, S&amp;P 100 index options, and single-stock American options. The neural-network-based SDE models are compared against the Black-Scholes model, the Dupire's local volatility model, and the Heston model. Models are evaluated in terms of how accurate they are at pricing out-of-sample financial derivatives, which is a core task in derivative pricing at financial institutions.","q-fin.CP, q-fin.MF, q-fin.ST"
Not feeling the buzz: Correction study of mispricing and inefficiency in online sportsbooks,https://arxiv.org/abs/2306.01740,,06/04/2024 09:20,Manual,"Lawrence Clegg, John Cartlidge","We present a replication and correction of a recent article (Ramirez, P., Reade, J.J., Singleton, C., Betting on a buzz: Mispricing and inefficiency in online sportsbooks, International Journal of Forecasting, 39:3, 2023, pp. 1413-1423, doi: 10.1016/j.ijforecast.2022.07.011). RRS measure profile page views on Wikipedia to generate a ""buzz factor"" metric for tennis players and show that it can be used to form a profitable gambling strategy by predicting bookmaker mispricing. Here, we use the same dataset as RRS to reproduce their results exactly, thus confirming the robustness of their mispricing claim. However, we discover that the published betting results are significantly affected by a single bet (the ""Hercog"" bet), which returns substantial outlier profits based on erroneously long odds. When this data quality issue is resolved, the majority of reported profits disappear and only one strategy, which bets on ""competitive"" matches, remains significantly profitable in the original out-of-sample period. While one profitable strategy offers weaker support than the original study, it still provides an indication that market inefficiencies may exist, as originally claimed by RRS. As an extension, we continue backtesting after 2020 on a cleaned dataset. Results show that (a) the ""competitive"" strategy generates no further profits, potentially suggesting markets have become more efficient, and (b) model coefficients estimated over this more recent period are no longer reliable predictors of bookmaker mispricing. We present this work as a case study demonstrating the importance of replication studies in sports forecasting, and the necessity to clean data. We open-source release comprehensive datasets and code.","stat.AP, cs.CE, q-fin.GN, q-fin.ST"
Modelling and Forecasting Energy Market Volatility Using GARCH and Machine Learning Approach,https://arxiv.org/abs/2405.19849,,06/03/2024 00:00,Manual,Seulki Chung,"This paper presents a comparative analysis of univariate and multivariate GARCH-family models and machine learning algorithms in modeling and forecasting the volatility of major energy commodities: crude oil, gasoline, heating oil, and natural gas. It uses a comprehensive dataset incorporating financial, macroeconomic, and environmental variables to assess predictive performance and discusses volatility persistence and transmission across these commodities. Aspects of volatility persistence and transmission, traditionally examined by GARCH-class models, are jointly explored using the SHAP (Shapley Additive exPlanations) method. The findings reveal that machine learning models demonstrate superior out-of-sample forecasting performance compared to traditional GARCH models. Machine learning models tend to underpredict, while GARCH models tend to overpredict energy market volatility, suggesting a hybrid use of both types of models. There is volatility transmission from crude oil to the gasoline and heating oil markets. The volatility transmission in the natural gas market is less prevalent.",econ.EM
Latent Factor Analysis in Short Panels,https://arxiv.org/abs/2306.14004,,06/03/2024 00:00,Manual,"Alain-Philippe Fortin, Patrick Gagliardini, Olivier Scaillet",We develop inferential tools for latent factor analysis in short panels. The pseudo maximum likelihood setting under a large cross-sectional dimension n and a fixed time series dimension T relies on a diagonal TxT covariance matrix of the errors without imposing sphericity nor Gaussianity. We outline the asymptotic distributions of the latent factor and error covariance estimates as well as of an asymptotically uniformly most powerful invariant (AUMPI) test for the number of factors based on the likelihood ratio statistic. We derive the AUMPI characterization from inequalities ensuring the monotone likelihood ratio property for positive definite quadratic forms in normal variables. An empirical application to a large panel of monthly U.S. stock returns separates month after month systematic and idiosyncratic risks in short subperiods of bear vs. bull market based on the selected number of factors. We observe an uptrend in the paths of total and idiosyncratic volatilities while the systematic risk explains a large part of the cross-sectional total variance in bear markets but is not driven by a single factor. Rank tests show that observed factors struggle spanning latent factors with a discrepancy between the dimensions of the two factor spaces decreasing over time.,"econ.EM, q-fin.PR, q-fin.ST, stat.AP, stat.ME"
Time Instability of the Fama-French Multifactor Models: An International Evidence,https://arxiv.org/abs/2208.01270,,06/04/2024 09:20,Manual,"Koichiro Moriya, Akihiko Noda","This paper investigates the time-varying structure of Fama and French's (1993; 2015) multi-factor models using Fama and MacBeth's (1973) two-step estimation based on the rolling window method. In particular, we employ the generalized GRS statistics proposed by Kamstra and Shi (2024) to examine whether the validity of the risk factors (or factor redundancy) in the FF3 and FF5 models remains stable over time, and investigate whether the manner of portfolio sorting affects the time stability of the validity of the risk factors. In addition, we examine whether the similar results are obtained even when we use different datasets by country and region. First, we find that the effectiveness of factors in the FF3 and FF5 models is not stable over time in all countries. Second, the effectiveness of factors is also affected by the manner of portfolio sorting. Third, the validity of the FF3, FF5, and their nested models do not remain stable over time except for Japan. This suggests that the efficient market hypothesis is supported in the Japanese stock market. Finally, the factor redundancy varies over time and is affected by the manner of portfolio sorting mainly in the U.S. and Europe.","q-fin.ST, econ.GN, q-fin.EC, q-fin.PR"
Financial Deepening and Economic Growth in Select Emerging Markets with Currency Board Systems: Theory and Evidence,https://arxiv.org/abs/2406.00472,,06/04/2024 09:20,Manual,Yujuan Qiu,"This paper investigates some indicators of financial development in select countries with currency board systems and raises some questions about the connection between financial development and growth in currency board systems. Most of those cases are long past episodes of what we would now call emerging markets. However, the paper also looks at Hong Kong, the currency board system that is one of the world's largest and most advanced financial markets. The global financial crisis of 2008 09 created doubts about the efficiency of financial markets in advanced economies, including in Hong Kong, and unsettled the previous consensus that a large financial sector would be more stable than a smaller one.",econ.EM
Portfolio Optimization with Robust Covariance and Conditional Value-at-Risk Constraints,https://arxiv.org/abs/2406.00610,,06/04/2024 09:20,Manual,Qiqin Zhou,"The measure of portfolio risk is an important input of the Markowitz framework. In this study, we explored various methods to obtain a robust covariance estimators that are less susceptible to financial data noise. We evaluated the performance of large-cap portfolio using various forms of Ledoit Shrinkage Covariance and Robust Gerber Covariance matrix during the period of 2012 to 2022. Out-of-sample performance indicates that robust covariance estimators can outperform the market capitalization-weighted benchmark portfolio, particularly during bull markets. The Gerber covariance with Mean-Absolute-Deviation (MAD) emerged as the top performer. However, robust estimators do not manage tail risk well under extreme market conditions, for example, Covid-19 period. When we aim to control for tail risk, we should add constraint on Conditional Value-at-Risk (CVaR) to make more conservative decision on risk exposure. Additionally, we incorporated unsupervised clustering algorithm K-means to the optimization algorithm (i.e. Nested Clustering Optimization, NCO). It not only helps mitigate numerical instability of the optimization algorithm, but also contributes to lower drawdown as well.","q-fin.PM, econ.EM, math.OC, q-fin.MF, stat.ML"
Causal Contrastive Learning for Counterfactual Regression Over Time,https://arxiv.org/abs/2406.00535,,06/04/2024 09:20,Manual,"Mouad El Bouchattaoui, Myriam Tami, Benoit Lepetit, Paul-Henry Courn\`ede","Estimating treatment effects over time holds significance in various domains, including precision medicine, epidemiology, economy, and marketing. This paper introduces a unique approach to counterfactual regression over time, emphasizing long-term predictions. Distinguishing itself from existing models like Causal Transformer, our approach highlights the efficacy of employing RNNs for long-term forecasting, complemented by Contrastive Predictive Coding (CPC) and Information Maximization (InfoMax). Emphasizing efficiency, we avoid the need for computationally expensive transformers. Leveraging CPC, our method captures long-term dependencies in the presence of time-varying confounders. Notably, recent models have disregarded the importance of invertible representation, compromising identification assumptions. To remedy this, we employ the InfoMax principle, maximizing a lower bound of mutual information between sequence data and its representation. Our method achieves state-of-the-art counterfactual estimation results using both synthetic and real-world data, marking the pioneering incorporation of Contrastive Predictive Encoding in causal inference.","cs.LG, stat.ME"
A Geometric Approach To Asset Allocation With Investor Views,https://arxiv.org/abs/2406.01199,,06/04/2024 09:20,Manual,"Alexandre V. Antonov, Koushik Balasubramanian, Alexander Lipton, Marcos Lopez de Prado","In this article, a geometric approach to incorporating investor views in portfolio construction is presented. In particular, the proposed approach utilizes the notion of generalized Wasserstein barycenter (GWB) to combine the statistical information about asset returns with investor views to obtain an updated estimate of the asset drifts and covariance, which are then fed into a mean-variance optimizer as inputs. Quantitative comparisons of the proposed geometric approach with the conventional Black-Litterman model (and a closely related variant) are presented. The proposed geometric approach provides investors with more flexibility in specifying their confidence in their views than conventional Black-Litterman model-based approaches. The geometric approach also rewards the investors more for making correct decisions than conventional BL based approaches. We provide empirical and theoretical justifications for our claim.","q-fin.MF, q-fin.GN, q-fin.PM"
An adaptive volatility method for probabilistic forecasting and its application to the M6 financial forecasting competition,https://arxiv.org/abs/2303.01855,,06/04/2024 09:20,Manual,"Joseph de Vilmarest, Nicklas Werge","In this paper, we address the problem of probabilistic forecasting using an adaptive volatility method rooted in classical time-varying volatility models and leveraging online stochastic optimization algorithms. These principles were successfully applied in the M6 forecasting competition under the team named AdaGaussMC. Our approach takes a unique path by embracing the Efficient Market Hypothesis (EMH) instead of trying to beat the market directly. We focus on evaluating the efficient market, emphasizing the importance of online forecasting in adapting to the dynamic nature of financial markets. The three key points of our approach are: (a) apply the univariate time-varying volatility model AdaVol, (b) obtain probabilistic forecasts of future returns, and (c) optimize the competition metrics using stochastic gradient-based algorithms. We contend that the simplicity of our approach contributes to its robustness and consistency. Remarkably, our performance in the M6 competition resulted in an overall 7th ranking, with a noteworthy 5th position in the forecasting task. This achievement, considering the perceived simplicity of our approach, underscores the efficacy of our adaptive volatility method in the realm of probabilistic forecasting.","q-fin.PM, q-fin.ST"
Data Scaling Effect of Deep Learning in Financial Time Series Forecasting,https://arxiv.org/abs/2309.02072,,06/04/2024 09:20,Manual,"Chen Liu, Minh-Ngoc Tran, Chao Wang, Richard Gerlach, Robert Kohn","For years, researchers investigated the applications of deep learning in forecasting financial time series. However, they continued to rely on the conventional econometric approach for model training that optimizes the deep learning models on individual assets. This study highlights the importance of global training, where the deep learning model is optimized across a wide spectrum of stocks. Focusing on stock volatility forecasting as an exemplar, we show that global training is not only beneficial but also necessary for deep learning-based financial time series forecasting. We further demonstrate that, given a sufficient amount of training data, a globally trained deep learning model is capable of delivering accurate zero-shot forecasts for any stocks.","econ.EM, cs.AI, q-fin.CP"
A multifractional option pricing formula,https://arxiv.org/abs/2303.16314,,06/04/2024 09:20,Manual,Axel A. Araneda,"Fractional Brownian motion has become a standard tool to address long-range dependence in financial time series. However, a constant memory parameter is too restrictive to address different market conditions. Here we model the price fluctuations using a multifractional Brownian motion assuming that the Hurst exponent is a time-deterministic function. Through the multifractional Ito calculus, both the related transition density function and the analytical European Call option pricing formula are obtained. The empirical performance of the multifractional Black-Scholes model is tested by calibration of option market quotes for the SPX index and offers best fit than its counterparts based on standard and fractional Brownian motions.",q-fin.MF
Modelling Non-monotone Risk Aversion and Convex Compensation in Incomplete Markets,https://arxiv.org/abs/2406.00435,,06/04/2024 09:20,Manual,"Yang Liu, Zhenyu Shen","In hedge funds, convex compensation schemes are popular to stimulate a high-profit performance for portfolio managers. In economics, non-monotone risk aversion is proposed to argue that individuals may not be risk-averse when the wealth level is low. Combining these two ingredients, we study the optimal control strategy of the manager in incomplete markets. Generally, we propose a wide class of utility functions, the Piecewise Symmetric Asymptotic Hyperbolic Absolute Risk Aversion (PSAHARA) utility, to model the two ingredients, containing both non-concavity and non-differentiability as some abnormalities. Significantly, we derive an explicit optimal control for the family of PSAHARA utilities. This control is expressed into a unified four-term structure, featuring the asymptotic Merton term and the risk adjustment term. Furthermore, we provide a detailed asymptotic analysis and numerical illustration of the optimal portfolio. We obtain the following key insights: (i) A manager with the PSAHARA utility becomes extremely risk-seeking when his/her wealth level tends to zero; (ii) The optimal investment ratio tends to the Merton constant as the wealth level approaches infinity and the negative Merton constant when the wealth falls to negative infinity, implying that such a manager takes a risk-seeking investment as the wealth falls negatively low; (iii) The convex compensation still induces a great risk-taking behavior in the case that the preference is modeled by SAHARA utility. Finally, we conduct a real-data analysis of the U.S. stock market under the above model and conclude that the PSAHARA portfolio is very risk-seeking and leads to a high return and a high volatility (two-peak Sharpe ratio).","math.OC, q-fin.MF"
HLOB -- Information Persistence and Structure in Limit Order Books,https://arxiv.org/abs/2405.18938,,06/03/2024 00:00,Manual,"Antonio Briola, Silvia Bartolucci, Tomaso Aste","We introduce a novel large-scale deep learning model for Limit Order Book mid-price changes forecasting, and we name it `HLOB'. This architecture (i) exploits the information encoded by an Information Filtering Network, namely the Triangulated Maximally Filtered Graph, to unveil deeper and non-trivial dependency structures among volume levels; and (ii) guarantees deterministic design choices to handle the complexity of the underlying system by drawing inspiration from the groundbreaking class of Homological Convolutional Neural Networks. We test our model against 9 state-of-the-art deep learning alternatives on 3 real-world Limit Order Book datasets, each including 15 stocks traded on the NASDAQ exchange, and we systematically characterize the scenarios where HLOB outperforms state-of-the-art architectures. Our approach sheds new light on the spatial distribution of information in Limit Order Books and on its degradation over increasing prediction horizons, narrowing the gap between microstructural modeling and deep learning-based forecasting in high-frequency financial markets.","q-fin.TR, cs.LG"
Revisiting Elastic String Models of Forward Interest Rates,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4773233,4/16/2024 5:23,04/16/2024 05:23,Manual,"Victor Le Coz, Jean-Philippe  Bouchaud","Twenty five years ago, several authors proposed to model the forward interest rate curve (FRC) as an elastic string along which idiosyncratic shocks propagate, accounting for the peculiar structure of the return correlation across different maturities. In this paper, we revisit the specific ""stiff'' elastic string field theory of Baaquie and Bouchaud (2004) in a way that makes its micro-foundation more transparent. Our model can be interpreted as capturing the effect of market forces that set the rates of nearby tenors in a self-referential fashion. The model is parsimonious and accurately reproduces the whole correlation structure of the FRC over the time period 1994-2023, with an error below 2%. We need only two parameters, the values of which being very stable except perhaps during the Quantitative Easing period 2009-2014. The dependence of correlation on time resolution (also called the Epps effect) is also faithfully reproduced within the model and leads to a cross-tenor information propagation time of 10 minutes. Finally, we confirm that the perceived time in interest rate markets is a strongly sub-linear function of real time, as surmised by Baaquie and Bouchaud (2004). In fact, our results are fully compatible with hyperbolic discounting, in line with the recent behavioural literature (Farmer and Geanakoplos, 2009).",
Market Risk Premium and ESG Risk,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4762314,4/12/2024 16:30,04/12/2024 16:30,Manual,"Daewoung Choi, Yong Kyu Gam, Yong Hyuck Kim, Dmitriy Muravyev, Hojong Shin","We study the impact of market-wide environmental, social, and governance (ESG) risk on the equity risk premium. We construct an aggregate ESG risk index, consolidating firm-level ESG risk scores from 2010 to 2022. Using the index, we identify days with large increases in aggregate ESG risk (“ESG days”), about 14 days per year. We find a strong positive correlation between the stock market beta and average returns on ESG days. Specifically, the market risk premium is 0.315% on ESG days, in stark contrast to the -0.014% premium on non-ESG days. These findings are consistent across model specifications and test portfolios. The results suggest that ESG risk is systematic and priced.",
Position: What Can Large Language Models Tell Us about Time Series Analysis,https://arxiv.org/abs/2402.02713,,06/04/2024 09:20,Manual,"Ming Jin, Yifan Zhang, Wei Chen, Kexin Zhang, Yuxuan Liang, Bin Yang, Jindong Wang, Shirui Pan, Qingsong Wen","Time series analysis is essential for comprehending the complexities inherent in various realworld systems and applications. Although large language models (LLMs) have recently made significant strides, the development of artificial general intelligence (AGI) equipped with time series analysis capabilities remains in its nascent phase. Most existing time series models heavily rely on domain knowledge and extensive model tuning, predominantly focusing on prediction tasks. In this paper, we argue that current LLMs have the potential to revolutionize time series analysis, thereby promoting efficient decision-making and advancing towards a more universal form of time series analytical intelligence. Such advancement could unlock a wide range of possibilities, including time series modality switching and question answering. We encourage researchers and practitioners to recognize the potential of LLMs in advancing time series analysis and emphasize the need for trust in these related efforts. Furthermore, we detail the seamless integration of time series analysis with existing LLM technologies and outline promising avenues for future research.","cs.LG, cs.AI"
Trading Volume Alpha,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4802345,4/23/2024 1:46,04/23/2024 01:46,Manual,"Ruslan Goyenko, Bryan T. Kelly, Tobias J. Moskowitz, Yinan Su, Chao Zhang","Portfolio optimization chiefly focuses on risk and return prediction, yet implementation costs also play a critical role. Predicting trading costs is challenging, however, since costs depend endogenously on trade size and trader identity, thus impeding a generic solution. We focus on a key, yet general, component of trading costs that abstracts from these challenges---trading volume. Trading volume is highly predictable, especially with machine learning.  We model the economic benefits of predicting volume through a portfolio framework that trades off portfolio tracking error versus net-of-cost performance---in essence translating volume prediction into net-of-cost portfolio alpha. We find the benefits of predicting volume to be substantial, and potentially as large as those from return prediction.",
Optimal single threshold stopping rules and sharp prophet inequalities,https://arxiv.org/abs/2404.12949,,06/04/2024 09:20,Manual,"Alexander Goldenshluger, Yaakov Malinovsky, Assaf Zeevi","This paper considers a finite horizon optimal stopping problem for a sequence of independent and identically distributed random variables. The objective is to design stopping rules that attempt to select the random variable with the highest value in the sequence. The performance of any stopping rule may be benchmarked relative to the selection of a ``prophet"" that has perfect foreknowledge of the largest value. Such comparisons are typically stated in the form of ""prophet inequalities."" In this paper we characterize sharp prophet inequalities for single threshold stopping rules as solutions to infinite two person zero sum games on the unit square with special payoff kernels. The proposed game theoretic characterization allows one to derive sharp non-asymptotic prophet inequalities for different classes of distributions. This, in turn, gives rise to a simple and computationally tractable algorithmic paradigm for deriving optimal single threshold stopping rules.","math.PR, cs.GT, math.OC, math.ST, stat.TH"
ESG-FTSE: A corpus of news articles with ESG relevance labels and use cases,https://arxiv.org/abs/2405.20218,,06/03/2024 00:00,Manual,"Mariya Pavlova, Bernard Casey, Miaosen Wang","We present ESG-FTSE, the first corpus comprised of news articles with Environmental, Social and Governance (ESG) relevance annotations. In recent years, investors and regulators have pushed ESG investing to the mainstream due to the urgency of climate change. This has led to the rise of ESG scores to evaluate an investment's credentials as socially responsible. While demand for ESG scores is high, their quality varies wildly. Quantitative techniques can be applied to improve ESG scores, thus, responsible investing. To contribute to resource building for ESG and financial text mining, we pioneer the ESG-FTSE corpus. We further present the first of its kind ESG annotation schema. It has three levels: a binary classification (relevant versus irrelevant news articles), ESG classification (ESG-related news articles), and target company. Both supervised and unsupervised learning experiments for ESG relevance detection were conducted to demonstrate that the corpus can be used in different settings to derive accurate ESG predictions. Keywords: corpus annotation, ESG labels, annotation schema, news article, natural language processing",cs.AI
Factor Augmented Matrix Regression,https://arxiv.org/abs/2405.17744,,06/03/2024 00:00,Manual,"Elynn Chen, Jianqing Fan, Xiaonan Zhu","We introduce \underline{F}actor-\underline{A}ugmented \underline{Ma}trix \underline{R}egression (FAMAR) to address the growing applications of matrix-variate data and their associated challenges, particularly with high-dimensionality and covariate correlations. FAMAR encompasses two key algorithms. The first is a novel non-iterative approach that efficiently estimates the factors and loadings of the matrix factor model, utilizing techniques of pre-training, diverse projection, and block-wise averaging. The second algorithm offers an accelerated solution for penalized matrix factor regression. Both algorithms are supported by established statistical and numerical convergence properties. Empirical evaluations, conducted on synthetic and real economics datasets, demonstrate FAMAR's superiority in terms of accuracy, interpretability, and computational speed. Our application to economic data showcases how matrix factors can be incorporated to predict the GDPs of the countries of interest, and the influence of these factors on the GDPs.",stat.ME
Combining exchangeable p-values,https://arxiv.org/abs/2404.03484,,06/03/2024 00:00,Manual,"Matteo Gasparin, Ruodu Wang, Aaditya Ramdas","The problem of combining p-values is an old and fundamental one, and the classic assumption of independence is often violated or unverifiable in many applications. There are many well-known rules that can combine a set of arbitrarily dependent p-values (for the same hypothesis) into a single p-value. We show that essentially all these existing rules can be strictly improved when the p-values are exchangeable, or when external randomization is allowed (or both). For example, we derive randomized and/or exchangeable improvements of well known rules like ""twice the median"" and ""twice the average"", as well as geometric and harmonic means. Exchangeable p-values are often produced one at a time (for example, under repeated tests involving data splitting), and our rules can combine them sequentially as they are produced, stopping when the combined p-values stabilize. Our work also improves rules for combining arbitrarily dependent p-values, since the latter becomes exchangeable if they are presented to the analyst in a random order. The main technical advance is to show that all existing combination rules can be obtained by calibrating the p-values to e-values (using an $\alpha$-dependent calibrator), averaging those e-values, converting to a level-$\alpha$ test using Markov's inequality, and finally obtaining p-values by combining this family of tests; the improvements are delivered via recent randomized and exchangeable variants of Markov's inequality.","math.ST, stat.TH"
On Robust Clustering of Temporal Point Process,https://arxiv.org/abs/2405.17828,,06/03/2024 00:00,Manual,"Yuecheng Zhang, Guanhua Fang, Wen Yu","Clustering of event stream data is of great importance in many application scenarios, including but not limited to, e-commerce, electronic health, online testing, mobile music service, etc. Existing clustering algorithms fail to take outlier data into consideration and are implemented without theoretical guarantees. In this paper, we propose a robust temporal point processes clustering framework which works under mild assumptions and meanwhile addresses several important issues in the event stream clustering problem.Specifically, we introduce a computationally efficient model-free distance function to quantify the dissimilarity between different event streams so that the outliers can be detected and the good initial clusters could be obtained. We further consider an expectation-maximization-type algorithm incorporated with a Catoni's influence function for robust estimation and fine-tuning of clusters. We also establish the theoretical results including algorithmic convergence, estimation error bound, outlier detection, etc. Simulation results corroborate our theoretical findings and real data applications show the effectiveness of our proposed methodology.",stat.ME
"Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations",https://arxiv.org/abs/2405.15990,,06/03/2024 00:00,Manual,"Artem Agafonov, Petr Ostroukhov, Roman Mozhaev, Konstantin Yakovlev, Eduard Gorbunov, Martin Tak\'a\v{c}, Alexander Gasnikov, Dmitry Kamzolov","Variational inequalities represent a broad class of problems, including minimization and min-max problems, commonly found in machine learning. Existing second-order and high-order methods for variational inequalities require precise computation of derivatives, often resulting in prohibitively high iteration costs. In this work, we study the impact of Jacobian inaccuracy on second-order methods. For the smooth and monotone case, we establish a lower bound with explicit dependence on the level of Jacobian inaccuracy and propose an optimal algorithm for this key setting. When derivatives are exact, our method converges at the same rate as exact optimal second-order methods. To reduce the cost of solving the auxiliary problem, which arises in all high-order methods with global convergence, we introduce several Quasi-Newton approximations. Our method with Quasi-Newton updates achieves a global sublinear convergence rate. We extend our approach with a tensor generalization for inexact high-order derivatives and support the theory with experiments.",math.OC
On the Law of Large Numbers for non-equally distributed weakly dependent random variables,https://arxiv.org/abs/2405.17850,,06/03/2024 00:00,Manual,"Alina Akhmiarova, Alexander Veretennikov","Three versions of the Weak Law of Large Numbers are proposed for weakly dependent and generally speaking non-equally distributed random variables, with finite or possibly infinite expectations.",math.PR
Empirical Evidence for the New Definitions in Financial Markets and Equity Premium Puzzle,https://arxiv.org/abs/2305.03468,,06/03/2024 00:00,Manual,Atilla Aras,"This study presents empirical evidence to support the validity of new definitions in financial markets. The author develops a new method to determine investors' risk attitudes in financial markets. The risk attitudes of investors in US financial markets from 1889-1978 are analyzed and the results indicate that equity investors who invested in the composite S&amp;P 500 index were risk-averse in 1977. Conversely, risk-free asset investors who invested in US Treasury bills were found to exhibit not enough risk-loving behavior, which can be considered a type of risk-averse behavior. These findings suggest that the new definitions in financial markets accurately reflect the behavior of investors and should be considered in investment strategies.","q-fin.GN, econ.GN, q-fin.EC"
Independence Testing for Temporal Data,https://arxiv.org/abs/1908.06486,,06/03/2024 00:00,Manual,"Cencheng Shen, Jaewon Chung, Ronak Mehta, Ting Xu, Joshua T. Vogelstein","Temporal data are increasingly prevalent in modern data science. A fundamental question is whether two time series are related or not. Existing approaches often have limitations, such as relying on parametric assumptions, detecting only linear associations, and requiring multiple tests and corrections. While many non-parametric and universally consistent dependence measures have recently been proposed, directly applying them to temporal data can inflate the p-value and result in an invalid test. To address these challenges, this paper introduces the temporal dependence statistic with block permutation to test independence between temporal data. Under proper assumptions, the proposed procedure is asymptotically valid and universally consistent for testing independence between stationary time series, and capable of estimating the optimal dependence lag that maximizes the dependence. Moreover, it is compatible with a rich family of distance and kernel based dependence measures, eliminates the need for multiple testing, and exhibits excellent testing power in various simulation settings.","stat.ML, cs.LG, stat.ME"
Time Series Representation Models,https://arxiv.org/abs/2405.18165,,06/03/2024 00:00,Manual,"Robert Leppich, Vanessa Borst, Veronika Lesch, Samuel Kounev","Time series analysis remains a major challenge due to its sparse characteristics, high dimensionality, and inconsistent data quality. Recent advancements in transformer-based techniques have enhanced capabilities in forecasting and imputation; however, these methods are still resource-heavy, lack adaptability, and face difficulties in integrating both local and global attributes of time series. To tackle these challenges, we propose a new architectural concept for time series analysis based on introspection. Central to this concept is the self-supervised pretraining of Time Series Representation Models (TSRMs), which once learned can be easily tailored and fine-tuned for specific tasks, such as forecasting and imputation, in an automated and resource-efficient manner. Our architecture is equipped with a flexible and hierarchical representation learning process, which is robust against missing data and outliers. It can capture and learn both local and global features of the structure, semantics, and crucial patterns of a given time series category, such as heart rate data. Our learned time series representation models can be efficiently adapted to a specific task, such as forecasting or imputation, without manual intervention. Furthermore, our architecture's design supports explainability by highlighting the significance of each input value for the task at hand. Our empirical study using four benchmark datasets shows that, compared to investigated state-of-the-art baseline methods, our architecture improves imputation and forecasting errors by up to 90.34% and 71.54%, respectively, while reducing the required trainable parameters by up to 92.43%. The source code is available at https://github.com/RobertLeppich/TSRM.","cs.LG, cs.AI"
Advancing Financial Risk Prediction Through Optimized LSTM Model Performance and Comparative Analysis,https://arxiv.org/abs/2405.20603,,06/03/2024 00:00,Manual,"Ke Xu, Yu Cheng, Shiqing Long, Junjie Guo, Jue Xiao, Mengfang Sun","This paper focuses on the application and optimization of LSTM model in financial risk prediction. The study starts with an overview of the architecture and algorithm foundation of LSTM, and then details the model training process and hyperparameter tuning strategy, and adjusts network parameters through experiments to improve performance. Comparative experiments show that the optimized LSTM model shows significant advantages in AUC index compared with random forest, BP neural network and XGBoost, which verifies its efficiency and practicability in the field of financial risk prediction, especially its ability to deal with complex time series data, which lays a solid foundation for the application of the model in the actual production environment.","cs.LG, cs.AI"
IncomeSCM: From tabular data set to time-series simulator and causal estimation benchmark,https://arxiv.org/abs/2405.16069,,06/03/2024 00:00,Manual,Fredrik D. Johansson,"Evaluating observational estimators of causal effects demands information that is rarely available: unconfounded interventions and outcomes from the population of interest, created either by randomization or adjustment. As a result, it is customary to fall back on simulators when creating benchmark tasks. Simulators offer great control but are often too simplistic to make challenging tasks, either because they are hand-designed and lack the nuances of real-world data, or because they are fit to observational data without structural constraints. In this work, we propose a general, repeatable strategy for turning observational data into sequential structural causal models and challenging estimation tasks by following two simple principles: 1) fitting real-world data where possible, and 2) creating complexity by composing simple, hand-designed mechanisms. We implement these ideas in a highly configurable software package and apply it to the well-known Adult income data set to construct the \tt IncomeSCM simulator. From this, we devise multiple estimation tasks and sample data sets to compare established estimators of causal effects. The tasks present a suitable challenge, with effect estimates varying greatly in quality between methods, despite similar performance in the modeling of factual outcomes, highlighting the need for dedicated causal estimators and model selection criteria.","cs.LG, stat.ME"
From classical to modern central limit theorems,https://arxiv.org/abs/2405.19828,,06/03/2024 00:00,Manual,Vladimir V. Ulyanov,"De Moivre (1733), investigating the limit distribution of the binomial distribution, was the first to discover the existence of the normal distribution and the central limit theorem. In this review article, we briefly recall the history of classical central limit theorem and martingale central limit theorem, and introduce a new direction of central limit theorem, namely nonlinear central limit theorem and nonlinear normal distribution.",math.PR
Automated Market Making and Loss-Versus-Rebalancing,https://arxiv.org/abs/2208.06046,,06/03/2024 00:00,Manual,"Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden, Anthony Lee Zhang","We consider the market microstructure of automated market makers (AMMs) from the perspective of liquidity providers (LPs). Our central contribution is a ``Black-Scholes formula for AMMs''. We identify the main adverse selection cost incurred by LPs, which we call ``loss-versus-rebalancing'' (LVR, pronounced ``lever''). LVR captures costs incurred by AMM LPs due to stale prices that are picked off by better informed arbitrageurs. We derive closed-form expressions for LVR applicable to all automated market makers. Our model is quantitatively realistic, matching actual LP returns empirically, and shows how CFMM protocols can be redesigned to reduce or eliminate LVR.","q-fin.MF, math.OC, q-fin.PM, q-fin.PR, q-fin.TR"
Prophet Inequalities: Separating Random Order from Order Selection,https://arxiv.org/abs/2304.04024,,06/05/2024 08:37,Manual,"Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona","Prophet inequalities are a central object of study in optimal stopping theory. A gambler is sent values in an online fashion, sampled from an instance of independent distributions, in an adversarial, random or selected order, depending on the model. When observing each value, the gambler either accepts it as a reward or irrevocably rejects it and proceeds to observe the next value. The goal of the gambler, who cannot see the future, is maximising the expected value of the reward while competing against the expectation of a prophet (the offline maximum). In other words, one seeks to maximise the gambler-to-prophet ratio of the expectations.
  The model, in which the gambler selects the arrival order first, and then observes the values, is known as Order Selection. In this model a ratio of $0.7251$ has been proved to be attainable for any instance. In very recent work, this has been improved up to $0.7258$. If the gambler chooses the arrival order (uniformly) at random, we obtain the Random Order model. The worst case ratio over all possible instances has been extensively studied for at least $40$ years. In the recent work aforementioned, through simulations, this ratio has been shown to be at most $0.7254$ for the Random Order model, thus establishing for the first time that carefully choosing the order, instead of simply taking it at random, benefits the gambler. We give an alternative, non-simulation-assisted proof of this fact, by showing mathematically that in the Random Order model, no algorithm can achieve a ratio larger than $0.7235$. This sets a new state-of-the-art hardness for this model, and establishes more formally that there is a real benefit in choosing the order.","cs.DS, cs.DM, math.OC, math.PR"
Autoencoder-Based Risk-Neutral Model for Interest Rates,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4836728,5/22/2024 18:56,05/22/2024 18:56,randomForestClassifier,"Andrei Lyashenko, Fabio Mercurio, Alexander Sokol","It is well known that yield curves have low effective dimensionality, and can be accurately represented using very few latent variables. The recent extension to nonlinear representations by means of autoencoders (AE) provided further improvement in accuracy compared to the classical linear representations from the Nelson-Siegel family or those obtained using principal component analysis (PCA). We examine Q-measure dynamics in an economy where historical curve evolution is consistent with such low dimensional representations (manifolds) and describe the constraints under which instrument prices in this economy can be arbitrage free for any level of volatility. We then derive the most general form of such arbitrage-free manifolds, and propose a new approach to constructing them based on the geometric concept of generating manifolds. In conclusion, we present a Q-measure model based on arbitrage-free AE manifolds and discuss theoretical and practical benefits of the proposed approach for risk and pricing applications.",
Layer-2 Arbitrage: An Empirical Analysis of Swap Dynamics and Price Disparities on Rollups,https://arxiv.org/abs/2406.02172,,06/05/2024 08:37,Manual,"Krzysztof Gogol, Johnnatan Messias, Deborah Miori, Claudio Tessone, Benjamin Livshits","This paper explores the dynamics of Decentralized Finance (DeFi) within the Layer-2 ecosystem, focusing on Automated Market Makers (AMM) and arbitrage on Ethereum rollups. We observe significant shifts in trading activity from Ethereum to rollups, with swaps on rollups happening 2-3 times more often, though, with lower trade volume. By examining the price differences between AMMs and centralized exchanges, we discover over 0.5 million unexploited arbitrage opportunities on rollups. Remarkably, we observe that these opportunities last, on average, 10 to 20 blocks, requiring adjustments to the LVR metrics to avoid double-counting arbitrage. Our results show that arbitrage in Arbitrum, Base, and Optimism pools ranges from 0.03% to 0.05% of trading volume, while in zkSync Era it oscillates around 0.25%, with the LVR metric overestimating arbitrage by a factor of five. Rollups offer not only lower gas fees, but also provide faster block production, leading to significant differences compared to the trading and arbitrage dynamics of Ethereum.",cs.CR
Optimal exercise of American options under time-dependent Ornstein-Uhlenbeck processes,https://arxiv.org/abs/2211.04095,,06/04/2024 09:20,Manual,"Abel Azze, Bernardo D'Auria, Eduardo Garc\'ia-Portugu\'es","We study the barrier that gives the optimal time to exercise an American option written on a time-dependent Ornstein--Uhlenbeck process, a diffusion often adopted by practitioners to model commodity prices and interest rates. By framing the optimal exercise of the American option as a problem of optimal stopping and relying on probabilistic arguments, we provide a non-linear Volterra-type integral equation characterizing the exercise boundary, develop a novel comparison argument to derive upper and lower bounds for such a boundary, and prove its Lipschitz continuity in any closed interval that excludes the expiration date and, thus, its differentiability almost everywhere. We implement a Picard iteration algorithm to solve the Volterra integral equation and show illustrative examples that shed light on the boundary's dependence on the process's drift and volatility.","math.PR, q-fin.MF, q-fin.PR"
A sequential test procedure for the choice of the number of regimes in multivariate nonlinear models,https://arxiv.org/abs/2406.02152,,06/05/2024 08:37,Manual,Andrea Bucci,"This paper proposes a sequential test procedure for determining the number of regimes in nonlinear multivariate autoregressive models. The procedure relies on linearity and no additional nonlinearity tests for both multivariate smooth transition and threshold autoregressive models. We conduct a simulation study to evaluate the finite-sample properties of the proposed test in small samples. Our findings indicate that the test exhibits satisfactory size properties, with the rescaled version of the Lagrange Multiplier test statistics demonstrating the best performance in most simulation settings. The sequential procedure is also applied to two empirical cases, the US monthly interest rates and Icelandic river flows. In both cases, the detected number of regimes aligns well with the existing literature.","econ.EM, math.ST, stat.TH"
Intergenerational Equitable Climate Change Mitigation: Negative Effects of Stochastic Interest Rates; Positive Effects of Financing,https://arxiv.org/abs/2312.07614,,06/03/2024 00:00,Manual,"Christian P. Fries, Lennart Quante","Today's decisions on climate change mitigation affect the damage that future generations will bear. Discounting future benefits and costs of climate change mitigation is one of the most critical components of assessing efficient climate mitigation pathways. We extend the DICE model with stochastic discount rates to reflect the uncertain nature of discount rates. Stochastic rates give rise to a stochastic mitigation strategy, resulting in all model quantities becoming stochastic.
  We show that the classical calibration of the DICE model induces intergenerational inequality: future generations have to bear higher costs relative to GDP. Further, we show that considering stochastic discount rates and stochastic abatement policies, which can be interpreted as successive re-calibration, increases intergenerational inequality (and adds additional risks). Motivated by this, we consider additional financing risks by investigating two modifications of DICE. We find that allowing financing of abatement costs and considering non-linear financing effects for large damages improves intergenerational effort sharing. To conclude our discussion of options to improve intergenerational equity in an IAM, we propose a modified optimization to keep costs below 3% of GDP, resulting in more equal distribution of efforts between generations.","q-fin.MF, econ.GN, q-fin.EC"
Is There Still a Golden Dilemma?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4807895,5/4/2024 12:11,05/04/2024 12:11,Manual,"Claude B. Erb, Campbell R. Harvey","The real, inflation-adjusted, price of gold is high. Historically, a high real gold price has been associated with low inflation-adjusted gold returns over the subsequent 10 years. Further, historically the realized 10-year rate of inflation has had close to no impact on realized 10-year nominal and real gold returns. An influx of investment in gold (from gold-owning ETFs, Costco shoppers, “de-dollarizing” central banks and possibly others) has seemingly doubled the real price of gold relative to pre-influx times. Today’s golden dilemma is yesterday’s golden dilemma: has an influx of gold buying ushered in a new age of permanently higher “this time is different” real gold prices or is this simply the latest “wash, rinse, repeat” cycle setting-up a significant fall in real gold prices?",
Microstructure Modes -- Disentangling the Joint Dynamics of Prices &amp; Order Flow,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4831906,5/18/2024 12:25,05/18/2024 12:25,Manual,"Salma ELOMARI-KESSAB, Guillaume Maitrier, Julius Bonart, Jean-Philippe  Bouchaud","In order to alleviate various problems caused by high-frequency noise, we propose a double coarse-graining procedure that allows us to extract meaningful information at the minute time scale. We use Principal Component Analysis to construct ""microstructure modes'' that describe the most common flow/return patterns and allow one to separate them into bid-ask symmetric and bid-ask anti-symmetric. We define and calibrate a Vector Auto-Regressive (VAR) model that encodes the dynamical evolution of these modes. The parameters of the VAR model are found to be extremely stable in time, and lead to relatively high R² prediction scores, especially for symmetric liquidity modes. The VAR model becomes marginally unstable as more lags are included, reflecting the long-memory nature of flows and giving some further credence to the possibility of ""endogenous liquidity crises''. Although very satisfactory on several counts, we show that our VAR framework does not account for the well known square-root law of price impact.",
Inference of Utilities and Time Preference in Sequential Decision-Making,https://arxiv.org/abs/2405.15975,,06/05/2024 08:37,Manual,"Haoyang Cao, Zhengqi Wu, Renyuan Xu","This paper introduces a novel stochastic control framework to enhance the capabilities of automated investment managers, or robo-advisors, by accurately inferring clients' investment preferences from past activities. Our approach leverages a continuous-time model that incorporates utility functions and a generic discounting scheme of a time-varying rate, tailored to each client's risk tolerance, valuation of daily consumption, and significant life goals. We address the resulting time inconsistency issue through state augmentation and the establishment of the dynamic programming principle and the verification theorem. Additionally, we provide sufficient conditions for the identifiability of client investment preferences. To complement our theoretical developments, we propose a learning algorithm based on maximum likelihood estimation within a discrete-time Markov Decision Process framework, augmented with entropy regularization. We prove that the log-likelihood function is locally concave, facilitating the fast convergence of our proposed algorithm. Practical effectiveness and efficiency are showcased through two numerical examples, including Merton's problem and an investment problem with unhedgeable risks.
  Our proposed framework not only advances financial technology by improving personalized investment advice but also contributes broadly to other fields such as healthcare, economics, and artificial intelligence, where understanding individual preferences is crucial.","math.OC, cs.LG, q-fin.CP"
Distributional bias compromises leave-one-out cross-validation,https://arxiv.org/abs/2406.01652,,06/05/2024 08:37,Manual,"George I. Austin, Itsik Pe'er, Tal Korem","Cross-validation is a common method for estimating the predictive performance of machine learning models. In a data-scarce regime, where one typically wishes to maximize the number of instances used for training the model, an approach called ""leave-one-out cross-validation"" is often used. In this design, a separate model is built for predicting each data instance after training on all other instances. Since this results in a single test data point available per model trained, predictions are aggregated across the entire dataset to calculate common rank-based performance metrics such as the area under the receiver operating characteristic or precision-recall curves. In this work, we demonstrate that this approach creates a negative correlation between the average label of each training fold and the label of its corresponding test instance, a phenomenon that we term distributional bias. As machine learning models tend to regress to the mean of their training data, this distributional bias tends to negatively impact performance evaluation and hyperparameter optimization. We show that this effect generalizes to leave-P-out cross-validation and persists across a wide range of modeling and evaluation approaches, and that it can lead to a bias against stronger regularization. To address this, we propose a generalizable rebalanced cross-validation approach that corrects for distributional bias. We demonstrate that our approach improves cross-validation performance evaluation in synthetic simulations and in several published leave-one-out analyses.","stat.ME, cs.LG, q-bio.QM"
Pricing and calibration in the 4-factor path-dependent volatility model,https://arxiv.org/abs/2406.02319,,06/05/2024 08:37,Manual,"Guido Gazzani, Julien Guyon","We consider the path-dependent volatility (PDV) model of Guyon and Lekeufack (2023), where the instantaneous volatility is a linear combination of a weighted sum of past returns and the square root of a weighted sum of past squared returns. We discuss the influence of an additional parameter that unlocks enough volatility on the upside to reproduce the implied volatility smiles of S&amp;P 500 and VIX options. This PDV model, motivated by empirical studies, comes with computational challenges, especially in relation to VIX options pricing and calibration. We propose an accurate neural network approximation of the VIX which leverages on the Markovianity of the 4-factor version of the model. The VIX is learned as a function of the Markovian factors and the model parameters. We use this approximation to tackle the joint calibration of S&amp;P 500 and VIX options.","q-fin.CP, q-fin.MF, q-fin.PR"
Generalized Exponentiated Gradient Algorithms and Their Application to On-Line Portfolio Selection,https://arxiv.org/abs/2406.00655,,06/04/2024 09:20,Manual,"Andrzej Cichocki, Sergio Cruces, Auxiliadora Sarmiento, Toshihisa Tanaka","This paper introduces a novel family of generalized exponentiated gradient (EG) updates derived from an Alpha-Beta divergence regularization function. Collectively referred to as EGAB, the proposed updates belong to the category of multiplicative gradient algorithms for positive data and demonstrate considerable flexibility by controlling iteration behavior and performance through three hyperparameters: $\alpha$, $\beta$, and the learning rate $\eta$. To enforce a unit $l_1$ norm constraint for nonnegative weight vectors within generalized EGAB algorithms, we develop two slightly distinct approaches. One method exploits scale-invariant loss functions, while the other relies on gradient projections onto the feasible domain. As an illustration of their applicability, we evaluate the proposed updates in addressing the online portfolio selection problem (OLPS) using gradient-based methods. Here, they not only offer a unified perspective on the search directions of various OLPS algorithms (including the standard exponentiated gradient and diverse mean-reversion strategies), but also facilitate smooth interpolation and extension of these updates due to the flexibility in hyperparameter selection. Simulation results confirm that the adaptability of these generalized gradient updates can effectively enhance the performance for some portfolios, particularly in scenarios involving transaction costs.","cs.LG, cs.IT, math.IT"
Dynamic Economics with Quantile Preferences,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4108230,05/13/2022 15:56,06/06/2024 15:23,Manual,"Luciano I. de Castro, Antonio F. Galvao, Daniel Nunes","This paper studies the dynamic quantile model for intertemporal decisions under uncertainty, in which the decision maker maximizes the τ-quantile, for τ ∈ (0, 1) of the stream of future utilities. We present two sets of contributions. First, we generalize existing results in directions that are important for applications. Second, we illustrate the simplicity and usefulness of this approach by applying it to five standard models in macroeconomics, development, finance and labor. In the first model, we construct an intertemporal consumption model with one asset and derive its properties. We obtain closed-form expressions for the value function, the optimal asset allocation and consumption, as well as for the consumption path. Second, we revisit the one-sector growth model. We compare and contrast the results with the corresponding expected utility case. We also investigate two models of investment under uncertainty, one with convex costs and another with demand uncertainty. We derive the corresponding quantile Euler equations and show that the purchase price of capital is the τ-quantile of the discounted present value of marginal profits. Finally, we discuss a quantile-based version of the job-search model. As mentioned, the paper generalizes the settings where one can use the dynamic quantile model. First, the future state is not determined exclusively by agent’s choice, but can be determined by the choice and shocks. Second, we allow choice variables and shocks to be either discrete or continuous. Under these generalizations, we show that the intertemporal quantile preferences are dynamically consistent, the corresponding dynamic problem yields a value function, this value function is concave and differentiable, and the principle of optimality holds. Additionally, we derive the corresponding Euler equation. These extensions broaden substantially the scope of applications for dynamic quantile models.",
Pure Strategy Equilibria of Single and Double Auctions with Interdependent Values,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2330502,09/29/2013 22:59,06/06/2024 15:23,Manual,"Aloisio Araujo, Luciano I. de Castro","We prove the existence of monotonic pure strategy equilibrium for many kinds of asymmetric auctions with n bidders and unitary demands, interdependent values and independent types. The assumptions require monotonicity only in the own bidder’s type. The payments can be a function of all bids. Thus, we provide a new equilibrium existence result for asymmetrical double auctions and a small number of bidders. The generality of our setting requires the use of special tie-breaking rules. We present an example of a double auction with interdependent values where all equilibria are trivial, that is, they have zero probability of trade. This is related to Akerlof’s “market for lemmons” example and to the “winner’s curse,” establishing a connection between them. However, we are able to provide sufﬁcient conditions for non-trivial equilibrium existence.",
Portfolio Selection in Quantile Decision Models,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3494601,12/13/2019 20:20,06/06/2024 15:23,Manual,"Luciano I. de Castro, Antonio F. Galvao, Gabriel Montes-Rojas, Jose Olmo","This paper develops a model for optimal portfolio allocation for an investor with quantile preferences, i.e., who maximizes  the τ-quantile of the portfolio return, for τ ∈ (0,1). Quantile preferences allow to study heterogeneity in individuals' portfolio choice by varying the quantiles, and have a solid axiomatic foundation. Their associated risk attitude is captured entirely by a single dimensional parameter (the quantile τ), instead of the utility function. We formally establish the properties of the quantile model.  The presence of a risk-free asset in the portfolio produces an all-or-nothing optimal response to the risk-free asset that depends on investors' quantile preference. In addition, when both assets are risky, we derive conditions under which the optimal portfolio decision has an interior solution that guarantees diversification vis-\`a-vis fully investing in a single risky asset. We also derive conditions under which the optimal portfolio decision is characterized by two regions: full diversification for quantiles below the median and no diversification for upper quantiles. These results are illustrated in an exhaustive simulation study and an empirical application using a tactical portfolio of stocks, bonds and a risk-free asset. The results show heterogeneity in portfolio diversification across risk attitudes.",
Do People Maximize Quantiles?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3607612,06/09/2020 15:51,06/06/2024 15:23,Manual,"Luciano I. de Castro, Antonio F. Galvao, Charles Noussair Noussair, Liang Qiao","Payoff quantiles have been used for decision making in banking and investment (in the form of Value-at-Risk) and in the mining, oil and gas industries (in the form of ""probabilities of exceeding"" a certain level of production). However, it is unknown how common quantile-based decision making actually is among typical individual decision makers. This paper describes an experiment that aims to (1) compare how common quantile decision making is relative to expected utility maximization, and (2) estimate risk attitude parameters under the assumption of quantile preferences. The experiment has two parts. In the first part, individuals make pairwise choices between risky lotteries, and the competing models are fitted to the choice data. In the second part, we directly elicit a decision rule from a menu of alternatives. The results show that a quantile preference model outperforms expected utility for a considerable minority, 30%--50%, of participants, depending on the metric. The majority of individuals are risk averse, and women are more risk averse than men, under both models.<br />",
A Statistical Learning Approach to Local Volatility Calibration and Option Pricing,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4678683,01/19/2024 14:52,06/06/2024 15:23,Manual,"Vinicius Albani, Leonardo Sarmanho, Jorge Zubelli","By combining Bayes’ theorem and maximum entropy densities (MED), we propose an accurate and computationally efficient technique for European option pricing and local volatility calibration. The resulting data driven technique avoids the solution of partial differential equations and the use of Monte Carlo methods. We also show that, under the proposed setting, the price of European options can be expressed as the average Black-Scholes option prices. Numerical examples with synthetic and real data illustrate the effectiveness of the pricing and estimation tools.",
Experiments on Portfolio Selection: A Comparison between Quantile Preferences and Expected Utility Decision Models,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3843111,05/11/2021 14:11,06/06/2024 15:23,Manual,"Luciano I. de Castro, Antonio F. Galvao, Jeong Yeol Kim, Gabriel Montes-Rojas, Jose Olmo","This paper conducts a laboratory experiment to assess the optimal portfolio allocation under quantile preferences (QP) and compare the model's predictions with those of the expected utility theory using a mean-variance (MV) utility function. We estimate the risk aversion coefficients associated to the individuals' empirical portfolio choices under the QP and MV theories, and evaluate the relative predictive performance of each theory. The experiment assesses individuals' preferences through a portfolio choice experiment constructed from two assets that may include a risk-free asset. The results of the experiment confirm the suitability of both theories to predict individuals' optimal choices. Furthermore, the aggregation of results by individual choices offers support to the MV theory.  However, the aggregation of results by task, which is far more informative, provides more support to the QP theory. The overall message that emerges from this experiment is that individuals' behavior is better predicted by the MV model when it is difficult to assess the differences in the lotteries' payoff distributions but better described as QP maximizers, otherwise.",
Quantile Approach to Intertemporal Consumption with Multiple Assets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4601551,10/26/2023 12:44,06/06/2024 15:23,Manual,"Luciano I. de Castro, Antonio F. Galvao, Hirofumi Ota","This paper develops a novel economic model and econometric methods to jointly identify and estimate parameters related to intertemporal preference and risk attitude. We begin by formulating an intertemporal consumption model with multiple assets based on dynamic quantile preferences that account for elasticity of intertemporal substitution, risk attitude, and discount factor. In this recursive model under uncertainty, the economic agent maximizes the discounted value of stream of future τ-quantile utilities, for τ ∈ (0, 1), and decides on the intertemporal consumption and assets to hold (savings), from a selection of multiple assets over time, subject to the standard budget constraint. We establish the properties of the  model and obtain interesting explicit expressions for the value function, and the optimal consumption. In addition, we derive the quantile Euler equation. From this equilibrium condition, we show that, when at least two returns are available, one is able to separately identify the risk attitude, which is measured by the quantile τ, and the elasticity of intertemporal substitution and discount factor. We propose new econometric theory for estimating these parameters of interest and establish the statistical properties of the semiparametric two-step estimator. In particular, we show that the estimator is consistent, with a cubic rate of convergence, derive its limiting distribution, and suggest a subsampling procedure for inference. Finally, we empirically estimate the structural model using both aggregated and disaggregated data. Results show evidence that discount factor is slightly smaller than one, the elasticity of intertemporal substitution is larger than one, and risk attitude is close to the median.",
The Returns to Currency Speculation in Emerging Markets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=964879,02/23/2007 13:41,06/07/2024 11:05,randomForestClassifier,"A. Craig Burnside, Martin Eichenbaum, Sergio T. Rebelo","The carry trade strategy involves selling forward currencies that are at a forward premium and buying forward currencies that are at a forward discount. We compare the payoffs to the carry trade applied to two different portfolios. The first portfolio consists exclusively of developed country currencies. The second portfolio includes the currencies of both developed countries and emerging markets. Our main empirical findings are as follows. First, including emerging market currencies in our portfolio substantially increases the Sharpe ratio associated with the carry trade. Second, bid-ask spreads are two to four times larger in emerging markets than in developed countries. Third and most dramatically, the payoffs to the carry trade for both portfolios are uncorrelated with returns to the U.S. stock market.",
Do Subjective Expectations Explain Asset Pricing Puzzles?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1344123,02/19/2009 00:00,06/07/2024 11:06,randomForestClassifier,"Gurdip Bakshi, Georgios  Skoulakis","The structural uncertainty model with Bayesian learning, advanced by Weitzman (AER 2007), provides a framework for gauging the effect of structural uncertainty on asset prices and risk premiums. This paper provides an operational version of this approach that incorporates realistic priors about consumption growth volatility, while guaranteeing finite asset pricing quantities. In contrast to the extant literature, the resulting asset pricing model with subjective expectations yields well-defined expected utility, finite moment generating function of consumption growth, and tractable expressions for equity premium and riskfree return. Our quantitative analysis reveals that explaining the historical equity premium and riskfree return, in the context of subjective expectations, requires implausible levels of structural uncertainty. Furthermore, these implausible prior beliefs result in consumption disaster probabilities that virtually coincide with those implied by more realistic priors. At the same time, the two sets of prior beliefs have diametrically opposite asset pricing implications: one asserting, and the other contradicting, the antipuzzle view.",
Are Options on Index Futures Profitable for Risk Averse Investors‘ Empirical Evidence,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1282085,10/14/2008 00:00,06/07/2024 11:03,randomForestClassifier,"George M. Constantinides, Michal Czerwonko, Jens Carsten Jackwerth, Stylianos Perrakis","American options on the S&amp;P 500 index futures that violate the stochastic dominance bounds of Constantinides and Perrakis (2007) from 1983 to 2006 are identified as potentially profitable trades. Call bid prices more frequently violate their upper bound than put bid prices do, while violations of the lower bounds by ask prices are infrequent. In out of sample tests of stochastic dominance, the writing of options that violate the upper bound increases the expected utility of any risk averse investor holding the market and cash, net of transaction costs and bid ask spreads. The results are economically significant and robust.",
Behavioralizing Finance,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1624948,06/15/2010 00:00,06/07/2024 11:04,randomForestClassifier,Hersh Shefrin,"Finance is in the midst of a paradigm shift, from a neoclassical based framework to a psychologically based framework. Behavioral finance is the application of psychology to financial decision making and financial markets. Behavioralizing finance is the process of replacing neoclassical assumptions with behavioral counterparts. This volume surveys the literature in behavioral finance, and identifies both its strengths and weaknesses. In doing so, it identifies possible directions for behavioralizing the frameworks used to study beliefs, preferences, portfolio selection, asset pricing, corporate finance, and financial market regulation. The intent is to provide a structured approach to behavioral finance in respect to underlying psychological concepts, formal framework, testable hypotheses, and empirical findings. A key theme of the volume is that the future of finance will combine realistic assumptions from behavioral finance and rigorous analysis from neoclassical finance.",
Relative Strength Strategies for Investing,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1585517,04/06/2010 00:00,06/07/2024 11:06,randomForestClassifier,Meb Faber,The purpose of this paper is to present simple quantitative methods that improve risk-adjusted returns for investing in US equity sectors and global asset class portfolios. A relative strength model is tested on the French-Fama US equity sector data back to the 1920s that results in increased absolute returns with equity-like risk. The relative strength portfolios outperform the buy and hold benchmark in approximately 70% of all years and returns are persistent across time. The addition of a trend-following parameter to dynamically hedge the portfolio decreases both volatility and drawdown. The relative strength model is then tested across a portfolio of global asset classes with supporting results.,
Sovereign Risk Premia,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1343746,02/17/2009 00:00,06/07/2024 11:05,randomForestClassifier,"Nicola Borri, Adrien Verdelhan","Emerging countries tend to default when their economic conditions worsen. If harsh economic conditions in an emerging country correspond to similar conditions for the U.S. investor, then foreign sovereign bonds are particularly risky. We explore how this mechanism impacts the data and influences a general equilibrium model of optimal borrowing and default. Empirically, the higher the correlation between past foreign bond and U.S. market returns, the higher the average sovereign excess returns.  In the model, sovereign defaults and bond prices depend not only on the borrowers' economic conditions, but also on the lenders' time-varying risk-aversion.",
The (Missing) Relation Between Announcement Returns and Value Creation,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3664087,07/31/2020 14:08,06/07/2024 11:05,randomForestClassifier,"Itzhak Ben-David, Utpal Bhattacharya, Ruidi Huang, Stacey E. Jacobsen","Acquisition announcement returns are widely considered market-based assessments of value creation. Unfortunately, the data do not support this conjecture. We show that commonly used and new measures of realized acquisition outcomes are correlated among themselves, though derived from different sources. Furthermore, these out-comes are predictable using standard information known at the announcement time. In contrast, announcement returns also measured at the announcement time-are uncorrelated with these outcomes. Importantly, announcement returns even fail to predict the predictable components of these outcomes. Overall, there is no evidence that announcement returns capture expected or realized value creation.",
Macroeconomic Risks and Characteristic-Based Factor Models,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=686983,03/25/2005 08:20,06/07/2024 11:06,randomForestClassifier,"S&ouml;hnke M. Bartram, Kevin Aretz, Peter F. Pope","We show that book-to-market, size, and momentum capture cross-sectional variation in exposures to a broad set of macroeconomic factors identified in the prior literature as potentially important for pricing equities. The factors considered include innovations in economic growth expectations, inflation, the aggregate survival probability, the term structure of interest rates, and the exchange rate. Factor mimicking portfolios constructed on the basis of book-to-market, size, and momentum therefore serve as proxy composite macroeconomic risk factors. Conditional and unconditional cross-sectional asset pricing tests indicate that most of the macroeconomic factors are priced. The performance of an asset pricing model based on the macroeconomic factors is comparable to the performance of the Fama and French (1992, 1993) model. However, the momentum factor is found to contain incremental information for asset pricing.",
Skill and Profit in Active Management,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3354074,03/25/2019 12:40,06/07/2024 11:04,randomForestClassifier,Robert F. Stambaugh,"I analyze skill’s role in active management under general equilibrium with many assets and costly trading.  More-skilled managers produce larger expected total investment profits, and their portfolio weights correlate more highly with assets' future returns.  Becoming more skilled, however, can reduce a manager's expected profit if enough other managers also become more skilled.  The greater skill allows those managers to identify profit opportunities more accurately, but active management in aggregate then corrects prices more, shrinking the profits those opportunities offer.  The latter effect can dominate in a setting consistent with numerous empirical properties of active management and stock returns.",
Inflation Hedging on Main Street? Evidence from Retail Tips Fund Flows,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4288526,11/29/2022 17:41,06/07/2024 11:05,randomForestClassifier,"Stefan Nagel, Zhen (Zach) Yan","Households participating in financial markets pay attention to inflation news when making their investment decisions, even in an environment of mostly low and stable inflation. ETFs and open-ended mutual funds holding Treasury Inflation-Protected Securities (TIPS) receive inflows from retail investors, and nominal Treasury ETF experience outflows, when long-horizon market-based inflation expectations measures increase. Changes in household survey expectations or in measures of inflation uncertainty do not contribute much in explaining retail TIPS fund flows. Retail flows into TIPS funds are asymmetric, with strong reactions only to positive inflation news, and sticky, with flow responses to news gradually playing out over several months. Retail investors appear to pay some attention to regular Federal Reserve announcements, but major events such as the ``taper tantrum&apos;&apos; in May 2013, the presidential election in November 2016, and the COVID-19 crisis in March 2020 are associated with particularly large retail TIPS fund flows.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;30692"" target=""_blank"">www.nber.org</a>.<br />",
Option-Implied Intra-Horizon Value-at-Risk,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2804702,07/06/2016 00:31,06/07/2024 11:03,randomForestClassifier,"Markus Leippold, Nikola Vasiljevic","We study the intra-horizon value at risk (iVaR) in a general jump diffusion setup and propose a new model of asset returns called displaced mixed-exponential model, which can arbitrarily closely approximate finite-activity jump-diffusions and completely monotone Levy processes. We derive analytical results for the iVaR and disentangle the risk contribution of jumps from diffusion. Estimating the iVaR for several popular jump models using on S&amp;P 100 option data, we find that option-implied estimates are much more responsive to market changes relative to their historical counterparts. Moreover, disentangling jumps from diffusion, jump account for about 90 percent of iVaR on average.",
Three Centuries of Asset Pricing,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=203109,01/11/2000 12:01,06/07/2024 11:06,randomForestClassifier,"Elroy Dimson, Massoud Mussavian","Theory on the pricing of financial assets can be traced back to Bernoulli's famous St. Petersburg paper of 1738. Since then, research into asset pricing and derivative valuation has been influenced by a couple of dozen major contributions published during the twentieth century. These seminal works have underpinned the key ideas of mean-variance optimisation, equilibrium analysis and no-arbitrage arguments. This paper presents a historical review of these important contributions to finance.",
Macro-Based Factors for the Cross-Section of Currency Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4400205,05/13/2023 03:44,06/07/2024 11:05,randomForestClassifier,"Leland Bybee, Leandro Gomes, Joao Paulo Valente","We use macroeconomic characteristics and exposures to Carry and Dollar as instruments to estimate a latent factor model with time-varying betas with the instrumented principal components analysis (IPCA) method by Kelly et al. (2020). On a pure out-of-sample basis, this model can explain up to 78% of cross-sectional variation of a Global panel of currencies excess returns, compared to only 27.9% for Dollar and Carry and 51% for a static PCA model. The latent factor and time-varying exposures are directly linked to macroeconomic fundamentals. The most relevant are exports exposures to commodities and US trade, credit over GDP, and interest rate differentials. This model, therefore, sheds light on how to incorporate macroeconomic fundamentals to explain time-series and cross-section.",
Market Efficiency and Accounting Research: A Discussion of 'Capital Market Research in Accounting' by S.P. Kothari,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=288265,11/26/2001 11:38,06/07/2024 11:05,randomForestClassifier,Charles M.C. Lee,"Much of capital market research in accounting over the past 20 years has assumed that the price adjustment process to information is instantaneous and/or trivial. This basic assumption has had an enormous influence on the way we select research topics, design empirical tests, and interpret research findings. In this discussion, I argue that price discovery is a complex process, deserving of more attention. I highlight significant problems associated with a naive view of market efficiency, and advocate a more general model involving noise traders. Finally, I discuss the implications of recent evidence against market efficiency for future capital market research in accounting.",
The Asset Price Approach to the Analysis of Capital Income Taxation,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=969313,03/08/2007 09:09,06/07/2024 11:04,randomForestClassifier,Lawrence H. Summers,"This paper summarizes my recent research directed at the development of an asset price approach to the analysis of capital income taxation. While asset prices play a crucial role in many macroeconomic models, they have been subordinate in most previous efforts to study the effects of capital income taxation on economic behavior. A number of reasons for focusing on the role of asset prices in analyzing public finance questions are discussed. These include the role of asset prices in determining investment decisions, and the fact that changes in asset prices are indicators of the horizontal and vertical equity effects of tax reforms. Recent empirical research in which asset price information is studied in order to measure the effects on economic behavior of tax reforms and to distinguish between alternative models of the effects of capital income taxation is reviewed. Directions for future research in public finance, focusing on asset markets, are also discussed.",
Equity Yields,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1931188,09/21/2011 10:15,06/07/2024 11:05,randomForestClassifier,"Jules H. van Binsbergen, Wouter Hueskes, Ralph S. J. Koijen, Evert B. Vrugt","We study a new data set of prices of traded dividends with maturities up to 10 years across three world regions: the US, Europe, and Japan. We use these asset prices to construct equity yields, analogous to bond yields. We decompose these yields to obtain a term structure of expected dividend growth rates and a term structure of risk premia, which allows us to decompose the equity risk premium by maturity. We find that both expected dividend growth rates and risk premia exhibit substantial variation over time, particularly for short maturities. In addition to predicting dividend growth, equity yields help predict other measures of economic growth such as consumption growth. We relate the dynamics of growth expectations to recent events such as the financial crisis and the earthquake in Japan.",
Systematic Liquidity,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=255116,03/21/2001 00:00,06/07/2024 11:04,randomForestClassifier,"Gur Huberman, Dominika Halka","Most of the market microstructure literature has focused on the liquidity of individual securities, whereas much of the asset pricing literature has examined the association between systematic risk and return.  We document the presence of a systematic, time-varying component of liquidity.  At the moment, neither the inventory, nor the asymmetric information-based approach to liquidity explains the systematic, time-varying component of liquidity.",
Dollar Funding and the Lending Behavior of Global Banks,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2171265,11/06/2012 20:41,06/07/2024 11:04,randomForestClassifier,"Victoria Ivashina, David S. Scharfstein, Jeremy C. Stein","A large share of dollar-denominated lending is done by non-U.S. banks, particularly European banks. We present a model in which such banks cut dollar lending more than euro lending in response to a shock to their credit quality.  Because these banks rely on wholesale dollar funding, while raising more of their euro funding through insured retail deposits, the shock leads to a greater withdrawal of dollar funding.  Banks can borrow in euros and swap into dollars to make up for the dollar shortfall, but this may lead to violations of covered interest parity (CIP) when there is limited capital to take the other side of the swap trade.  In this case, synthetic dollar borrowing becomes expensive, which causes cuts in dollar lending. We test the model in the context of the Eurozone sovereign crisis, which escalated in the second half of 2011 and resulted in U.S. money-market funds sharply reducing the funding provided to European banks. Coincident with the contraction in dollar funding, there were significant violations of euro-dollar CIP. Moreover, dollar lending by Eurozone banks fell relative to their euro lending in both the U.S. and Europe; this was not the case for U.S. global banks. Finally, European banks that were more reliant on money funds experienced bigger declines in dollar lending.",
Real Credit Cycles,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3776984,02/01/2021 06:20,06/07/2024 11:04,randomForestClassifier,"Pedro Bordalo, Nicola Gennaioli, Andrei Shleifer, Stephen Terry","We incorporate diagnostic expectations into a workhorse neoclassical business cycle model with heterogeneous firms and risky debt. A realistic degree of diagnostic overreaction estimated from US firm forecasts generates economic fragility during good times, countercyclical credit spreads, and boom-bust credit cycles at the firm and aggregate levels. Good times predict future disappointment, spread increases, low bond returns, and investment declines. To generate the size of spread increases observed during 2008-9, the model requires only disappointment of overoptimistic beliefs rather than large negative shocks. Diagnostic expectations offer a realistic, parsimonious way to produce financial reversals in business cycle models.",
"Information Shocks, Liquidity Shocks, Jumps, and Price Discovery: Evidence from the U.S. Treasury Market",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1106897,03/18/2008 00:00,06/07/2024 11:05,randomForestClassifier,"George J. Jiang, Ingrid Lo, Adrien Verdelhan","In this paper, we identify jumps in U.S. Treasury-bond (T-bond) prices and investigate what causes such unexpected large price changes. In particular, we examine the relative importance of macroeconomic news announcements versus variation in market liquidity in explaining the observed jumps in the U.S. Treasury market. We show that while jumps occur mostly at prescheduled macroeconomic announcement times, announcement surprises have limited power in explaining bond price jumps. Our analysis further shows that preannouncement liquidity shocks, such as changes in the bid-ask spread and market depth, have significant predictive power for jumps. The predictive power is significant even after controlling for information shocks. Finally, we present evidence that post-jump order flow is less informative relative to the case where there is no jump at announcement.",
The Cross-Section of Foreign Currency Risk Premia and Consumption Growth Risk,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1697648,10/25/2010 00:00,06/07/2024 11:05,randomForestClassifier,"Hanno N. Lustig, Adrien Verdelhan","Aggregate consumption growth risk explains why low interest rate currencies do not appreciate as much as the interest rate differential and why high interest rate currencies do not depreciate as much as the interest rate differential. Domestic investors earn negative excess returns on low interest rate currency portfolios and positive excess returns on high interest rate currency portfolios. Because high interest rate currencies depreciate on average when domestic consumption growth is low and low interest rate currencies appreciate under the same conditions, low interest rate currencies provide domestic investors with a hedge against domestic aggregate consumption growth risk.",
Shortfall Aversion,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2501538,09/25/2014 18:59,06/07/2024 11:04,randomForestClassifier,"Paolo Guasoni, Gur Huberman, Dan Ren","Shortfall aversion reflects the higher utility loss of a spending cut from a reference point than the utility gain from a similar spending increase, in the spirit of Prospect Theory's loss aversion. This paper posits a model of utility of spending scaled by a function of past peak spending, called target spending. The discontinuity of the marginal utility at the target spending corresponds to shortfall aversion. According to the closed-form solution of the associated spending-investment problem, (i) the spending rate is constant and equals the historical peak for relatively large values of wealth/target; and (ii) the spending rate increases (and the target with it) when that ratio reaches its model-determined upper bound. These features contrast with traditional Merton-style models which call for spending rates proportional to wealth. A simulation using the 1926-2012 realized returns suggests that spending of the very shortfall averse is typically increasing and very smooth.",
Who Holds Sovereign Debt and Why It Matters,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4114081,06/01/2022 02:43,06/07/2024 11:04,randomForestClassifier,"Xiang Fang, Bryan Hardy, Karen K. Lewis","This paper studies the impact of investor composition on the sovereign debt market. We construct an aggregate data set of sovereign debt holdings by foreign and domestic bank, non-bank private, and official investors for 95 countries over twenty years. We find that private non-bank investors absorb most of the increase in sovereign debt supply. We further find that foreign non-bank investor demand is most responsive to the yield for emerging market (EM) debt, while yield elasticity for all investors is much lower for advanced economy debt. We show that EM sovereigns are highly vulnerable to losing their foreign non-bank investors.",
Epidemics in the New Keynesian Model,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3637731,06/29/2020 14:30,06/07/2024 11:05,randomForestClassifier,"Martin Eichenbaum, Sergio T. Rebelo, Mathias Trabandt","This paper documents the behavior of key macro aggregates in the wake of the Covid epidemic. We show that a unique feature of the Covid recession is that the peak-to-trough decline is roughly the same for consumption, investment, and output. In contrast to the 2008 recession, there was only a short-lived rise in financial stress that quickly subsided. Finally, there was mild deflation between the peak and the trough of the Covid recession. We argue that a New Keynesian model that explicitly incorporates epidemic dynamics captures these qualitative features of the Covid recession. A key feature of the model is that Covid acts like a negative shock to the demand for consumption and the supply of labor.",
How Active is Your Fund Manager? A New Measure that Predicts Performance,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1468203,09/08/2009 13:02,06/07/2024 11:04,randomForestClassifier,"Martijn Cremers, Antti Petajisto","We introduce a new measure of active portfolio management, Active Share, which represents the share of portfolio holdings that differ from the benchmark index holdings. We compute Active Share for domestic equity mutual funds from 1980 to 2003. We relate Active Share to fund characteristics such as size, expenses, and turnover in the cross-section, and we also examine its evolution over time. Active Share predicts fund performance: funds with the highest Active Share significantly outperform their benchmarks, both before and after expenses, and they exhibit strong performance persistence. Nonindex funds with the lowest Active Share underperform their benchmarks.",
Does Investor Misvaluation Drive the Takeover Market?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1275877,10/06/2008 00:00,06/07/2024 11:04,randomForestClassifier,"Ming Dong, David A. Hirshleifer, Scott A. Richardson, Siew Hong Teoh","This paper uses pre-offer market valuations to evaluate the misvaluation and Q theories of takeovers. Bidder and target valuations (price-to-book, or price-to-residual-income-model-value) are related to means of payment, mode of acquisition, premia, target hostility, offer success, and bidder and target announcement-period returns. The evidence is broadly consistent with both hypotheses. The evidence for the Q hypothesis is stronger in the pre-1990 period than in the 1990-2000 period, whereas the evidence for the misvaluation hypothesis is stronger in the 1990-2000 period than in the pre-1990 period.",
The Effects of Cross-Border Bank Mergers on Bank Risk and Value,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1295263,11/04/2008 00:00,06/07/2024 11:04,randomForestClassifier,"Yakov Amihud, Gayle L. DeLong","This paper examines the effects of cross border bank mergers on the risk and (abnormal)returns of acquiring banks. We find that overall, the acquirers  risk neither increases nor decreases. In particular, on average neither their total risk nor their systematic risk fallsrelative to banks in their home banking market. The abnormal returns to acquirers arenegative and significant, but are somewhat higher when risk increases relative to banks in the acquirer s home country.",
Asset Pricing with Fading Memory,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3464500,10/07/2019 17:30,06/07/2024 11:05,randomForestClassifier,"Stefan Nagel, Zhengyang Xu","Building on evidence that lifetime experiences shape individuals' macroeconomic expectations, we study asset prices in an economy in which a representative agent learns with fading memory about unconditional mean endowment growth. With IID fundamentals, constant risk aversion, and memory decay calibrated to microdata, the model generates a high and strongly counter-cyclical objective equity premium, while the subjective equity premium is virtually constant. Consistent with this theory, experienced payout growth (a weighted average of past growth rates) is negatively related to future stock market excess returns and subjective expectations errors in surveys, and positively to analyst forecasts of long-run earnings growth.",
Measuring Agency MBS Market Liquidity with Transaction Data,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3749998,12/16/2014 13:09,06/07/2024 11:03,randomForestClassifier,"Sean D. Campbell, Canlin Li, Jay Im",Agency mortgage backed securities are fixed income securities that entitle the owner to principal and interest payments on underlying residential mortgages that are guaranteed by government-sponsored enterprises or government agencies.,
Do Funds Make More When They Trade More?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2529873,11/24/2014 08:37,06/07/2024 11:04,randomForestClassifier,"Lubos Pastor, Robert F. Stambaugh, Lucian A. Taylor","We model optimal fund turnover in the presence of time-varying profit opportunities. Our model predicts a positive relation between an active fund’s turnover and its subsequent benchmark-adjusted return. We find such a relation for equity mutual funds. This time-series relation between turnover and performance is stronger than the cross-sectional relation, as the model predicts. Also as predicted, the turnover-performance relation is stronger for funds trading less-liquid stocks, such as small-cap funds. Turnover has a common component that is positively correlated with proxies for stock mispricing, consistent with funds exploiting time-varying opportunities. Turnover’s common component helps predict fund returns.",
Presidential Politics and Stock Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2960458,04/29/2017 09:05,06/07/2024 11:06,randomForestClassifier,"Robert D. Arnott, Bradford  Cornell, Vitali Kalesnik","In a provocative paper, Santa-Clara and Valkanov (2003) present evidence that stock market returns are much higher under Democratic presidents than Republican presidents.  Their work was updated by Pastor and Veronesi (2017), who find that the effect is even stronger when the data are extended through the end of 2015.  Given the strength of the results, Pastor and Veronesi go on to develop a model based on time varying risk aversion to explain the pattern.  There is reason to suspect that the resulting linking stock market performance with presidential affiliation maybe spurious...  In particular, two key events are responsible for much of the differential return under Democratic and Republican presidents.  Specifically, the fact that Republicans were president during the two great crashes beginning in 1929 and 2008 and, not surprisingly, Democrats were president during the subsequent recoveries explains a majority of the differential.  This suggests the finding may be serendipity. To study this possibility, we turn to international data for five major countries as out-of-sample test: Australia, Canada, Germany, France and the United Kingdom.  Consistent with the suspicion that the U.S. results are spurious, we find no systematic relationship between the party in power and stock market returns.",
Four Facts About ESG Beliefs and Investor Portfolios,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4415012,04/11/2023 18:52,06/07/2024 11:06,randomForestClassifier,"Stefano Giglio, Matteo Maggiori, Johannes Stroebel, Zhenhao Tan, Stephen P. Utkus, Xiao Xu","We analyze survey data on ESG beliefs and preferences in a large panel of retail investors linked to administrative data on their investment portfolios. The survey elicits investors’ expectations of long-term ESG equity returns and asks about their motivations, if any, to invest in ESG assets. We document four facts. First, investors generally expected ESG investments to underperform the market. Between mid-2021 and late-2022, the average expected 10-year annualized return of ESG investments relative to the overall stock market was −1.4%. Second, there is substantial heterogeneity across investors in their ESG return expectations and their motives for ESG investing: 45% of survey respondents do not see any reason to invest in ESG, 25% are primarily motivated by ethical considerations, 22% are driven by climate hedging motives, and 7% are motivated by return expectations. Third, there is a link between individuals’ reported ESG investment motives and their actual investment behaviors, with the highest ESG portfolio holdings among individuals who report ethics-driven investment motives. Fourth, financial considerations matter independently of other investment motives: we find meaningful ESG holdings only for investors who expect these investments to outperform the market, even among those investors who reported that their most important ESG investment motives were ethical or hedging reasons.",
Inspecting the Mechanism of Quantitative Easing in the Euro Area,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2836353,09/09/2016 15:37,06/07/2024 11:05,randomForestClassifier,"Ralph S. J. Koijen, Francois Koulischer, Beno&icirc;t Nguyen, Motohiro Yogo","Using security-level holdings for all euro-area investors, we study portfolio rebalancing during the quantitative easing program from March 2015 to December 2017. Foreign investors outside the euro area accommodated most of the Eurosystem’s purchases. Duration, government credit, and corporate credit risk did not get concentrated in particular regions or investor sectors. We estimate a demand system for government bonds by instrumental variables to relate portfolio rebalancing to yield changes. Government bond yields decreased by 65 basis points on average, and this estimate varies from 38 to 83 basis points across countries.",
Financial Globalization and the Rise of IPOs Outside the U.S.,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2118624,07/29/2012 00:00,06/07/2024 11:03,randomForestClassifier,"Craig Doidge, George Andrew Karolyi, Ren&eacute; M. Stulz","From 1990 to 2011, the share of the world’s initial public offering (IPO) activity outside the U.S. increased with financial globalization. In the 1990s, when financial globalization was lower, there were 0.37 U.S. IPOs for each non-U.S. IPO compared to only 0.12 in the 2000s. Consistent with theoretical predictions, we find that greater financial globalization is associated with a decrease in the importance of national institutions as determinants of a country’s domestic IPO activity. One reason for this decrease is that greater financial globalization makes it easier for firms going public to access foreign capital markets and use foreign institutions. As a result, a large part of the increase in non-U.S. IPO activity occurred through an increase in global IPOs by both small and large firms. U.S. IPO activity did not benefit from increased financial globalization and, consequently, the U.S. share of world IPOs fell. It did so most dramatically for small-firm IPOs, for which its market share fell from 31% in the 1990s to 5% in the 2000s. Our evidence highlights the role of financial globalization in explaining the drop in the U.S. share but it also suggests that some of the drop is due to U.S.-specific factors.",
Treasury Inconvenience Yields During the Covid-19 Crisis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3632643,06/22/2020 22:13,06/07/2024 11:05,randomForestClassifier,"Zhiguo He, Stefan Nagel, Zhaogang Song","In sharp contrast to most previous crisis episodes, the Treasury market experienced severe stress and illiquidity during the COVID-19 crisis, raising concerns that the safe-haven status of U.S. Treasuries may be eroding. We document large shifts in Treasury ownership and temporary accumulation of Treasury and reverse repo positions on dealer balance sheets during this period. We build a dynamic equilibrium asset pricing model in which dealers subject to regulatory balance sheet constraints intermediate demand/supply shocks from habitat agents and provide repo financing to levered investors. The model predicts that Treasury inconvenience yields, measured as the spread between Treasuries and overnight-index swap rates (OIS), as well as spreads between dealers’ reverse repo and repo rates, should be highly positive during the COVID-19 crisis, which are confirmed in the data. The same model framework, adapted to the institutional setting in 2007-2009, also helps explain the negative Treasury-OIS spread observed during the Great Recession.",
Commodity Futures: A Japanese Perspective,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=924340,08/15/2006 00:00,06/07/2024 11:06,randomForestClassifier,"Gary B. Gorton, Fumio Hayashi, K. Geert Rouwenhorst","We study the basic properties of an equally-weighted index of U.S. commodity futures from the perspective of a Japanese investor. We find that the returns on the U.S. equally-weighted commodity futures index maintain their basic properties, documented in Gorton and Rouwenhorst (2005), when translated into Yen. In particular, looking at returns on Japanese stocks and bonds, the commodity futures index, translated into Yen, continues to display equity-like returns, but with slightly less volatility. In addition, the Yen-based commodity futures returns show essentially zero correlation with Japanese equities and negative correlation with bonds.",
Reimagining Index Funds,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4591461,10/31/2023 19:45,06/07/2024 11:06,randomForestClassifier,"Robert D. Arnott, Chris Brightman, Xi Liu, Que Nguyen","“Gold-standard” cap-weighted indices have a buy-high and sell-low dynamic that causes a structural long-term performance drag. Of course, relative to itself, no index can underperform, which is the reason it goes unnoticed. If we use a company’s fundamentals to choose stocks—and then cap-weights them – improves the risk-adjusted returns of gold-standard cap-weighted indices. This index, which we call Fundamental-selection Cap-weighted (FS-CW), has outperformed the most popular cap-weighted equity indices around the world over the last 30 years, while reducing risk, and with additional benefits of slightly lower turnover and transaction costs. Live results further support its merits. Building a better index fund that can earn a superior risk-adjusted return versus other cap-weighted indices is not only possible—it is a reality!",
The Wealth-Consumption Ratio,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2153454,09/28/2012 17:12,06/07/2024 11:05,randomForestClassifier,"Hanno N. Lustig, Stijn Van Nieuwerburgh, Adrien Verdelhan","We derive new estimates of total wealth, the returns on total wealth, and the wealth effect on consumption. We estimate the prices of aggregate risk from bond yields and stock returns using a no-arbitrage model. Using these risk prices, we compute total wealth as the price of a claim to aggregate consumption. We find that US households have a surprising amount of total wealth, most of it human wealth. This wealth is much less risky than stock market wealth. Events in long-term bond markets, not stock markets, drive most total wealth fluctuations. The wealth effect on consumption is small and varies over time with real interest rates.",
The Market for Crash Risk,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=334941,09/30/2002 00:00,06/07/2024 11:04,randomForestClassifier,David S. Bates,"This paper examines the equilibrium when negative stock market jumps (crashes) can occur, and investors have heterogeneous attitudes towards crash risk. The less crash-averse insure the more crash-averse through the options markets that dynamically complete the economy. The resulting equilibrium is compared with various option pricing anomalies reported in the literature: the tendency of stock index options to overpredict volatility and jump risk, the Jackwerth (2000) implicit pricing kernel puzzle, and the stochastic evolution of option prices. The specification of crash aversion is compatible with the static option pricing puzzles, while heterogeneity partially explains the dynamic puzzles. Heterogeneity also magnifies substantially the stock market impact of adverse news about fundamentals.",
Do Peso Problems Explain the Returns to the Carry Trade?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1596287,04/27/2010 00:00,06/07/2024 11:05,randomForestClassifier,"A. Craig Burnside, Martin Eichenbaum, Isaac Kleshchelski, Sergio T. Rebelo","We study the properties of the carry trade, a currency speculation strategy in which an investor borrows low-interest-rate currencies and lends high-interest-rate currencies. This strategy generates payoffs which are on average large and uncorrelated with traditional risk factors. We investigate whether these payoffs reflect a peso problem. We argue that they do. We reach this conclusion by analyzing the payoffs to the hedged carry trade, in which an investor uses currency options to protect himself from the downside risk from large, adverse movements in exchange rates",
How Real Option Disinvestment Flexibility Augments Project Npv,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=516124,03/14/2004 00:00,06/07/2024 11:04,randomForestClassifier,"Aneel Keswani, Mark B. Shackleton",In this article we show how a project's option value increases with incremental levels of investment and dis-investment flexibility. We do this by presenting two NPV and seven option pricing models in a strict sequence of increasing flexibility. We illustrate each with numerical examples and determine the maximum value that a project option could ever support. We show that managerial consideration of exit options at the time of project initiation can add value.,
Latent Variable Approach to Modelling Dependence of Credit Risks: Application to French Firms and Implications for Regulatory Capital,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=757344,07/18/2005 00:00,06/07/2024 11:06,randomForestClassifier,"Sandra Foulcher, Christian Gourieroux, Andr&eacute; Tiomo","This paper extends the analysis in Migration Correlation: Estimation Method and Application to the French Companies Rated by the Banque de France and provides a methodology for valuing dependent defaults based on the latent variable approach. This methodology underlies all models derived from the Merton's structural model and includes in particular the Basel II proposition. The latent correlation is calibrated by developing factor models that relate changes in unobservable variable to changes in a small number of economic factors. Our model exploits the relationship between the default correlation and the latent correlation throughout the joint probability of default. Using a comprehensive rating database managed by the Banque de France, we employ this relationship to calibrate latent correlations and finally to compute credit risk charges at a portfolio level.",
Illiquidity and Stock Returns II: Cross-Section and Time-Series Effects,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3139180,03/19/2018 16:41,06/07/2024 11:04,randomForestClassifier,"Yakov Amihud, Joonki Noh","Lou and Shu decompose Amihud’s illiquidity measure (ILLIQ) proposing that its component, the average of inverse dollar trading volume (IDVOL), is sufficient to explain the pricing of illiquidity. Their decomposition misses a component of ILLIQ that is related to illiquidity. We find that this component affects stock returns significantly, both in the cross-section and in time-series. We show that the ILLIQ premium is significantly positive after controlling for mispricing, sentiment, and seasonality. In addition, the aggregate market ILLIQ outperforms market IDVOL in estimating the effect of market illiquidity shocks on realized stock returns.",
Sorting Out Downside Beta,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1980614,01/06/2012 00:00,06/07/2024 11:05,randomForestClassifier,"Thierry Post, Pim van Vliet, Simon Lansdorp","This study analyzes various measures of the downside beta of stocks. Downside beta is sometimes defined and estimated in different ways. Theoretically, an approach based on the mean-semi-variance equilibrium model appears superior. Two known alternative approaches are not consistent with the basic principles of coherent risk measures and the properties of a well-behaved pricing kernel. Moreover, to achieve superior out-of-sample predictive power, it is essential to estimate the downside beta definition that follows from the theory. Using monthly stock-level data, the downside beta premium, if properly defined and estimated, is roughly four to seven percent per annum, depending on the model specification and sample period, compared with a premium of zero to three percent for regular market beta.",
Identifying Sources of Correlation in Global Equity Portfolios (September 2010),https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1708255,11/14/2010 00:00,06/07/2024 11:03,randomForestClassifier,MSCI Inc.,"With 153 factors, the Barra Global Equity Model (GEM2) provides a rich and granular view of the global equity space and the main sources of return and risk.  However, having 153 factors leads to 11,628 unique correlations/covariances between factors, which makes it a challenge for managers to assess correlations in a meaningful way.   In this Research Bulletin, we show how the correlation (covariance) information can be aggregated into groups, such as diagonal and off-diagonal blocks based on factor types. We also show an even more intuitive way to understand which factors carry the most risk by using the X-Sigma-Rho attribution framework proposed by Davis and Menchero (2010).",
"Market Volatility, Liquidity Shocks, and Stock Returns: Worldwide Evidence",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3067801,11/13/2017 08:39,06/07/2024 11:03,randomForestClassifier,"Rui Ma, Hamish D. Anderson, Ben R. Marshall","We examine the interaction between market volatility, liquidity shocks, and stock returns in 41 countries over the period 1990–2015. We find liquidity is an important channel through which market volatility affects stock returns in international markets and we show this is distinct from the direct volatility–return relation. The influence of the liquidity channel on the link between market volatility and returns is stronger in markets exhibiting higher levels of market volatility and lower trading volume. It is also stronger in countries with better governance, no short-selling constraints, and more high-frequency trading and during crisis periods.",
Political News and Stock Prices: The Case of Saddam Hussein Contracts,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1296368,11/07/2008 00:00,06/07/2024 11:04,randomForestClassifier,"Yakov Amihud, Avi Wohl","This paper studies the association between the market s expectations of Saddam Hussein's fall from power, reflected in Saddam contract prices, and stock prices, oil prices and exchange rates. During the war, a rise in the probability of Saddam's fall, which also indicated a speedy end to the war, was positively and significantly associated with stock prices, strengthened the dollar against the Euro, and lowered oil prices. Before the war, a rise in the probability of Saddam's fall, which may have also indicated the probability of a costly war breaking out, lowered stock prices, which adjustment gradually to this information.",
Extreme Risk Management,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1341363,02/12/2009 00:00,06/07/2024 11:05,randomForestClassifier,"Lisa R. Goldberg, Michael Y. Hayes, Jose Menchero, Indrajit Mitra","Quantitative risk management relies on a constellation of tools that are used to analyze portfolio risk. We develop the standard toolkit, which includes betas, risk budgets and correlations, in a general, coherent, mnemonic framework centered around marginal risk contributions. We apply these tools to generate side-by-side analyses of volatility and expected shortfall, which is a measure of average portfolio excess of value-at-risk. We focus on two examples whose importance is highlighted by the current economic crisis. By examining downside protection provided by an out-of-the-money put option we show that the diversification benefit of the option is greater for a risk measure that is more highly concentrated in the tail of the distribution. By comparing two-asset portfolios that are distinguished only by the likelihood of coincident extreme events, we show that expected shortfall measures market contagion in a way that volatility cannot.",
The Evolution of Earnings Management and Firm Valuation: A Cross-Country Analysis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=965636,02/27/2007 00:00,06/07/2024 11:05,randomForestClassifier,"Nuno Fernandes, Miguel A. Ferreira","We investigate the determinants of earnings management and its implications for firm value for more than 24,000 firms in 43 countries for the 1990-2003 period. We find that firm characteristics explain at least as much of the variation in earnings management as country characteristics, and that firm characteristics become relatively more important at the turn of the 20th century. Investment opportunities, dependence on external finance, ownership dispersion, cash holdings, and greater visibility and access to global financial markets tend to decrease earnings management, as firms adopt more rigorous standards when they can benefit the most from them. We find a link between earnings management and firm valuation: a move from the 75th to the 25th percentile of earnings management is associated with an increase in Tobin's Q of 16%. The negative relation between earnings management and firm valuation is found to be particularly strong at the turn of the 20th century and for firms with strong investment opportunities and need of external finance.",
Corporate Social Responsibility,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4267476,11/17/2022 16:30,06/07/2024 11:05,randomForestClassifier,"Harrison G. Hong, Edward P. Shore","Is shareholder interest in corporate social responsibility driven by pecuniary motives (abnormal rates of return) or non-pecuniary ones (willingness to sacrifice returns to address various firm externalities)? To answer this question, we categorize the literature into seven tests: (1) costs of capital, (2) performance of portfolios, (3) ownership by types of institutions, (4) surveys and experiments, (5) managerial motives, (6) shareholder proposals, and (7) firm inclusion in responsibility indices. These tests and the most recent proposals data predominantly indicate that shareholders are driven by non-pecuniary motives. To stimulate further research on welfare implications for global warming, we assess whether estimates of the returns shareholders are willing to sacrifice (or, 'greeniums'), along with the increasing amounts of assets pledged to firms that become sustainable, are consistent with the growth of aggregate investments in the decarbonization sector.",
FX Market Metrics: New Findings Based on Cls Bank Settlement Data,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2938706,03/22/2017 14:01,06/07/2024 16:31,randomForestClassifier,"Joel Hasbrouck, Richard M. Levich","Using a new and unique data set of foreign currency settlement instructions provided by CLS Bank, we investigate activity and liquidity in the foreign exchange market. In the major currency pairs, CLS settlement volume shares are similar to those reported in the BIS triennial surveys. They are also similar to shares computed from EBS trade data reported by Mancini, Ranaldo and Wrampelmeyer (2013) (MRW), but only for currency pairs that do not belong to the “UK Commonwealth” pairs, for which EBS coverage is limited.We estimate Amihud (2002) illiquidity ratios from CLS submissions and Olsen price records, and examine the correlations between these ratios and price impact estimates based on high frequency EBS data and reported by MRW. The correlation is 0.748, but with marginal statistical significance and only when the commonwealth pairs are excluded from the analysis. When the commonwealth pairs are included, the correlation drops to -0.130 (insignificant). We believe that, as with the volume estimates, this reflects EBS’ limited coverage of the commonwealth currency pairs. The common liquidity factor in our illiquidity ratios constructed from all major pairs is highly correlated, however, with the factor based only on non-commonwealth pairs, suggesting that liquidity factors constructed from EBS data may be good proxies for factors based on broader samples.Our data include numerical identifiers for counterparties to each trade which allows us to estimate market concentration by currency pair. We find that trading is more concentrated (across participants) in less actively traded currencies, which typically exhibit lower liquidity.",
Correlations in Price Changes and Volatility Across International Stock Markets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=886547,02/28/2006 00:00,06/07/2024 16:34,randomForestClassifier,"Yasushi Hamao, Ronald W. Masulis, Victor Ng","The short-run interdependence of prices and price volatility across three major international stock markets is studied. Daily opening and closing prices of major stock indexes for the Tokyo, London, and New York stock markets are examined. The analysis utilizes the autoregressive conditionally heteroskedastic (ARCH family of statistical models to explore these pricing relationships. Evidence of price volatility spillovers from New York to Tokyo, London to Tokyo, and New, York to London is observed but no price volatility spillover effects in other directions are found for the pre-October 1987 period.",
The Permanent Income Hypothesis and Consumption Durability: Analysis Based on Japanese Panel Data,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=321343,07/16/2004 09:27,06/07/2024 16:37,randomForestClassifier,Fumio Hayashi,"The permanent income hypothesis is tested on a four-quarter panel of about two thousand Japanese households for ten commodity groups. Consumption is a distributed lag function of expenditures, and the utility function is additively separable in time. Durability is defined as the persistence of the distributed lag. The permanent income hypothesis implies that, for each commodity group, expected change in expenditures is correlated neither with past expenditure changes on other commodities nor with expected change indisposable income, if its own lags are controlled for. The main results are the following: (1) durability is substantial even for food and services, (2)the permanent income hypothesis applies to almost all (probably more than ninety percent) of the population, and (3) the habit persistence hypothesis is rejected in favor of the permanent income hypothesis.",
Indexing and Active Fund Management: International Evidence,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1830207,05/03/2011 13:27,06/07/2024 11:04,randomForestClassifier,"Martijn Cremers, Miguel A. Ferreira, Pedro Matos, Laura T. Starks","We examine the relation between indexing and active management in the mutual fund industry worldwide. Explicit indexing and closet indexing by active funds are associated with countries’ regulatory and financial market environments. We find that actively managed funds are more active and charge lower fees when they face more competitive pressure from low-cost explicitly indexed funds. A quasi-natural experiment using the exogenous variation in indexed funds generated by the passage of pension laws supports a causal interpretation of the results. Moreover, the average alpha generated by active management is higher in countries with more explicit indexing and lower in countries with more closet indexing. Overall, our evidence suggests that explicit indexing improves competition in the mutual fund industry.",
The Relative Strength of Industries versus Countries in Global Equity Markets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2161090,10/13/2012 11:00,06/07/2024 11:05,randomForestClassifier,"Jose Menchero, Andrei Morozov","In this article, we investigate the relative strength of industry versus country effects in the global equity markets over the sample period 1994–2010. In particular, we examine three market segments: (a) the world market, (b) emerging markets, and (c) developed Europe. We employ a factor-based approach to construct portfolios that capture the ""pure"" effect of each industry or country. We define two quantities to measure the relative strength of the two effects: diversification potential and mean absolute deviation. For the world market, we find that industry and country effects are of comparable strength, although each dominates during different subperiods. In particular, countries dominated in the mid-to-late 1990s, whereas industries dominated in the aftermath of the internet bubble. For emerging markets, we find that countries have dominated industries over the entire sample period. In developed Europe, by contrast, we find that industries have dominated countries since the introduction of the euro. We also investigate the size dependency of the relative strength of industry versus country effects. In particular, we find that in the small-cap segment, industry effects become weaker whereas country effects retain their full strength.",
Empirical Asset Pricing and Statistical Power in the Presence of Weak Risk Factors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1596292,04/27/2010 00:00,06/07/2024 11:05,randomForestClassifier,A. Craig Burnside,"The risk factors in many consumption-based asset pricing models display statistically weak correlation with the returns being priced. Some GMM-based procedures used to test these models have very low power to reject proposed stochastic discount factors (SDFs) when they are mis-specified and the covariance matrix of the asset returns with the risk factors has less than full column rank. Consequently, these estimators provide potentially misleading positive assessments of the SDFs. Working with SDFs specified in terms of demeaned risk factors improves the performance of GMM but the power to reject mis-specified SDFs may remain low. Two summary tests for failure of the rank condition have reasonable power, and lead to no Type I errors in Monte Carlo experiments.",
The Common Factor in Idiosyncratic Volatility: Quantitative Asset Pricing Implications,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2430071,04/28/2014 08:57,06/07/2024 11:05,randomForestClassifier,"Bernard Herskovic, Bryan T. Kelly, Hanno N. Lustig, Stijn Van Nieuwerburgh","We show that firms’ idiosyncratic volatility obeys a strong factor structure and that shocks to the common factor in idiosyncratic volatility (CIV) are priced. Stocks in the lowest CIV-beta quintile earn average returns 5.4% per year higher than those in the highest quintile. The CIV factor helps to explain a number of asset pricing anomalies. We provide new evidence linking the CIV factor to income risk faced by households. These three facts are consistent with an incomplete markets heterogeneous-agent model. In the model, CIV is a priced state variable because an increase in idiosyncratic firm volatility raises the average household’s marginal utility. The calibrated model matches the high degree of comovement in idiosyncratic volatilities, the CIV-beta return spread, and several other asset price moments.",
What's the Value of a TBTF Guaranty? Evidence from the G-SII Designation for Insurance Companies,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2547723,01/11/2015 15:54,06/07/2024 11:04,randomForestClassifier,"Kathryn L. Dewenter, Leigh A. Riddick","We document median abnormal stock returns of 12% (U.S. $17.2 billion) for international insurance firms designated as Global Systemically Important Insurers (G-SII). These gains are associated with a fall in default probabilities, an increase in expected asset risk and an insignificant loss to creditors. Abnormal price responses for the G-SII show significant cross correlations with measures of firm risk and with country-level measures of regulatory quality. Over the same event window, identical measures for other large insurance firms show no significant average change.  These results suggest that TBTF policies improve financial stability by lowering risk for the largest and riskiest firms, but the protection still comes at some cost, despite an emphasis in current policies on curtailing the moral hazard effects of protection.",
First in the Queue: The Role of Access Privileges in Private Equity Performance,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3965747,11/18/2021 02:09,06/07/2024 11:05,randomForestClassifier,"Andrea Carnelli Domp&eacute;, Daniel Ferreira, Davide Ferri, Pedro Saffi, Bo Tang","Access privileges matter in private equity markets. Funds of funds and other financial intermediaries can create value not only by selecting, but also by being able to access, better investment opportunities. We find that access-constrained funds outperform their peers, and that limited partners with access privileges tend to re-commit to access-constrained managers. The findings suggest that access privileges play an important role in explaining value creation and limited partners’ performance persistence in private markets.",
Climate Change and Long-Run Discount Rates: Evidence from Real Estate,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2639748,08/05/2015 18:42,06/07/2024 16:33,randomForestClassifier,"Stefano Giglio, Matteo Maggiori, Krishna Rao, Johannes Stroebel, Andreas Weber","We explore what private market data can tell us about the appropriate discount rates for valuing investments in climate change abatement. We estimate the term structure of discount rates for real estate up to the very long horizons relevant for investments in climate change abatement. The housing term structure is downward-sloping, reaching 2.6% at horizons beyond 100 years. We also show that real estate is exposed to both consumption risk and climate risk. We explore the implications of these new data using a tractable asset pricing model that incorporates important features of climate change. Climate change is modeled as a rare catastrophic event, the probability of which increases with economic growth. Economic activity partially mean reverts following a climate disaster, capturing the ability of the economy to adapt. As a result, short-run cash flows are more exposed to climate risk than long-run cash flows, allowing us to match the observed housing term structure. The model and data provide simple yet powerful guidance for appropriate discount rates for investments that hedge climate disaster risk. The term structure of these discount rates is upward-sloping but bounded above by the risk-free rate. For extremely far horizons at which we do not observe the risk-free rate, the estimated long-run discount rates for housing (a risky asset) provide an upper bound that becomes tighter with maturity. This suggests that the appropriate discount rates for investments in climate change abatement are low at all horizons, substantially below those conventionally used for valuing these investments and for determining the social cost of carbon.",
Comovements in the Prices of Securities Issued by Large Complex Financial Institutions,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=724062,05/19/2005 00:00,06/07/2024 16:38,randomForestClassifier,"Christian B. Hawkesby, Ian W. Marsh, Ibrahim Stevens","In recent years, mergers, acquisitions and organic growth have meant that some of the largest and most complex financial groups have come to transcend national boundaries and traditionally defined business lines. As a result, they have become a potential channel for the cross-border and cross-market transmission of financial shocks. This paper analyses the degree of comovement in the prices of securities issued by a selected group of large complex financial institutions (LCFIs), and assesses the extent to which movements in the prices of these securities are driven by common factors. A relatively high degree of commonality is found for most LCFIs (compared with a control group of non-financials), although there are still noticeable divisions between subgroups of LCFIs, both according to geography and primary business line.",
The Asymmetry in Responsible Investing Preferences and Beliefs,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3583862,05/21/2020 16:05,06/07/2024 16:31,randomForestClassifier,"Jacquelyn Humphrey, Shimon Kogan, Jacob S. Sagi, Laura T. Starks","Empirical stylized facts in the literature concerning “sin” versus “angel” stocks display asymmetry. Through an experiment, we examine whether such biases can be micro- founded via individuals’ preferences and belief formations. We find that negative environmental and social externalities have thrice the impact of positive externalities on investment choices. Further, negative externalities modestly increase pessimism about investment prospects while positive externalities have no discernible impact. The asymmetry is pervasive, heterogeneous, and comparable to the magnitude observed in loss-aversion. Beyond rationalizing stylized empirical facts, our findings should help direct the growing theoretical literature that models the implications of non-pecuniary individual investor behavior.",
"Default, Framing and Spillover Effects:  the Case of Lifecycle Funds in 401(K) Plans",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1426459,06/30/2009 13:38,06/07/2024 16:36,randomForestClassifier,"Olivia S. Mitchell, Gary R. Mottola, Stephen P. Utkus, Takeshi Yamaguchi","Important behavioral factors such as default and framing effects are increasingly being employed to optimize decision-making in a variety of settings, including individually-directed retirement plans. Yet such approaches may have unintended ""spillover"" effects, as we show with regard to the introduction of lifecycle funds in U.S. 401(k) plans. As anticipated, lifecycle funds do reshape individual portfolio choices through large default and framing effects. But unexpectedly, they also create a new class of investors which holds these funds as part of more complex portfolios. Our results are directly relevant to those interested in retirement plan design and retirement security; they also highlight the importance of assessing such spillover effects in other consequential settings where behavioral economics techniques may be employed.",
Assessing the Probability of Bankruptcy,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=465220,12/04/2003 10:10,06/07/2024 16:32,randomForestClassifier,"Stephen A. Hillegeist, Elizabeth K. Keating, Donald P. Cram, Kyle G. Lundstedt","We assess whether two popular accounting-based measures, Altman's (1968) Z-Score and Ohlson's (1980) O-Score, effectively summarize publicly-available information about the probability of bankruptcy.   We compare the relative information content of these Scores to a market-based measure of the probability of bankruptcy that we develop based on the Black-Scholes-Merton option-pricing model, BSM-Prob. Our tests show that BSM-Prob provides significantly more information than either of the two accounting-based measures.   This finding is robust to various modifications of Z-Score and O-Score, including updating the coefficients, making industry adjustments, and decomposing them into their lagged levels and changes. We recommend that researchers use BSM-Prob instead of Z-Score and O-Score in their studies and provide the SAS code to calculate BSM-Prob.",
Monetary Policy Mistakes and the Evolution of Inflation Expectations,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1848594,05/23/2011 10:20,06/07/2024 11:06,randomForestClassifier,"Athanasios Orphanides, John C. Williams","What monetary policy framework, if adopted by the Federal Reserve, would have avoided the Great Inflation of the 1960s and 1970s? We use counterfactual simulations of an estimated model of the U.S. economy to evaluate alternative monetary policy strategies. We show that policies constructed using modern optimal control techniques aimed at stabilizing inflation, economic activity, and interest rates would have succeeded in achieving a high degree of economic stability as well as price stability only if the Federal Reserve had possessed excellent information regarding the structure of the economy or if it had acted as if it placed relatively low weight on stabilizing the real economy. Neither condition held true. We document that policymakers at the time both had an overly optimistic view of the natural rate of unemployment and put a high priority on achieving full employment. We show that in the presence of realistic informational imperfections and with an emphasis on stabilizing economic activity, an optimal control approach would have failed to keep inflation expectations well anchored, resulting in high and highly volatile inflation during the 1970s. Finally, we show that a strategy of following a robust first-difference policy rule would have been highly effective at stabilizing inflation and unemployment in the presence of informational imperfections. This robust monetary policy rule yields simulated outcomes that are close to those seen during the period of the Great Moderation starting in the mid-1980s.",
Bankruptcy Law in Latin America: Past and Future,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2332031,09/30/2013 21:37,06/07/2024 16:34,randomForestClassifier,"Aloisio Araujo, Bruno Funchal","""Bankruptcy Law in Latin America: Past and Future"" increasingly recognizes the relevance of legal and institutional structures for the functioning and development of the economy. Bankruptcy laws are a crucial element of such institutions. This paper examines the laws that govern corporate bankruptcy procedures, their effects on the economic environment, and the recent bankruptcy reforms in Latin America, with a focus on Brazil.

Firms take on debts for several reasons. They generally intend to repay these debts with their future gains, but there is always the possibility that the borrowing firms will not fulfill the repayment promise. Bankruptcy law determines what happens in such circumstances.

In the absence of a bankruptcy law, creditors have two legal procedures at their disposal. In the case of secured loans, creditors can seize the firm's assets that serve as collateral for their loans. In the case of unsecured loans, creditors can go to court asking to sell some of the firm's assets. This method of debt collection runs into difficulties when there are many creditors and the debtor'€™s assets do not cover its liabilities (that is, when the firm is insolvent). Under these conditions, each creditor will try to be the first to recover its debts. This uncoordinated race of creditors may lead to the dismantling of the firm's assets and a loss of value for all creditors. 

It is in the collective interest of creditors, and of society at large, that the disposition of the debtor's assets be carried out in an orderly way, via a centralized bankruptcy procedure. In a perfect world, there would be no need for a bankruptcy law because individuals could solve this problem through private contracts in which the debtor specified ex ante what would happen in case of default (for example, how to divide up assets and use them for debt repayment). Writing such contracts is very difficult, however. Debtors may acquire new creditors and assets after the contract is signed, and it is hard to specify how the division process should change as a function of such adjustments. Besides, contracts like this simply are not written in practice. Bankruptcy law provides a default option for this problem of contract incompleteness.

Most countries have two bankruptcy procedures: one for liquidating the assets of failing firms and another for reorganizing failing firms. Ideally, bankruptcy law should provide a good balance between liquidation and reorganization procedures. 

When a firm files for bankruptcy liquidation, the bankruptcy court appoints a trustee who shuts down the firm and sells its assets. This can involve either the sale of the whole business or its productive units or the piecemeal sale of its assets, depending on demand and on which option maximizes the value of the company's assets. The absolute priority rule determines how the proceeds of sale are divided among the claimants. It specifies what claims are paid in full according to an order defined by bankruptcy law of each country.

Reorganization is the other alternative. When capital markets are imperfect, which is very common in developing countries, the best managers may not be able to raise the necessary cash to buy the firm. The firm may therefore be inefficiently dismantled and its assets sold cheaply. Reorganization provides a good alternative for countries with weak capital markets.",
Intra-Dealer Integration,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1595442,04/25/2010 00:00,06/07/2024 16:39,randomForestClassifier,"Laurent Germain, Brian Kluger, Crina Pungulescu, David Stolin, Daniel G. Weaver","This paper examines the quotation behavior of dealers who made markets in the same stocks on both NASDAQ and either EASDAQ or the LSE. Whereas previous studies examine international integration at the market level, we examine integration at the dealer level. In other words, do dealers within the same market-making firm use information from their arm on the opposite side of the Atlantic in forming their own quotes? We find that while there is some evidence of integration at the market level, integration is hard to detect at the dealer level. The results are largely unaffected by differences in fungibility between our two samples.",
The Impact of IPOs on Stock Market Participation,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3909980,08/27/2021 06:35,06/07/2024 16:34,randomForestClassifier,"Feng Jiang, Michelle Lowry, Yiming Qian","The decrease in companies going public has received widespread attention, and the associated costs are widely debated. We document one widespread benefit of IPOs: increased stock market participation, including among people not directly associated with the heretofore private firm. Stock market participation represents a key factor toward building wealth. We find that local IPOs increase households’ propensity to own stock and their percent equity holdings. The attention channel drives effects: local IPOs attract attention to the market, through increased information production and publicity. The wealth channel has little influence, consistent with local IPOs not generating wealth shocks for most households.",
Market Liquidity -- Theory and Empirical Evidence,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2119006,07/28/2012 18:55,06/07/2024 11:04,randomForestClassifier,"Dimitri  Vayanos, Jiang Wang","In this paper we survey the theoretical and empirical literature on market liquidity. We organize both literatures around three basic questions: (a) how to measure illiquidity, (b) how illiquidity relates to underlying market imperfections and other asset characteristics, and (c) how illiquidity affects expected asset returns. Using a unified model from Vayanos and Wang  (2010), we survey theoretical work on six main imperfections: participation costs, transaction costs, asymmetric information, imperfect competition, funding constraints, and search---and for each imperfection we address the three basic questions within that model. We review the empirical literature through the lens of the theory, using the theory to both interpret existing results and suggest new tests and analysis.",
Liquidity as an Investment Style,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1675108,09/12/2010 00:00,06/07/2024 16:34,randomForestClassifier,"Zhiwu Chen, Roger G. Ibbotson, Wendy Hu","We first show that liquidity, as measured by stock turnover or trading volume, is an economically significant investment style that is distinct from traditional investment styles such as size, value/growth, and momentum. We then introduce and examine the performance of several portfolio strategies, including a Volume Weighted Strategy, an Earnings Weighted Strategy, an Earnings-Based Liquidity Strategy, and a Market Cap-Based Liquidity Strategy. Our backtest research shows that the Earnings-Based Liquidity Strategy offers the highest return and the best risk-return trade-off, while the Volume Weighted Strategy does the worst. The superior performance of the liquidity strategies are due to equilibrium, macro, and micro reasons.  In equilibrium, liquid stocks sell at a liquidity premium and illiquid stocks sell at a liquidity discount. Investing in less liquid stocks thus pays.  Second, at the macro level, the growing level of financialization of assets in the world makes today’s less liquid securities increasingly more liquid over time. Finally, at the micro level, the strategy avoids, or invests less, in popular, heavily traded glamour stocks and favors out-of-favor stocks, both of which tend to revert to more normal trading volume over time.",
Improving the Predictability of Real Economic Activity and Asset Returns with Forward Variances Inferred from Option Portfolios,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1622088,06/08/2010 00:00,06/07/2024 11:06,Manual,"Gurdip Bakshi, George Panayotov, Georgios  Skoulakis","This paper presents an option positioning that allows us to infer forward variances from option portfolios. The forward variances we construct from equity index options help to predict (i) growth in measures of real economic activity, (ii) Treasury bill returns, (iii) stock market returns, and (iv) changes in variance swap rates. Our yardstick for measuring predictive ability is both individual and joint parameter statistical significance within a market, as well as across a set of markets.",
Markov-Switching GARCH Models in R: The MSGARCH Package,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2845809,10/02/2016 21:27,06/07/2024 16:36,randomForestClassifier,"David Ardia, Keven Bluteau, Kris Boudt, Leopoldo Catania, Denis-Alexandre Trottier","We describe the package MSGARCH, which implements Markov-switching GARCH models in R with efficient C++ object-oriented programming. Markov-switching GARCH models have become popular methods to account for regime changes in the conditional variance dynamics of time series. The package MSGARCH allows the user to perform simulations as well as Maximum Likelihood and MCMC/Bayesian estimations of a very large class of Markov-switching GARCH-type models. The package also provides methods to make single-step and multi-step ahead forecasts of the complete conditional density of the variable of interest. Risk management tools to estimate conditional volatility, Value-at-Risk, and Expected-Shortfall are also available. We illustrate the broad functionality of the MSGARCH package using exchange rate and stock market return data.",
Enhancing Time Series Momentum Strategies Using Deep Neural Networks,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3369195,05/08/2019 18:37,06/07/2024 16:36,randomForestClassifier,"Bryan Lim, Stefan Zohren, Stephen Roberts","While time series momentum is a well-studied phenomenon in finance, common strategies require the explicit definition of both a trend estimator and a position sizing rule. In this paper, we introduce Deep Momentum Networks -- a hybrid approach which injects deep learning based trading rules into the volatility scaling framework of time series momentum.  The model also simultaneously learns both trend estimation and position sizing in a data-driven manner, with networks directly trained by optimising the Sharpe ratio of the signal. Backtesting on a portfolio of 88 continuous futures contracts, we demonstrate that the Sharpe-optimised LSTM improved traditional methods by more than two times in the absence of transactions costs, and continue outperforming when considering transaction costs up to 2-3 basis points. To account for more illiquid assets, we also propose a turnover regularisation term which trains the network to factor in costs at run-time.",
Equilibrium Asset Prices and Investor Behavior in the Presence of Money Illusion,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1280267,10/08/2008 00:00,06/07/2024 16:32,randomForestClassifier,"Suleyman Basak, Hongjun Yan","This article analyzes the implications of money illusion for investor behavior and asset prices in a securities market economy with inflationary fluctuations. We provide a belief-based formulation of money illusion which accounts for the systematic mistakes in evaluating real and nominal quantities. The impact of money illusion on security prices and their dynamics is demonstrated to be considerable even though its welfare cost on investors is small in typical environments. A money-illusioned investor's real consumption is shown to generally depend on the price level, and specifically to decrease in the price level. A general-equilibrium analysis in the presence of money illusion generates implications that are consistent with several empirical regularities. In particular, the real bond yields and dividend price ratios are positively related to expected inflation, the real short rate is negatively correlated with realized inflation, and money illusion may induce predictability and excess volatility in stock returns. The basic analysis is generalized to incorporate heterogeneous investors with differing degrees of illusion.",
Hedge Fund Manager Compensation Contracts During Financial Crisis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2127841,08/11/2012 00:00,06/07/2024 16:34,randomForestClassifier,"Hui Zhao, Xiaoyan Zhang, Fei Pan, Kwei Tang","During the recent financial crisis, capital flow to hedge funds plunged, and competition among hedge fund managers intensified. This leads to a transfer of bargaining power from hedge fund managers to investors when negotiating fund managers' compensation contracts. We use a signaling game theoretical model to study the optimal compensation contract design for hedge fund managers during crisis periods. Our model predicts that when bargaining power is on the investors' side, hedge fund managers are better off by lowering fees and dropping high-water mark. Using 2007-2008 hedge fund data, we find that funds which lower incentive fees and drop high-water mark provision have higher survival probabilities, attract more capital flows, and obtain higher returns. To our knowledge, our paper is the first work to focus on compensation contract design in times of crisis and our results provide important guidelines for the industry.",
Macroeconomic Models for Monetary Policy: A Critical Review from a Finance Perspective,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2899842,1/17/2017 12:52,06/07/2024 16:33,randomForestClassifier,"Winston Wei Dou, Andrew W. Lo, Ameya Muley, Harald Uhlig","We provide a critical review of macroeconomic models used for monetary policy at central banks from a finance perspective. We review the history of monetary policy modeling, survey the core monetary models used by major central banks, and construct an illustrative model for those readers who are unfamiliar with the literature. Within this framework, we highlight several important limitations of current models and methods, including the fact that local-linearization approximations omit important nonlinear dynamics, yielding biased impulse-response analysis and parameter estimates. We also propose new features for the next generation of macrofinancial policy models, including: a substantial role for a financial sector, the government balance sheet and unconventional monetary policies; heterogeneity, reallocation, and redistribution effects; the macroeconomic impact of large nonlinear risk-premium dynamics; time-varying uncertainty; financial sector and systemic risks; imperfect product market and markups; and further advances in solution, estimation, and evaluation methods for dynamic quantitative structural models.",
Procyclical Stocks Earn Higher Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4851783,6/3/2024 10:47,06/07/2024 16:34,Manual,"William N. Goetzmann, Akiko Watanabe, Masahiro Watanabe","We find that procyclical stocks, whose returns comove with business cycles, earn higher average returns than countercyclical stocks. We use almost a three-quarter century of real GDP growth expectations from economists’ surveys to determine forecasted economic states. This approach largely avoids the confounding effects of econometric forecasting model error. The loading on the expected real GDP growth rate is a priced risk measure. A fully tradable, ex-ante portfolio formed on this loading generates a procyclicality premium that is statistically significant, economically large, long-lasting over a few years, and independent of the size, book-to-market, and momentum effects.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32509"" target=""_blank"">www.nber.org</a>.<br />",
Financial Risk Measurement for Financial Risk Management,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2062717,5/19/2012 16:09,06/07/2024 16:33,randomForestClassifier,"Torben G. Andersen, Tim Bollerslev, Peter Christoffersen, Francis X. Diebold","Current practice largely follows restrictive approaches to market risk measurement, such as historical simulation or RiskMetrics. In contrast, we propose flexible methods that exploit recent developments in financial econometrics and are likely to produce more accurate risk assessments, treating both portfolio-level and asset-level analysis.  Asset-level analysis is particularly challenging because the demands of real-world risk management in financial institutions - in particular, real-time risk tracking in very high-dimensional situations - impose strict limits on model complexity.  Hence we stress powerful yet parsimonious models that are easily estimated.  In addition, we emphasize the need for deeper understanding of the links between market risk and  macroeconomic fundamentals, focusing primarily on links among equity return volatilities, real growth, and real growth volatilities.  Throughout, we strive not only to deepen our scientific understanding of market risk, but also cross-fertilize the academic and practitioner communities, promoting improved market risk measurement technologies that draw on the best of both.",
The History of the Cross Section of Stock Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2897719,1/12/2017 19:27,06/07/2024 16:35,randomForestClassifier,"Juhani T. Linnainmaa, Michael R. Roberts","Using data spanning the 20th century, we show that most accounting-based return anomalies are spurious. When examined out-of-sample by moving either backward or forward in time, anomalies' average returns decrease, and volatilities and correlations with other anomalies increase. The data-snooping problem is so severe that even the true asset pricing model is expected to be rejected when tested using in-sample data. Our results suggest that asset pricing models should be tested using out-of-sample data or, when not feasible, by whether a model is able to explain half of the in-sample alpha.",
Displacement Risk and Asset Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1898711,7/30/2011 14:54,06/07/2024 16:31,randomForestClassifier,"Nicolae Garleanu, Leonid Kogan, Stavros Panageas","We study asset-pricing implications of innovation in a general-equilibrium overlapping- generations economy. Innovation increases the competitive pressure on existing firms and workers, reducing the profits of existing firms and eroding the human capital of older workers. Due to the lack of inter-generational risk sharing, innovation creates a systematic risk factor, which we call “displacement risk.” This risk helps explain several empirical patterns, including the existence of the growth-value factor in returns, the value premium, and the high equity premium. We assess the magnitude of displacement risk using estimates of inter-cohort consumption differences across households and find support for the model.",
Hedge Fund Activists: Value Creators or Good Stock Pickers?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3614029,6/23/2020 17:54,06/07/2024 11:04,randomForestClassifier,"Martijn Cremers, Erasmo Giambona, Simone M. Sepe, Ye Wang","This paper considers two competing hypotheses for the positive abnormal stock returns of firms targeted by activist hedge funds in both the short term and the long term: are they value creators or good stock pickers? Using matching to mitigate selection effects, we find that activists’ targets do not outperform ex ante similar control firms; this suggests that activists are good stock pickers, not value creators. We also observe abnormal returns around filings disclosing material changes in activist ownership. This too supports good stock picking as the more plausible hypothesis. Overall, our evidence indicates that hedge fund activism does not seem to benefit the buy-and-hold shareholders of targeted firms.",
The Risk and Return from Factors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=95208,6/15/1998 16:15,06/07/2024 11:03,randomForestClassifier,"Josef Lakonishok, Louis K.C. Chan, Jason J. Karceski","The ability to identify which factors best capture systematic return covariation is central to applications of multifactor pricing models. This paper uses a common data set to evaluate the performance of various proposed factors in capturing return comovements. Factors associated with the market, size, past return, book-to-market and dividend yield help explain return comovement on an out-of-sample basis (although they are not necessarily associated with large premiums in average returns). Except for the default premium and the term premium, macroeconomic factors perform poorly. We document regularities in the behavior of the more important factors, and confirm their influence in the Japanese and U.K. markets as well.",
Econometric Measures of Systemic Risk in the Finance and Insurance Sectors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1648023,7/26/2010 11:19,06/07/2024 16:30,randomForestClassifier,"Monica Billio, Mila Getmansky Sherman, Andrew W. Lo, Loriana Pelizzon","We propose several econometric measures of systemic risk to capture the interconnectedness among the monthly returns of hedge funds, banks, brokers, and insurance companies based on principal components analysis and Granger-causality tests. We find that all four sectors have become highly interrelated over the past decade, increasing the level of systemic risk in the finance and insurance industries.  These measures can also identify and quantify financial crisis periods, and seem to contain predictive power for the current financial crisis.  Our results suggest that hedge funds can provide early indications of market dislocation, and systemic risk arises from a complex and dynamic network of relationships among hedge funds, banks, insurance companies, and brokers.",
Conditional Risk Premia in Currency Markets and Other Asset Classes,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2271935,5/30/2013 9:43,06/07/2024 16:38,randomForestClassifier,"Martin Lettau, Matteo Maggiori, Michael Weber","The downside risk CAPM (DR-CAPM) can price the cross section of currency returns. The market-beta differential between high and low interest rate currencies is higher conditional on bad market returns, when the market price of risk is also high, than it is conditional on good market returns. Correctly accounting for this variation is crucial for the empirical performance of the model. The DR-CAPM can jointly explain the cross section of equity, commodity, sovereign bond and currency returns, thus offering a unified risk view of these asset classes. In contrast, popular models that have been developed for a specific asset class fail to jointly price other asset classes.",
Understanding the Determinants of Analyst Target Price Forecasts,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2412813,3/23/2014 17:42,06/07/2024 16:35,randomForestClassifier,"Patricia Dechow, Haifeng You","We investigate the determinants of analysts’ target price forecasts and evaluate their relative importance for explaining the cross-sectional variation in target price implied returns. We identify four broad determinants: the informational component predictive of future stock returns, errors in forecasting fundamentals, errors in forecasting the expected return to risk, and biases relating to analysts’ incentives.  Our findings indicate that analysts have a limited ability to predict short-term future returns, and incorrect fundamental forecasts marginally impact target price valuations.  Errors in forecasting the expected return to empirical risk proxies such as beta and idiosyncratic volatility have the greatest impact and induce significant noise and optimism into target prices.  Job-related incentives induce incremental optimism in target prices. We use our target price determinants model to predict the optimistic bias in target price forecasts and evaluate whether investors correctly ignore the predictable bias. The results suggest that investors make similar valuation errors to analysts and/or do not perfectly back out the predicted bias in target prices.",
Cross-Sectional Uncertainty and the Business Cycle: Evidence from 40 Years of Options Data,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3886779,7/14/2021 15:24,06/07/2024 11:04,randomForestClassifier,"Ian Dew-Becker, Stefano Giglio","This paper presents a novel and unique measure of cross-sectional uncertainty constructed from stock options on individual firms. Cross-sectional uncertainty varied little between 1980 and 1995, and subsequently had three distinct peaks – during the tech boom, the financial crisis, and the coronavirus epidemic. Cross-sectional un- certainty has had a mixed relationship with overall economic activity, and aggregate uncertainty is much more powerful for forecasting aggregate growth. The data and moments can be used to calibrate and test structural models of the effects of uncertainty shocks. In international data, we find similar dynamics and a strong common factor in cross-sectional uncertainty.",
What's Gone Wrong with Option Liquidity: Evidence from the Knight Capital's Trading Glitch,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3517429,3/2/2020 8:16,06/07/2024 11:04,randomForestClassifier,"Nikunj Kapadia, Matthew Linn","Since the early 2000s liquidity in option markets has become less resilient, and our evidence suggests that it is so because of an increased vulnerability to liquidity shocks in the underlying. To demonstrate the causal impact, we consider an incident in which a large broker dealer erroneously executed millions of orders in the stock market.  The computer glitch increased uninformed order flow resulting in liquidity-related uncertainty in the equity market.  Option spreads of impacted stocks widened by as much as one-third while abnormal stock order flow was ongoing and remained wide until uncertainty about the glitch was resolved.  The evidence is consistent with a mechanism whereby option market makers face risk of being picked off with every revised quote in the underlying. Option market participants bear higher adverse selection costs than equity market participants, making the derivative markets fragile. <br />",
When are Contrarian Profits Due to Stock Market Overreaction?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=227214,4/27/2000 0:00,06/07/2024 11:04,randomForestClassifier,"Andrew W. Lo, A. Craig Mackinlay","The profitability of contrarian investment strategies need not be the result of stock market overreaction. Even if returns on individual securities are temporally independent, portfolio strategies that attempt to exploit return reversals may still earn positive expected profits. This is due to the effects of cross-autocovariances from which contrarian strategies inadvertently benefit. We provide an informal taxonomy of return-generating processes that yield positive [and negative] expected profits under a particular contrarian portfolio strategy, and use this taxonomy to reconcile the empirical findings of weak negative autocorrelation for returns on individual stocks with the strong positive autocorrelation of portfolio returns. We present empirical evidence against overreaction as the primary source of contrarian profits, and show the presence of important lead-lag relations across securities.",
Have Capital Market Anomalies Attenuated in the Recent Era of High Liquidity and Trading Activity?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2029057,3/27/2012 22:01,06/07/2024 16:32,randomForestClassifier,"Tarun Chordia, Avanidhar Subrahmanyam, Qing Tong","We examine whether the recent regime of increased liquidity and trading activity is associated with attenuation of prominent equity return anomalies due to increased arbitrage.  We find that the majority of the anomalies have attenuated, and the average returns from a portfolio strategy based on prominent anomalies have approximately halved after decimalization.  We provide evidence that hedge fund assets under management, short interest and aggregate share turnover have led to the decline in anomaly-based trading strategy profits in recent years.  Overall, our work indicates that policies to stimulate liquidity and ameliorate trading costs improve capital market efficiency.",
The Three-Pass Regression Filter: A New Approach to Forecasting Using Many Predictors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1868703,6/22/2011 0:00,06/07/2024 11:05,randomForestClassifier,"Bryan T. Kelly, Seth Pruitt","We forecast a single time series using many predictor variables with a new estimator called the three-pass regression filter (3PRF). It is calculated in closed form and conveniently represented as a set of ordinary least squares regressions. 3PRF forecasts converge to the infeasible best forecast when both the time dimension and cross section dimension become large. This requires only specifying the number of relevant factors driving the forecast target, regardless of the total number of common (and potentially irrelevant) factors driving the cross section of predictors. We derive inferential theory in the form of limiting distributions for estimated relevant factors, predictive coefficients and forecasts, and provide consistent standard error estimators. We explore two empirical applications that exemplify the many predictor problem: Forecasting macroeconomic aggregates with a large panel of economic indices, and forecasting stock market aggregates with many individual assets' price-dividend ratios. These, combined with a range of Monte Carlo experiments, demonstrate the 3PRF's forecasting power.",
Analysts' Use of Earnings Forecasts in Predicting Stock Returns: Forecast Horizon Effects,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1118988,4/14/2008 22:43,06/07/2024 16:39,Manual,"Sati P. Bandyopadhyay, Lawrence D. Brown, Gordon D. Richardson","Little attention has been paid to a principal decision context in which analysts' earnings forecasts are prepared, namely, as an input to their recommendations. We use two data sets, Value Line, USA, and Research Evaluation Service, Canada, and examine the importance of analysts' earnings forecasts for their stock price forecasts via three hypotheses: (1) analysts' earnings forecasts are important for their stock price forecasts; (2) analysts' long-term earnings forecasts are more important than their short-term earnings forecasts for their predictions of stock prices over a particular stock price forecast horizon; (3) the importance of analysts' earnings forecasts for their stock price forecasts rises as the joint earnings and stock price forecast horizon increases. We show that: (1) when the earnings forecast horizon is the next fiscal year, forecasted earnings explain only 30% of the variation in forecasted price; (2) the importance of forecasted earnings for forecasted price rises as the earnings forecast horizon increases; (3) in the long run, (i.e. three to five years hence), forecasted earnings explain about 60% of the variation in forecasted price. Decision usefulness is an ex ante concept, but tests regarding the usefulness of earnings for stock price generally have used actual (not expectational) data. Our evidence suggests that earnings expectations are decision useful, where the decision context is sell-side analysts' stock price forecasts. Our results are potentially important to users of sell-side analyst research reports. When a stock recommendation is accompanied only by short-run earnings forecasts, investors need to closely examine estimates of non-earnings variables to assess the quality of stock recommendations. In contrast, when stock recommendations are accompanied by both short-run and long-run earnings forecasts, investors need to examine estimates of non-earnings information variables less closely.",
Loss-Aversion and Household Portfolio Choice,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=680783,3/19/2008 0:00,06/07/2024 16:34,randomForestClassifier,"Stephen G. Dimmock, Roy Kouwenberg","In this paper we empirically test if loss-aversion affects household participation in equity markets, household allocations to equity, and household allocations between mutual funds and individual stocks. Using household survey data, we obtain direct measures of each surveyed household’s loss-aversion coefficient from questions involving hypothetical payoffs. We find that higher loss-aversion is associated with a lower probability of participation. We also find that higher loss-aversion reduces the probability of direct stockholding by significantly more than the probability of owning mutual funds. After controlling for sample selection we do not find a relationship between loss-aversion and portfolio allocations to equity.",
From Equity Premium Puzzle to Expectations Puzzle: General Equilibrium Production Economy with Stochastic Habit Formation,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1300790,11/13/2008 0:00,06/07/2024 16:31,randomForestClassifier,Qiang Dai,"This paper develops a general equilibrium model for a representative agent, production economy with stochastic internal habit formation. The model describes a scale-independent economy, with a unique stochastic investment opportunity set. Local correlation between the stochastic interest rate and time-varying market price of risk can be determined endogenously and leads to correct predictions on the sign and magnitude of several major empirical puzzles in both equity and bond markets.  In the empirical part of the paper, we calibrate our model, simultaneously, to the equity premium puzzle, the risk-free rate puzzle, and the expectations puzzle, and show that the three puzzles are completely resolved under reasonable parameter values.  Thus, we establish, conclusively, the inextricable link between the equity and bond markets, both theoretically and empirically. Our model subsumes the internal habit formation models of Sundaresan (1989) and Constantinides (1990), and, perhaps somewhat surprisingly, the external habit formation model of Campbell and Cochrane (1999).",
"Financial Service Providers, AI, Satisficing, and the Human Touch In the Market for Financial Nudges and Boosts",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3779635,3/18/2021 20:21,06/07/2024 11:04,randomForestClassifier,Hersh Shefrin,"Advances in artificial intelligence (AI) are reshaping many facets of the decision landscape faced by consumers and investors. These advances have resulted in lower fees and borrowing costs, increased access to financial services, and greater customization. In this paper, I discuss how the need for the human touch impacts the potential for digital technologies to lower the cost of providing mass customization and personalization to the broad market for wealth management. I present the cases of three financial service firms, to illustrate how the failure to account properly for the human touch can result in unsuccessful technologically-based strategies.",
Bubbles and Credit Constraints,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1779485,3/7/2011 0:00,06/07/2024 16:31,randomForestClassifier,"Jianjun Miao, Pengfei Wang","We provide an infinite-horizon model of a production economy with bubbles, in which firms meet stochastic investment opportunities and face credit constraints. Capital is not only an input for production, but also serves as collateral. We show that bubbles on this reproducible asset may arise, which relax collateral constraints and improve investment efficiency. The collapse of bubbles leads to a recession. We show that there is a credit policy that can eliminate the bubble on firm assets and can achieve the efficient allocation.",
“Safe” Annuity Retirement Products and a Possible US Retirement Crisis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4761980,2024-04-12 16:29:00,06/07/2024 16:31,randomForestClassifier,"Thomas E. Lambert, Christopher B. Tobe","This paper examines a looming possible crisis in many Americans’ retirement plans due to the proliferation of annuity products in their retirement investment portfolios.  As defined benefit pension plans have almost completely disappeared as a means of retirement savings and have been replaced by defined contribution retirement plans over the last 40 to 50 years, a great number of private and public sector defined contribution retirement plans have become laden with insurance contracts called annuities.  Of the remaining solid defined benefit plans many, through a process called Pension Risk Transfer are being converted to high-risk single entity annuities.  Such products have been sold to employers and employees as “safe” and “guaranteed’ financial instruments that that are just as good as a defined retirement benefit plan backed by Federal PBGC (Pension Benefit Guarantee Corporation) insurance.  The results of the analysis in this paper calls this into question, and with so many of these annuities having ties to investments and loans related to risky assets, the authors find that many annuity products are exposed to systemic risk that could lead to a bust in the pensions of many retirees and soon-to-be retirees.   The “Emperor has no Clothes” as the life insurance industry has poured billions of dollars into advertising, lobbying, commissions &amp; trade articles with misinformation on annuities with everyone afraid to call out the obvious fiduciary problems.   To invest in annuities one must look the other way at one of most basic investment principals -diversification, i.e., “do not put your eggs in one basket.”   Excessive monopolistic profits through secret spread fees have remained hidden with no US Federal regulation or oversight.  This paper shows the drawbacks, weaknesses, and pitfalls of annuities as investments for retirement plans as well as the injustices of such plans toward lower income workers.",
"Performance Indicators of the Digital Age: Mobile Apps, Firm Disclosure, and Stock Returns",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4851807,2024-06-05 14:14:00,06/07/2024 16:34,Manual,"Shuping Chen, Yukun Liu, Xi Wu","Mobile apps, iOS or Android apps downloadable onto smartphones and tablets, are becoming an important part of the global economy. Mobile apps can facilitate earnings generation by being the primary (or an alternative) platform of product delivery, and directly via in-app purchases or inapp advertisements. We demonstrate that mobile app download is a leading performance indicator as it significantly predicts subsequent quarter's earnings. However, the investment community does not fully understand the valuation implications of mobile apps, resulting in predictable analyst forecast errors and predictable excess returns. A long-short strategy on abnormal downloads delivers an EW (VW) annualized return of 8% (9%). Importantly, firm disclosure of mobile app information in SEC filings mitigates the predictability of analyst forecast errors and returns. Our study advances our understanding of new performance indicators of the digital economy and the role of disclosure in enhancing such understanding for the investment community.",
Factor and Idiosyncratic Var-Itô Volatility Matrix Models for Heavy-Tailed High-Frequency Financial Observations,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4767274,2024-03-21 05:17:00,06/07/2024 16:38,randomForestClassifier,"Donggyu Kim, Yazhen Wang, Jianqing Fan, Minseok Shin","This paper introduces a novel Itô diffusion process for both factor and idiosyncratic volatility matrices whose eigenvalues follow the vector auto-regressive (VAR) model. We call it the factor and idiosyncratic VAR-Itô (FIVAR-Itô) model. The FIVAR-Itô model accounts for the dynamics of the factor and idiosyncratic volatilities and includes many parameters. In addition, many empirical studies have shown that high-frequency stock returns often exhibit heavy tails. To handle these two problems simultaneously, we propose a penalized optimization procedure with a truncation scheme for parameter estimation. We apply the proposed parameter estimation procedure to predicting large volatility matrices and establish its asymptotic properties.",
"High-Frequency Liquidity in the Chinese Stock Market: Measurements, Patterns, and Determinants",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4860429,2024-06-10 23:17:00,06/11/2024 08:57,Manual,"Ruixun Zhang, Chaoyi Zhao, Yufan Chen, Lintong Wu, Yuehao Dai, Ermo Chen, Lan Wu",,
The Effects of Exchange Rate Movements on Publicly Traded US Corporations,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4811782,2024-05-10 11:22:00,06/07/2024 16:37,Manual,"Ivo Welch, Yuqing Zhou","Previous literature struggled to find strong effects of exchange-rate exposure on US stock returns. Our paper brings firm-specific export data to reinvestigate this exchange-rate puzzle and finds surprisingly large exchange-rate effects on exports, sales, profits, and stock returns.  These were not offset by (financial or operational) hedging, and they seem to have not only been due to export changes but also due to changes in the domestic competitive environment. The effects increased over time and were stronger for larger and more export-oriented firms.",
Mean-variance portfolio selection in jump-diffusion model under no-shorting constraint: A viscosity solution approach,https://arxiv.org/abs/2406.03709,,06/07/2024 11:06,randomForestClassifier,"Xiaomin Shi, Zuo Quan Xu","This paper concerns a continuous time mean-variance (MV) portfolio selection problem in a jump-diffusion financial model with no-shorting trading constraint. The problem is reduced to two subproblems: solving a stochastic linear-quadratic (LQ) control problem under control constraint, and finding a maximal point of a real function. Based on a two-dimensional fully coupled ordinary differential equation (ODE), we construct an explicit viscosity solution to the Hamilton-Jacobi-Bellman equation of the constrained LQ problem. Together with the Meyer-It\^o formula and a verification procedure, we obtain the optimal feedback controls of the constrained LQ problem and the original MV problem, which corrects the flawed results in some existing literatures. In addition, closed-form efficient portfolio and efficient frontier are derived. In the end, we present several examples where the two-dimensional ODE is decoupled.","math.OC, q-fin.MF, q-fin.PM"
Short Option Maturity Term Structures of Skewness and Excess Kurtosis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4776441,2024-04-15 19:04:00,06/07/2024 16:32,Manual,"Dilip B. Madan, King Wang","Absolute skewness and excess kurtosis are observed to increase with maturity for short maturity options in contrast to the result for the longer maturities. Lévy and Sato processes are not consistent with this behavior. Neither are additive processes obtained by arbitrary time changes and space scalings applied to an underlying Lévy process. Additive processes with bilateral gamma marginals along with separate space scalings and time changes applied to the up and down moves are observed to deliver such term structures. The two sided CGMY model with infinite variation on the up side and finite variation down deliver term structure results qualitatively similar to that of the raw data on skewness and excess kurtosis. However, this model falls short in the quantitative magnitudes for maturity elasticities of absolute skewness and excess kurtosis.",
Filled and Killed: Forecast and Realized Trading Costs Across Horizons from Global Equity and Fixed Income Portfolio Trades,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4782032,2024-04-15 20:36:00,06/07/2024 16:39,Manual,"Andrew Ang, Ananth Madhavan","We analyze trading costs across regions and asset classes using unique data on 2,022 portfolio transitions from February 2016 to December 2023 comprising over USD 3.1 trillion in trade value. We find realized portfolio trading costs are consistent with pre-trade forecasts; even relatively large and complex trades can be executed at modest cost. We use count-data models to determine the optimal trade horizon as a function of portfolio characteristics. Trade horizons are similar across equities and fixed income, and increase with trade risk, value, and complexity. These results can be used by investors to better understand the potential capacity where urgency of trading is not a key determinant, and we apply the findings to estimating the capacity and transaction costs in factor-based strategies.",
Options-driven Volatility Forecasting,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4790644,2024-04-24 13:32:00,06/07/2024 16:37,Manual,"Nikolas Michael, Mihai Cucuringu, Sam Howison","We augment the Heterogeneous Autoregressive Regression model for forecasting realized volatility, using various measurements for the daily, weekly, and monthly volatilities, in addition to other predictive features. The main focus is on novel methods for extracting volatility estimators using option price data. Firstly, we provide a dimensionality reduction method for implied volatility surfaces built under the Black--Scholes model, whereby we combine simple row-wise and column-wise decompositions of the implied volatility surface with principal component analysis. Secondly, we provide a method for extracting the implied volatility under a Heston model. This is achieved by a calibration of the Heston model while assuming that some of the model parameters remain constant. We demonstrate that these augmentations result in improved daily forecasts for realized volatility in a selection of different stocks. These volatility forecasts, can be also be utilized to further increase predictive performance for the realized volatility of other instruments, and can be combined to provide accurate forecasts for VIX.",
Stock Option Incentives and Firm Performance *,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4852362,2024-06-05 20:30:00,06/07/2024 16:32,Manual,"Stephen Brown, Stephen A. Hillegeist","This paper analyzes the performance consequences of employee stock options for a broad sample of firms during the period 1996-1999. Our tests are performed separately for the top-5 executives and all other employees. We estimate the expected level of option incentives based on each firm's economic characteristics. We examine the association between the unexpected level of option incentives and firm performance as measured by future abnormal returns, future return on assets, and current and future firm value (Tobin's Q). We find consistent evidence that firms with unexpectedly high levels of option incentives exhibit significantly higher levels of firm performance. The results hold for both Executives and Employees and are consistent across each of our three measures of firm performance.",
The Flipside of Financial Innovation: Why Contracts Fail,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730746,2024-03-16 23:59:00,06/07/2024 11:06,Manual,"Rajkumar Janardanan, Xiao Qiao, K. Geert Rouwenhorst","We examine factors that predict the success and failure of financial innovations using a novel comprehensive database, which contains surviving and defunct commodity futures contracts traded on 28 exchanges between 1871 and 2022. New innovations are more likely to fail if they do not sufficiently compensate investors for risk, or if they experience extreme returns. Contracts are also less likely to succeed if they face significant competitive pressure from other products or exchanges. Sometimes, innovations fail because they experience systemic shocks such as wars, economic recessions and financial crises.",
CentraleSupélec Seminar - How do we use LLMs for predicting the equity market?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4790166,2024-04-16 17:42:00,06/07/2024 11:04,Manual,"Baptiste Lefort, Eric Benhamou",Slides used for the CentraleSupélec seminar. We briefly presented how LLMs can be a valuable tool for investment on the financial markets.,
Convex ordering for stochastic control: the swing contracts case,https://arxiv.org/abs/2406.07464,,06/12/2024 09:24,randomForestClassifier,"Gilles Pag\`es, Christian Yeo","We investigate propagation of convexity and convex ordering on a typical stochastic optimal control problem, namely the pricing of \q{\emph{Take-or-Pay}} swing option, a financial derivative product commonly traded on energy markets. The dynamics of the underlying asset is modelled by an \emph{ARCH} model with convex coefficients. We prove that the value function associated to the stochastic optimal control problem is a convex function of the underlying asset price. We also introduce a domination criterion offering insights into the monotonicity of the value function with respect to parameters of the underlying \emph{ARCH} coefficients. We particularly focus on the one-dimensional setting where, by means of Stein's formula and regularization techniques, we show that the convexity assumption for the \emph{ARCH} coefficients can be relaxed with a semi-convexity assumption. To validate the results presented in this paper, we also conduct numerical illustrations.",q-fin.MF
Ponzi Funds,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4836527,2024-05-20 18:35:00,05/20/2024 18:35,Manual,"Philippe van der Beck, Jean-Philippe  Bouchaud, Dario Villamaina",,
A Profitable Day Trading Strategy For The U.S. Equity Market,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4729284,2024-03-15 11:15:00,06/07/2024 11:06,randomForestClassifier,"Carlo Zarattini, Andrea Barbon, Andrew Aziz","The validity of day trading as a long-term consistent and uncorrelated source of income for traders and investors is a matter of debate. In this paper, we endeavored to answer this question by conducting a thorough analysis of the profitability of Opening Range Breakout (ORB) strategies, with a particular focus on the 5-minute ORB. Using a large dataset that covered more than 7,000 US stocks traded from 2016 to 2023, the research aimed to assess how eﬀective this strategy was in producing consistent and uncorrelated returns. A new aspect of our study was the focus on Stocks in Play, which are stocks that show higher than normal trading activity on a specific day, mostly because of fundamental news about the company. Our results showed a significant benefit in limiting day trading only to those Stocks in Play (even after considering transaction costs). A portfolio that consisted of the top 20 Stocks in Play achieved a total net performance of over 1,600%, with a Sharpe ratio of 2.81, and an annualized alpha of 36%. Passive exposure in the S&amp;P 500 would have achieved a total return of 198% during the same period. Furthermore, this paper expanded the analysis to compare the return profile of the ORB strategy applied to diﬀerent time frames, such as 15, 30, and 60 minutes. In the last part of the paper, we presented detailed stock-specific statistics for the 25 best and worst performers of an ORB strategy over all the time frames. <br /><br />To the best of our knowledge, this is the first public paper with such intraday granularity and comprehensive stock-level database.",
Volatility Targeting Is Trendy: How Trend Following Explains Alpha in Volatility-Managed Strategies,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4773781,2024-04-15 18:38:00,06/07/2024 16:32,Manual,"Benjamin Hood, Cameron Raughtigan","Why do volatility targeting/management strategies tend to outperform simple buy-and-hold positions in the same assets, as found by Moreira and Muir (2017) and Harvey et al (2018)? We test the hypothesis that this outperformance is mainly due to a loading on trend following that arises because of the negative correlation between return direction (trend) and magnitude (volatility), the so-called “leverage effect.” When controlling for trend exposure, alpha to volatility targeting is shown to mainly accrue to trend for both a long equity history and a set of 14 global equity index futures contracts. By contrast, this is not true for commodity, fixed income, or currency futures, where the leverage effect is not present. We further discuss the mechanical relationship between volatility targeting and trend following, creating a point of connection between these two seemingly different branches of research.",
Combining VPFs and Tax-Aware Strategies to Diversify Low-Basis Stock,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4750627,2024-04-05 15:35:00,06/07/2024 16:35,randomForestClassifier,"Joseph Liberman, Nathan Sosner","We illustrate how combining VPFs with tax-aware strategies can help diversify low-basis stock and thereby improve after-tax wealth accumulation. We find that direct-indexing strategies have limited ability to offset VPF settlement gains. Thus, in the context of a VPF transaction, direct indexing adds value only when managed at a very low cost. Tax-aware long-short factor strategies offer two advantages over direct indexing. First, they can outperform a passive index before tax. Second, they realize significantly higher net losses than direct-indexing strategies, allowing the investor to offset a larger fraction of the VPF settlement gain. As a result, long-run after-tax wealth outcomes are significantly better when a VPF is combined with tax-aware long-short factor strategies rather than with other alternatives, such as a direct-indexing strategy or a market index fund.",
Equity Premium Events,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4773692,2024-04-08 18:35:00,06/07/2024 16:31,Manual,"Benjamin Knox, Juan M. Londono, Mehrdad Samadi, Annette Vissing-Jorgensen","We develop a methodology to determine which days are “equity premium events”: events with significantly elevated equity premia relative to the daily equity term structure. To do so, we use recently available daily S&amp;P 500 option expirations and forward analogs of the Martin (2017) and Tetlock (2023) measures of the equity premium. We use a data-driven approach to identify events that are significantly priced by equity markets without taking a stance on what those events are. Important events include a variety of economic and political events. In the cross-section of macroeconomic releases, FOMC, CPI, and nonfarm payrolls have the largest abnormal equity premia, which increase substantially between June 2022 and June 2023. However, the elevated equity premia on macroeconomic release days are quantitatively far from explaining the large realized excess returns documented in previous work, suggesting a role for unexpectedly good news. To provide intuition for the variation in event equity premia across announcement types and time, we propose an asset pricing framework that decomposes the equity premium for a given macroeconomic release into components due to news variance and the sensitivities of the stock market and the SDF to the news released.",
Levering Up to Do Good: Direct Long-Short Investing and Charitable Giving,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4804911,2024-04-25 18:08:00,06/07/2024 16:35,Manual,"Stanley Krasner, Joseph Liberman, Nathan Sosner, Sydney Brenner","We use historical strategy simulations to evaluate the advantages of donating appreciated stock in the context of tax-aware long-short factor strategies. Our main findings are as follows. First, long-short strategies have a higher donation capacity than long-only investments, and their donation capacity increases with leverage. Second, long-short strategies have a higher donation efficiency than long-only investments. Similar to donation capacity, donation efficiency increases with leverage. Third, long-short strategies receive a larger loss-realization boost from donation of appreciated stocks than long-only investments, which also increases with leverage. Fourth, by removing appreciated positions from the strategy portfolio, higher donation targets reduce the tax costs of modifying the long-short strategy, for example, transitioning it to a long-only portfolio. Finally, when stock donations are done without replenishment, long-short portfolios offer pre-tax and after-tax performance that is far superior to that of long-only investment. Here too, pre-tax and after-tax value achieved with long-short investments increases with leverage.",
Most claimed statistical findings in cross-sectional return predictability are likely true,https://arxiv.org/abs/2206.15365,,06/11/2024 09:02,Manual,Andrew Y. Chen,"I develop simple and intuitive bounds for the false discovery rate (FDR) in cross-sectional return predictability publications. The bounds can be calculated by plugging in summary statistics from previous papers and reliably bound the FDR in simulations that closely mimic cross-predictor correlations. Most bounds find that at least 75% of findings are true. The tightest bound finds that at least 91% of findings are true. Surprisingly, the estimates in Harvey, Liu, and Zhu (2016) imply a similar FDR. I explain how Harvey et al.'s conclusion that most findings are false stems from misinterpreting ``insignificant factor'' as ``false discovery.''",q-fin.GN
Forecasting International Stock Market Variances,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4831547,2024-05-17 15:01:00,06/07/2024 16:32,Manual,"Geert Bekaert, Nancy R. Xu, Tiange Ye","We examine 320 different forecasting models for international monthly stock return volatilities, using high frequency realized variances and the implied option variance as the predictor variables. We evaluate linear and non-linear models, and logarithmic transformed and weighted least squares estimation approaches. A logarithmically transformed Corsi (2009) model combined with the option implied variance (“lm4 log”) is robustly, across countries and time, among the best forecasting models. It also survives tests using panel models and international variables. When alternative models (such as models including negative returns) have better performance, the forecasts they generate are extremely highly correlated with those of the “lm4 log” model.",
Sensitivity Assessing to Data Volume for forecasting: introducing similarity methods as a suitable one in Feature selection methods,https://arxiv.org/abs/2406.04390,,06/10/2024 09:02,Manual,Mahdi Goldani Soraya Asadi Tirvan,"In predictive modeling, overfitting poses a significant risk, particularly when the feature count surpasses the number of observations, a common scenario in high-dimensional data sets. To mitigate this risk, feature selection is employed to enhance model generalizability by reducing the dimensionality of the data. This study focuses on evaluating the stability of feature selection techniques with respect to varying data volumes, particularly employing time series similarity methods. Utilizing a comprehensive dataset that includes the closing, opening, high, and low prices of stocks from 100 high-income companies listed in the Fortune Global 500, this research compares several feature selection methods including variance thresholds, edit distance, and Hausdorff distance metrics. The aim is to identify methods that show minimal sensitivity to the quantity of data, ensuring robustness and reliability in predictions, which is crucial for financial forecasting. Results indicate that among the tested feature selection strategies, the variance method, edit distance, and Hausdorff methods exhibit the least sensitivity to changes in data volume. These methods therefore provide a dependable approach to reducing feature space without significantly compromising the predictive accuracy. This study not only highlights the effectiveness of time series similarity methods in feature selection but also underlines their potential in applications involving fluctuating datasets, such as financial markets or dynamic economic conditions. The findings advocate for their use as principal methods for robust feature selection in predictive analytics frameworks.","econ.GN, q-fin.EC"
Earnings Management and Economic Conditions,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4850552,2024-06-04 17:43:00,06/07/2024 16:32,Manual,"Stephen A. Hillegeist, An-Ping Lin","We examine whether economic conditions are associated with firms' earnings management decisions as well as the strength of incentives to manage earnings. We expect economic conditions affect both the benefits and costs of engaging in earnings management, and thus, potentially explain time-series variation in earnings management. We find incomeincreasing earnings management activities are negatively associated with real GDP growth, especially during periods when economic conditions are worsening (i.e., declining economic growth rates). Our counter-cyclical earnings management results are robust to using multiple measures of earnings management and economic conditions. In addition, we find earnings management incentives related to earnings smoothing, equity financing, market reactions to earnings surprises, and CEO turnover vary with economic conditions in ways that are consistent with how earnings management varies with economic conditions. Overall, firms' earnings management activities vary counter-cyclically with economic growth, as do their internal and external incentives to manage earnings.",
Mosaics of Predictability,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4853767,2024-06-06 21:05:00,06/07/2024 16:34,Manual,"Lin William Cong, Guanhao Feng, Jingyu He, Yuanzhi Wang","Existing studies on asset return predictability focus on aggregate performance. We examine the often-overlooked heterogeneity in return predictability across different assets and macroeconomic regimes. A novel tree-based asset clustering methodology is introduced to partition the panel of asset-return observations according to return predictability, using high-dimensional asset characteristics and aggregate time-series predictors. When implemented on U.S. equities over the past five decades, we find that some characteristics-managed (unexpected earnings, earnings-to-price, and cashflow-to-price) and/or macro-based (term spread and net equity issuance) clusters are more predictable, resulting in a heterogeneous predictive model with outperformance. Finally, it is revealed that less predictable clusters exhibit lower risk-adjusted investment performance, highlighting the empirical link between return predictability and trading profitability.",
One Factor to Bind the Cross-Section of Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4791496,2024-04-16 17:52:00,06/07/2024 16:34,Manual,"Nicola Borri, Denis Chetverikov, Yukun Liu, Aleh Tsyvinski","We propose a new non-linear single-factor asset pricing model. Despite its parsimony, this model represents exactly any non-linear model with an arbitrary number of factors and loadings – a consequence of the Kolmogorov-Arnold representation theorem. It features only one pricing component, comprising a nonparametric link function of the time-dependent factor and factor loading that we jointly estimate with sieve-based estimators. Using 171 assets across major classes, our model delivers superior cross-sectional performance with a low-dimensional approximation of the link function. Most known finance and macro factors become insignificant controlling for our single-factor.",
The Pre-FOMC Drift and the Secular Decline in Long-Term Interest Rates,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4764451,2024-04-12 16:59:00,06/07/2024 11:03,Manual,"Qing Peng, Jun Pan","We document positive and significant returns on long-term U.S. Treasury bonds on the day before the FOMC announcements and attribute this pre-FOMC drift to the premium for heightened uncertainty. Unlike the pre-FOMC drift in U.S. equity, which is realized mostly on the day of the FOMC announcement, the pre-FOMC drift in long-term bond occurs earlier. On the day before the FOMC announcement, the 10-year bond yield drops by a significant 0.68 bps and contributes importantly to the secular decline in interest rates documented by Hillenbrand (2021). Unique to the day before the FOMC is a severe disconnect between the long- and short-term yields – an indication that the pre-FOMC pricing of long-term bonds is dominated by the risk-premium channel, not the monetary-policy decision on the target rate. We further capture the pre-FOMC heightened uncertainty using the ex-ante Macro Attention Index (MAI) of Fisher et al. (2022). Conditioning on above-median MAI on unemployment rates, the pre-FOMC reduction in 10-year yield increase significantly to 1.50 bps and is predictive of the subsequent pre-FOMC drift in equity. We further find a strong and positive relation between the pre-FOMC reduction in 10-year yield and the ratio of dissent among the FOMC committee.",
Optimization of the Generalized Covariance Estimator in Noncausal Processes,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4804375,2024-04-25 19:51:00,06/07/2024 16:39,Manual,"Gianluca Cubadda, Francesco Giancaterini, Alain Hecq, Joann Jasiak","This paper investigates the performance of routinely used optimization algorithms in application to the Generalized Covariance estimator (GCov) for univariate and multivariate mixed causal and noncausal models. The GCov is a semi-parametric estimator with an objective function based on nonlinear autocovariances to identify causal and noncausal orders. When the number and type of nonlinear autocovariances included in the objective function are insufficient/inadequate, or the error density is too close to the Gaussian, identification issues can arise. These issues result in local minima in the objective function, which correspond to parameter values associated with incorrect causal and noncausal orders. Then, depending on the starting point and the optimization algorithm employed, the algorithm can converge to a local minimum. The paper proposes the Simulated Annealing (SA) optimization algorithm as an alternative to conventional numerical optimization methods. The results demonstrate that SA performs well in its application to mixed causal and noncausal models, successfully eliminating the effects of local minima. The proposed approach is illustrated by an empirical study of a bivariate series of commodity prices.",
Model Aggregation for Risk Evaluation and Robust Optimization,https://arxiv.org/abs/2201.06370,,06/11/2024 09:02,Manual,"Tiantian Mao, Ruodu Wang, Qinyu Wu","We introduce a new approach for prudent risk evaluation based on stochastic dominance, which will be called the model aggregation (MA) approach. In contrast to the classic worst-case risk (WR) approach, the MA approach produces not only a robust value of risk evaluation but also a robust distributional model, independent of any specific risk measure. The MA risk evaluation can be computed through explicit formulas in the lattice theory of stochastic dominance, and under some standard assumptions, the MA robust optimization admits a convex-program reformulation. The MA approach for Wasserstein and mean-variance uncertainty sets admits explicit formulas for the obtained robust models. Via an equivalence property between the MA and the WR approaches, new axiomatic characterizations are obtained for the Value-at-Risk (VaR) and the Expected Shortfall (ES, also known as CVaR). The new approach is illustrated with various risk measures and examples from portfolio optimization.",q-fin.RM
Equity Premium Income ETFs: How much income do you get to keep after taxes?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4814195,2024-05-01 19:40:00,06/07/2024 16:32,Manual,"Paul Bouchey, Benjamin Hood, Michael Zaslavsky","Equity premium income ETFs focus on dividends and call writing to enhance the cash flows produced by the portfolio. However, not all equity premium income ETFs are taxed the same and many of these funds were designed with nontaxable retirement accounts in mind. Taxable investors should understand how the fund is structured and how the distributions are taxed before investing in these funds. The good news is that fund managers have tools at their disposal that can make these funds more tax efficient.",
“Safe” Annuity Retirement Products and a Possible US Retirement Crisis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4763269,2024-04-12 16:51:00,06/07/2024 16:31,randomForestClassifier,"Thomas E. Lambert, Christopher B. Tobe","[entAbstract<br />	This paper examines a looming possible crisis in many Americans’ retirement plans due to the proliferation of annuity products in their retirement investment portfolios.  As defined benefit pension plans have almost completely disappeared as a means of retirement savings and have been replaced by defined contribution retirement plans over the last 40 to 50 years, a great number of private and public sector defined contribution retirement plans have become laden with insurance contracts called annuities.  Of the remaining solid defined benefit plans many, through a process called Pension Risk Transfer are being converted to high-risk single entity annuities.  Such products have been sold to employers and employees as “safe” and “guaranteed’ financial instruments that that are just as good as a defined retirement benefit plan backed by Federal PBGC (Pension Benefit Guarantee Corporation) insurance.  The results of the analysis in this paper calls this into question, and with so many of these annuities having ties to investments and loans related to risky assets, the authors find that many annuity products are exposed to systemic risk that could lead to a bust in the pensions of many retirees and soon-to-be retirees.   The “Emperor has no Clothes” as the life insurance industry has poured billions of dollars into advertising, lobbying, commissions &amp; trade articles with misinformation on annuities with everyone afraid to call out the obvious fiduciary problems.   To invest in annuities one must look the other way at one of most basic investment principals -diversification, i.e., “do not put your eggs in one basket.”   Excessive monopolistic profits through secret spread fees have remained hidden with no US Federal regulation or oversight.  This paper shows the drawbacks, weaknesses, and pitfalls of annuities as investments for retirement plans as well as the injustices of such plans toward lower income workers.  <br />Keywords: annuities, financialization, monopoly capital, pensions, retirement, risky assets, systemic risk.",
Can market volumes reveal traders' rationality and a new risk premium?,https://arxiv.org/abs/2406.05854,,06/11/2024 09:02,Manual,"Francesca Mariani, Maria Cristina Recchioni, Tai-Ho Wang, Roberto Giacalone","An empirical analysis, suggested by optimal Merton dynamics, reveals some unexpected features of asset volumes. These features are connected to traders' belief and risk aversion. This paper proposes a trading strategy model in the optimal Merton framework that is representative of the collective behavior of heterogeneous rational traders. This model allows for the estimation of the average risk aversion of traders acting on a specific risky asset, while revealing the existence of a price of risk closely related to market price of risk and volume rate. The empirical analysis, conducted on real data, confirms the validity of the proposed model.",q-fin.TR
"Will Southeast Asia be the next global manufacturing hub? A multiway cointegration, causality, and dynamic connectedness analyses on factors influencing offshore decisions",https://arxiv.org/abs/2406.07525,,06/12/2024 09:24,randomForestClassifier,"Haibo Wang, Lutfu S. Sua, Jun Huang, Jaime Ortiz, Bahram Alidaee","The COVID-19 pandemic has compelled multinational corporations to diversify their global supply chain risk and to relocate their factories to Southeast Asian countries beyond China. Such recent phenomena provide a good opportunity to understand the factors that influenced offshore decisions in the last two decades. We propose a new conceptual framework based on econometric approaches to examine the relationships between these factors. Firstly, the Vector Auto Regression (VAR) for multi-way cointegration analysis by a Johansen test as well as the embedding Granger causality analysis to examine offshore decisions--innovation, technology readiness, infrastructure, foreign direct investment (FDI), and intermediate imports. Secondly, a Quantile Vector Autoregressive (QVAR) model is used to assess the dynamic connectedness among Southeast Asian countries based on the offshore factors. This study explores a system-wide experiment to evaluate the spillover effects of offshore decisions. It reports a comprehensive analysis using time-series data collected from the World Bank. The results of the cointegration, causality, and dynamic connectedness analyses show that a subset of Southeast Asian countries have spillover effects on each other. These countries present a multi-way cointegration and dynamic connectedness relationship. The study contributes to policymaking by providing a data-driven innovative approach through a new conceptual framework.","econ.GN, q-fin.EC, stat.AP"
"Creative Destruction, Stock Return Volatility, and the Number of Listed Firms",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4854349,2024-06-05 11:58:00,06/07/2024 16:33,Manual,"S&ouml;hnke M. Bartram, Gregory W. Brown, Ren&eacute; M. Stulz","Average idiosyncratic volatility and firm idiosyncratic volatility increase with the number of listed firms. Average industry idiosyncratic volatility increases with the number of listed firms in the industry. We explain the relation between idiosyncratic volatility and the number of listed firms through Schumpeterian creative destruction. We show that Schumpeterian creative destruction increases as the number of listed firms increases. However, there is no consistent evidence of an incremental effect of the number of non-listed firms on idiosyncratic volatility either in the aggregate or at the industry level, suggesting that listed firms play a unique role in the dynamism of the economy.",
Mixing Financial Stress with GPT-4 News Sentiment Analysis for Optimal Risk-On/Risk-Off Decisions,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4781752,2024-04-15 20:06:00,06/07/2024 11:04,Manual,"Baptiste Lefort, Eric Benhamou, Jean-Jacques Ohana, David Saltiel, Beatrice Guez, Thomas Jacquot","This paper introduces a new risk-on risk-off strategy for the stock market, which combines a financial stress indicator with a sentiment analysis done by ChatGPT reading and interpreting Bloomberg daily market summaries. Forecasts of market stress derived from volatility and credit spreads are enhanced when combined with the financial news sentiment derived from GPT4. As a result, the strategy shows improved performance, evidenced by higher Sharpe ratio and reduced maximum drawdowns. The improved performance is consistent across the NASDAQ, the S&amp;P 500 and the six major equity markets, indicating that the method generalises across equities markets.",
Passive Investing and the Rise of Mega-Firms,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4851266,2024-06-03 20:03:00,06/07/2024 16:32,Manual,"Hao Jiang, Dimitri  Vayanos, Lu Zheng","We study how passive investing affects asset prices. Flows into passive funds raise disproportionately the stock prices of the economy's largest firms, and especially those large firms that the market overvalues. These effects are sufficiently strong to cause the aggregate market to rise even when flows are entirely due to investors switching from active to passive. Our results arise because flows create idiosyncratic volatility for large firms, which discourages investors from correcting the flows' effects on prices. Consistent with our theory, the largest firms in the S&amp;P500 experience the highest returns and increases in volatility following flows into that index.",
Better Opt Out: Revisiting the Predictive Power of Options-implied Signals,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4766424,2024-04-26 16:33:00,06/07/2024 11:05,Manual,"Iman Honarvar, Clint Howard","This study critically examines the assumption that options-implied signals robustly predict stock returns. We revisit thirteen such signals, as suggested by prior research, for their ability to forecast monthly cross-sectional stock returns. Although these signals robustly predict returns from 1996 to 2008, we find a marked decline in performance thereafter. Furthermore, we identify a look-ahead bias in the construction of these signals, arising from the use of non-synchronous options and stock price data. Correcting for this bias by lagging the options data substantially reduces the signals' predictive ability, even before 2008. These findings question the efficacy of options-implied implication in forecasting monthly stock returns and the robustness of trading strategies predicated on this information.",
Are the Hedges of Funds Green?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4773780,2024-04-15 18:38:00,06/07/2024 16:30,randomForestClassifier,"Tianyi Qu, Bing Liang, Mila Getmansky Sherman, Huan Kuang","Hedge funds have become greener over the past decade. In this study, we construct a return-based method to measure hedge fund greenness and find that funds with higher green beta not only outperform other funds but also exhibit lower risk. This outperformance is driven by fund managers’ superior investment skill in both green stock picking and green factor timing. Furthermore, we document that investors reward green funds with higher inflows after the 2015 Paris Agreement, but only within high-performance funds. Finally, we show that political beliefs, climate news sentiment, and participation in the United Nations Principles for Responsible Investment (PRI) all influence hedge funds’ exposure to sustainable investing and investor flows.",
What Hundreds of Economic News Events Say About Belief Overreaction in the Stock Market,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4787392,2024-04-08 12:46:00,06/07/2024 16:38,randomForestClassifier,"Francesco Bianchi, Sydney C. Ludvigson, Sai Ma","We measure the nature and severity of a variety of belief distortions in market reactions to hundreds of economic news events using a new methodology that synthesizes estimation of a structural asset pricing model with algorithmic machine learning to quantify bias. We estimate that investors systematically overreact to perceptions about multiple fundamental shocks in a macro-dynamic system, generating asymmetric compositional effects when several counteracting shocks occur simultaneously in real-world events. We show that belief overreaction to all shocks can lead the market to over- or underreact to events, amplifying or dampening volatility.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32301"" target=""_blank"">www.nber.org</a>.<br />",
Predicting Individual Corporate Bond Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4753422,2024-04-06 13:01:00,06/07/2024 16:34,randomForestClassifier,"Guanhao Feng, Xin He, Yanchu Wang, Chunchi Wu","This paper documents substantial evidence of return predictability and investment gains for individual corporate bonds via machine learning. The forecast-implied long-short and market-timing strategies deliver significant risk-adjusted returns over transaction costs. Random Forest has the best performance as the ensemble of regression trees helps reduce overfitting. Using a long-span sample from 1976 to 2020, we can evaluate return predictability over business cycles and find aggregate predictors (e.g., corporate bond market return and TERM factor) that show nonnegligible forecasting power orthogonal to bond characteristics. Finally, we find return predictability differs between bonds issued by private and public firms, with higher investment gains in private bonds.",
A Multi-step Approach for Minimizing Risk in Decentralized Exchanges,https://arxiv.org/abs/2406.07200,,06/12/2024 09:24,randomForestClassifier,"Daniele Maria Di Nosse, Federico Gatta","Decentralized Exchanges are becoming even more predominant in today's finance. Driven by the need to study this phenomenon from an academic perspective, the SIAG/FME Code Quest 2023 was announced. Specifically, participating teams were asked to implement, in Python, the basic functions of an Automated Market Maker and a liquidity provision strategy in an Automated Market Maker to minimize the Conditional Value at Risk, a critical measure of investment risk. As the competition's winning team, we highlight our approach in this work. In particular, as the dependence of the final return on the initial wealth distribution is highly non-linear, we cannot use standard ad-hoc approaches. Additionally, classical minimization techniques would require a significant computational load due to the cost of the target function. For these reasons, we propose a three-step approach. In the first step, the target function is approximated by a Kernel Ridge Regression. Then, the approximating function is minimized. In the final step, the previously discovered minimum is utilized as the starting point for directly optimizing the desired target function. By using this procedure, we can both reduce the computational complexity and increase the accuracy of the solution. Finally, the overall computational load is further reduced thanks to an algorithmic trick concerning the returns simulation and the usage of Cython.","q-fin.PM, q-fin.RM"
Dynamic Asset Pricing in a Unified Bachelier-Black-Scholes-Merton Model,https://arxiv.org/abs/2405.12479,,06/11/2024 09:02,Manual,"W. Brent Lindquist, Svetlozar T. Rachev, Jagdish Gnawali, Frank J. Fabozzi","We present a unified, market-complete model that integrates both the Bachelier and Black-Scholes-Merton frameworks for asset pricing. The model allows for the study, within a unified framework, of asset pricing in a natural world that experiences the possibility of negative security prices or riskless rates. In contrast to classical Black-Scholes-Merton, we show that option pricing in the unified model displays a difference depending on whether the replicating, self-financing portfolio uses riskless bonds or a single riskless bank account. We derive option price formulas and extend our analysis to the term structure of interest rates by deriving the pricing of zero-coupon bonds, forward contracts, and futures contracts. We identify a necessary condition for the unified model to support a perpetual derivative. Discrete binomial pricing under the unified model is also developed. In every scenario analyzed, we show that the unified model simplifies to the standard Black-Scholes-Merton pricing under specific limits and provides pricing in the Bachelier model limit. We note that the Bachelier limit within the unified model allows for positive riskless rates. The unified model prompts us to speculate on the possibility of a mixed multiplicative and additive deflator model for risk-neutral option pricing.","q-fin.MF, q-fin.PR"
Stress Index Strategy Enhanced With Financial News Sentiment Analysis for the Equity Markets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4780225,2024-04-15 20:06:00,06/07/2024 11:04,Manual,"Baptiste Lefort, Eric Benhamou, Jean-Jacques Ohana, Beatrice Guez, David Saltiel, Thomas Jacquot","This paper introduces a new risk-on risk-off strategy for the stock market, which combines a financial stress indicator with a sentiment analysis done by ChatGPT reading and  interpreting Bloomberg daily market summaries. Forecasts of market stress derived from volatility  and credit spreads are enhanced when combined with the financial news sentiment derived from GPT4. As a result, the strategy shows improved performance, evidenced by higher Sharpe ratio and reduced maximum drawdowns. The improved performance is consistent across the NASDAQ, the S&amp;P 500 and the six major equity markets, indicating that the method generalises across equities markets.",
Biodiversity and Climate: Friends or Foes?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4778320,2024-04-15 19:05:00,06/07/2024 16:39,randomForestClassifier,"Eric Bouy&eacute;, Romain Deguest, Emmanuel Jurczenko, Jerome Teiletche","We present a portfolio optimization framework that allows incorporating biodiversity measures in investment decisions, alongside other sustainability objectives. Notably, our general approach can help investors tackle both biodiversity and climate objectives at once. By focusing on the tracking error variance minimization problem under both biodiversity and climate objectives, we show over a 21-year empirical exercise within a sovereign bond universe that investors can design portfolio strategies with enhanced biodiversity and climate content, without compromising on absolute risk-adjusted returns.  However, when measuring risk-adjusted returns relative to the market capitalization benchmark, we observe that adding a biodiversity objective to a portfolio with an existing climate objective slightly deteriorates its relative performance. This deterioration tends to decrease for more ambitious sustainable portfolios and completely dissipates when long-only constraints are removed. Our results remain robust to changes in the choice of sustainability measures or modeling set-ups.",
Causal Discovery in Financial Markets: A Framework for Nonstationary Time-Series Data,https://arxiv.org/abs/2312.17375,,06/10/2024 09:02,Manual,"Agathe Sadeghi, Achintya Gopal, Mohammad Fesanghary","This paper introduces a new causal structure learning method for nonstationary time series data, a common data type found in fields such as finance, economics, healthcare, and environmental science. Our work builds upon the constraint-based causal discovery from nonstationary data algorithm (CD-NOD). We introduce a refined version (CD-NOTS) which is designed specifically to account for lagged dependencies in time series data. We compare the performance of different algorithmic choices, such as the type of conditional independence test and the significance level, to help select the best hyperparameters given various scenarios of sample size, problem dimensionality, and availability of computational resources. Using the results from the simulated data, we apply CD-NOTS to a broad range of real-world financial applications in order to identify causal connections among nonstationary time series data, thereby illustrating applications in factor-based investing, portfolio diversification, and comprehension of market dynamics.",q-fin.ST
Deep Reinforcement Learning: Extending Traditional Financial Portfolio Methods,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4780026,2024-04-15 20:06:00,06/07/2024 11:04,Manual,"Eric Benhamou, Beatrice Guez, Jean-Jacques Ohana","Portfolio allocation, a key part of investment management, aims to balance risk and return. Traditional methodologies, rooted in modern portfolio theory, have been widely used for this purpose. Recently, deep reinforcement learning (DRL) has emerged as a powerful<br />tool to tackle these complex problems, allowing finding new solutions through a trial-and-error process. The central idea of this paper is to demonstrate that traditional portfolio allocation<br />strategies can be reframed in the DRL framework. It shows that a short-sighted agent, driven by immediate rewards and only considering the first two moments, converges to the Markowitz portfolio. By supplying this agent with more information, such as contextual data and additional future rewards, the DRL model can outperform traditional methods, though this comes with added complexity. Experiments confirm the usefulness of contextual data and show that DRL can improve traditional financial methods.",
Transaction Cost Optimization in a Fully Invested Portfolio with Target Weights,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4781258,2024-04-15 20:05:00,06/07/2024 16:36,randomForestClassifier,Valeriy Zakamulin,"This paper explores the optimization of transaction costs in a fully invested portfolio, where all available capital is committed to risky assets. The weights assigned to these assets are fixed based on a long-term strategic allocation. Unlike a passive portfolio, a fully invested portfolio is active, necessitating regular rebalancing to maintain the desired asset mix. Transaction costs pose a significant challenge to achieving optimal portfolio performance. Financial optimization models incorporating transaction costs fall within the domain of stochastic optimal control theory. However, the lack of analytical solutions and the intricate nature of numerical solution methods pose significant obstacles in applying these models in real-world applications. To overcome these challenges, we propose a practical model that balances theoretical and numerical simplicity while maintaining practical relevance. The central idea in our approach posits that the optimal rebalancing policy within a multi-period model can be effectively approximated by a policy derived from a single-period model. Through historical simulations, we illustrate the efficiency of our model, providing empirical support for our theoretical framework. In summary, our paper offers a practical and efficient approach to address the complexities of transaction cost optimization in a fully invested portfolio.",
"The Early Bird Catches the Worm: How Lasting is the Value of New, Alternative Data?",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4790865,2024-04-11 17:26:00,06/07/2024 16:31,randomForestClassifier,"Prince Elvis Asamoah, Massimo Massa, Albert Mensah, Vicki Wei Tang","We investigate how the information content of alternative data is impounded in prices and the duration of its value to mutual fund managers. Using a regression discontinuity design, we document that mutual funds increase their loadings on specific stocks by 0.7%-3% in response to exogenous, rounding-induced 1-percentage-point increase in ratings from customer-generated comments about companies’ products and services on social media platforms. This effect is more pronounced when information asymmetry is greater. Funds relying more on such data yield higher abnormal future returns and exhibit better stock-picking and market-timing abilities. This effect dissipates when the data becomes public.",
"Comparisons of Asset Manager, Asset Owner, and Wealth and Retail Portfolios",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4783121,2024-04-16 13:17:00,06/07/2024 16:39,Manual,"Peter Jacobs, Ursula Marchioni, Stefan Poechhacker, Nicolas Werbach, Andrew Ang","We find more similarities than differences in examining 800 European asset manager, asset owner, and wealth/retail portfolios. The total risk of the average European institutional portfolio across these types is 10 to 11% and is dominated by equity risk, which accounts for 90% of total portfolio risk. Within the institutions’ equity portfolios, country-specific tilts account for approximately half of the risk, and then 35% and 17% of the risk is attributable to style factors and sectors, respectively. The dominating style factor is small size, and relative to the MSCI ACWI equity benchmark, the average institution has negative quality and momentum tilts, and a positive value bias. All three types of institutional investors have lower carbon emission intensities, but lower ESG scores, than MSCI ACWI.",
How to Construct a Long-Only Multifactor Credit Portfolio?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4775767,2024-04-05 20:52:00,06/07/2024 11:04,randomForestClassifier,"Joris Blonk, Philip Messow","This paper examines how to combine single factors into a multifactor portfolio of corporate bonds. The two most common approaches in the literature are the so-called ‘integrated’ and ‘mixing’ approaches. This paper analyzes these two methods in corporate bond markets, and finds that the integrated factor portfolios generally lead to higher risk-adjusted returns. This is largely due to the fact that they do not invest in underperforming bonds that score poorly on a single factor, to which the ‘mixing’ approach is exposed to. Our results are robust over time and hold in different macro environments and in both Investment Grade and High Yield markets.",
Time-series Variation in Implied Costs of Capital: Evidence from Test of Intertemporal Capital Asset Pricing Model Predictions*,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4855759,2024-06-07 17:38:00,06/07/2024 16:32,Manual,"Peeyush Taori, Lakshmanan Shivakumar, Karthik Balakrishnan",,
GRIP: Graphical Models Revealing Insights for Portfolio Replication - A Learning Approach,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4780148,2024-04-15 20:06:00,06/07/2024 11:04,Manual,"Eric Benhamou, Jean-Jacques Ohana, Beatrice Guez","This paper presents a new and effective methodology for decoding strategies in the context of investment portfolios. The proposed approach relies on Dynamic Bayesian Graphical Models, which are powerful tools for capturing complex relationships and dependencies in data over time. Using these models, we can accurately decode the hidden strategy within the investment universe. By leveraging Dynamic Bayesian Graphical Models, we calculate dynamic weights that exhibit the most stable allocation rules. Through extensive experimentation on various investment scenarios, we demonstrate that our approach achieves high accuracy in decoding strategies. The method’s reliance on Dynamic Bayesian Graphical Models enables it to effectively uncover hidden patterns and relationships within the investment data, leading to improved portfolio allocation decisions and robust generalization across different market conditions.",
The Glidepath Confusion,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4750204,2024-03-30 11:59:00,06/07/2024 11:04,randomForestClassifier,Edward Hoyle,"Using long histories of financial and economic data for the UK and US, we quantify the risk associated with the asset-allocation decisions of pension savers and pensioners. When saving, our focus is on glidepaths: programmes that dictate asset allocations based on the age of the saver, or the number of working years they have left before retirement. We confirm our intuition that savers who allocate more to stocks than bonds have better investment outcomes on average, since stocks have historically generated superior real returns. We also examine the extent to which we can use our choice of glidepath to control tail risks and the variation in outcomes. This turns out to be rather limited, with the real returns of assets being the principal driver of risk. We find that a saver who is unlucky enough to experience a left-tail investment outcome is unlikely to have fared much better had they followed a different glidepath. Using bootstrapping techniques, we discover that over-allocating to stocks may be more damaging in the left tail than historical sample paths suggest. We take a novel look at the impact of fees on pension accumulation, quantifying the effect of investment performance and fee compounding on retirement wealth. Finally, we look at decumulation. We consider how both the level of income required in retirement and the choice of asset allocation can affect the probability of ruin.",
Interconnected Markets: Exploring the Dynamic Relationship Between BRICS Stock Markets and Cryptocurrency,https://arxiv.org/abs/2406.07641,,06/13/2024 09:09,randomForestClassifier,"Wei Wang, Haibo Wang","This study uses data from the BRICS stock market index, cryptocurrencies, and investor sentiment indicators from January 6, 2015, to June 29, 2023. BRICS nations emerge as pivotal representatives of emerging economies. This study employs a time-varying parameter vector autoregression model to unravel the intricate interdependence between traditional stock assets and the evolving landscape of cryptocurrencies. The analysis investigates spillover effects between BRICS stock markets and cryptocurrencies, revealing increasing interconnectedness during highly uncertain events like COVID-19, but no significant impact on major US stock market indices.","econ.GN, q-fin.EC, q-fin.PM, q-fin.RM"
Data Specialists and Market Efficiency,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4739691,2024-03-27 17:02:00,06/07/2024 16:31,randomForestClassifier,"Massimo Massa, Hong Zhang, Yijun Zhou","In the age of big data, investors need to process increasingly complicated, multidimensional data to decipher different aspects of a firm. How do investors deal with such multidimensional data? We find more informed institutional investors tend to specialize in subsets of firm aspects (i.e., data specialists). Such data specialization, however, may hamper market efficiency. Inattention shocks to specialists hinder price efficiency in their specialized aspects of firms; other aspects of firms may also be negatively influenced due to strategic complementarity. Specialist inattention also significantly impacts anomaly returns, impeding the price corrective effect of news arrival.",
"The Early Bird Catches the Worm: How Lasting is the Value of New, Alternative Data?",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4788210,2024-04-16 17:25:00,06/07/2024 16:31,Manual,"Massimo Massa, Albert Mensah, Vicki Wei Tang, Prince Elvis Asamoah","We investigate how the information content of alternative data is impounded in prices and the duration of its value to mutual fund managers. Using a regression discontinuity design, we document that mutual funds increase their loadings on specific stocks by 0.7%-3% in response to exogenous, rounding-induced 1-percentage-point increase in ratings from customer-generated comments about companies’ products and services on social media platforms. This effect is more pronounced when information asymmetry is greater. Funds relying more on such data yield higher abnormal future returns and exhibit better stock-picking and market-timing abilities. This effect dissipates when the data becomes public.",
The Evolving Index Effect: Evidence from Australia,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4779993,2024-04-15 20:06:00,06/07/2024 11:05,randomForestClassifier,Clint Howard,"Evidence around the price response of stocks to index change announcements (the index effect) in Australia is mixed. In contrast to the U.S. market, results often point towards the absence of any index effects in Australia. By studying a comprehensive set of index announcements across S&amp;P/ASX indexes, I find significant heterogeneity in the index effect across Australian securities. Additions to small capitalization indexes exhibit economically meaningful index effects, whereas additions to large capitalization indexes are largely insignificant. Unscheduled additions experience larger announcement date returns but subsequent reversals compared to scheduled additions. These results are consistent with both information and price pressure effects from index trading.",
Speculative Trading and Price Momentum,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4766687,2024-04-15 06:42:00,06/07/2024 16:37,randomForestClassifier,"Alex  Dontoh, Joshua Ronen, Bharat Sarath","Research indicates that contrary to the theory of efficient markets, capital market returns, or the sequence of price changes, demonstrate serial correlation. Our study finds that the activity of liquidity traders, alongside informed and rational traders, can lead to intricate patterns of price changes, even when the value of the underlying asset remains unchanged. We examine the role of speculative trading, in which rational traders make bets based on anticipated short-term liquidity changes and the asset's expected long-term value, in shaping the evolution of prices. We introduce a detailed recursive equilibrium model that considers the influence of future trading rounds on present prices. This model marks a departure from previous research, which typically focuses on optimizing strategies for the immediate next trading round.",
Cluster GARCH,https://arxiv.org/abs/2406.06860,,06/12/2024 09:24,randomForestClassifier,"Chen Tong, Peter Reinhard Hansen, Ilya Archakov","We introduce a novel multivariate GARCH model with flexible convolution-t distributions that is applicable in high-dimensional systems. The model is called Cluster GARCH because it can accommodate cluster structures in the conditional correlation matrix and in the tail dependencies. The expressions for the log-likelihood function and its derivatives are tractable, and the latter facilitate a score-drive model for the dynamic correlation structure. We apply the Cluster GARCH model to daily returns for 100 assets and find it outperforms existing models, both in-sample and out-of-sample. Moreover, the convolution-t distribution provides a better empirical performance than the conventional multivariate t-distribution.","econ.EM, q-fin.RM"
"On Conditional least squares estimation for the AD(1,n) model",https://arxiv.org/abs/2406.07653,,06/13/2024 09:09,randomForestClassifier,"Mohamed Ben Alaya, Houssem Dahbi, Hamdi Fathallah","This paper deals with the problem of global parameter estimation of AD(1, n) where n is a positive integer which is a subclass of affine diffusions introduced by Duffie, Filipovic, and Schachermayer. In general affine models are applied to the pricing of bond and stock options, which is illustrated for the Vasicek, Cox-Ingersoll-Ross and Heston models. Our main results are about the conditional least squares estimation of AD(1, n) drift parameters based on two types of observations : continuous time observations and discrete time observations with high frequency and infinite horizon. Then, for each case, we study the asymptotic properties according to ergodic and non-ergodic cases. This paper introduces as well some moment results relative to the AD(1, n) model.","math.ST, stat.AP, stat.TH"
Is Long Run Risk Really Priced? A Reply,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4803146,2024-04-23 01:53:00,06/07/2024 16:34,Manual,"Yukun Liu, Ben Matthies","Maio (2023) implements the cross-sectional asset pricing tests of the NI-index from Liu and Matthies (2022). Maio (2023) confirms that every pricing result in Liu and Matthies (2022) replicates successfully. Next, Maio (2023) runs new tests which test the asset pricing power of the NI-index on different subsamples of portfolios and argues that the cross-sectional pricing power of the NI-index is driven exclusively by the 10 momentum test portfolios. This claim is false. If the NI-index exclusively prices the momentum portfolios, then the pricing power of the NI-index should disappear after removing all momentum portfolios from the set of test assets. Despite this being the only direct test of the central claim in Maio (2023), the results of this test are never shown by the author. We implement it here by removing all 10 momentum portfolios from our sample and testing the asset pricing power of the NI-index on the remaining 41 test portfolios (25 Size-BM, 10 Industry, and 6 Bond portfolios). The price of risk of the NI-index is positive and significant with a sizeable adjusted R-squared of 50 percent. This simple test unequivocally rejects the claim that the pricing power of the NI-index is driven exclusively by the momentum portfolios. Maio (2023) makes several more minor points which we address in a similar fashion.",
Application of Black-Litterman Bayesian in Statistical Arbitrage,https://arxiv.org/abs/2406.06706,,06/12/2024 09:24,randomForestClassifier,Qiqin Zhou,"\begin{abstract} In this paper, we integrated the statistical arbitrage strategy, pairs trading, into the Black-Litterman model and constructed efficient mean-variance portfolios. Typically, pairs trading underperforms under volatile or distressed market condition because the selected asset pairs fail to revert to equilibrium within the investment horizon. By enhancing this strategy with the Black-Litterman portfolio optimization, we achieved superior performance compared to the S\&amp;P 500 market index under both normal and extreme market conditions. Furthermore, this research presents an innovative idea of incorporating traditional pairs trading strategies into the portfolio optimization framework in a scalable and systematic manner.","q-fin.CP, stat.AP"
Estimation of VaR with jump process: application in corn and soybean markets,https://arxiv.org/abs/2311.00832,,06/11/2024 09:02,randomForestClassifier,"Minglian Lin, Indranil SenGupta, William Wilson","Value at Risk (VaR) is a quantitative measure used to evaluate the risk linked to the potential loss of investment or capital. Estimation of the VaR entails the quantification of prospective losses in a portfolio of investments, using a certain likelihood, under normal market conditions within a specific time period. The objective of this paper is to construct a model and estimate the VaR for a diversified portfolio consisting of multiple cash commodity positions driven by standard Brownian motions and jump processes. Subsequently, a thorough analytical estimation of the VaR is conducted for the proposed model. The results are then applied to two distinct commodities -- corn and soybean -- enabling a comprehensive comparison of the VaR values in the presence and absence of jumps.",q-fin.MF
Heterogeneous Beliefs Model of Stock Market Predictability,https://arxiv.org/abs/2406.08448,,06/13/2024 09:09,randomForestClassifier,Jiho Park,"This paper proposes a theory of stock market predictability patterns based on a model of heterogeneous beliefs. In a discrete finite time framework, some agents receive news about an asset's fundamental value through a noisy signal. The investors are heterogeneous in that they have different beliefs about the stochastic supply. A momentum in the stock price arises from those agents who incorrectly underestimate the signal accuracy, dampening the initial price impact of the signal. A reversal in price occurs because the price reverts to the fundamental value in the long run. An extension of the model to multiple assets case predicts co-movement and lead-lag effect, in addition to cross-sectional momentum and reversal. The heterogeneous beliefs of investors about news demonstrate how the main predictability anomalies arise endogenously in a model of bounded rationality.","q-fin.PR, q-fin.GN, q-fin.TR"
Obtaining Accurate Gold Prices,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4758000,2024-04-15 16:44:00,06/07/2024 16:31,randomForestClassifier,Amit K. Sinha,"Gold prices have been of major interest for a lot of investors, analysts, and economists. Accordingly, a number of different modeling approaches have been used to forecast gold prices. In this manuscript, the geometric Brownian motion approach, used in the pricing of numerous types of assets, is used to forecast the prices of gold at yearly, monthly, and quarterly frequencies. This approach allows for simulating one-period-ahead prices and the associated probabilities. The expected prices obtained from the simulated prices and probabilities are found to provide reliable forecasts when compared with the observed yearly, monthly, and quarterly prices.",
"No-Arbitrage Pricing, Dynamics and Forward Prices of Collateralized Derivatives",https://arxiv.org/abs/2208.08746,,06/13/2024 09:09,randomForestClassifier,Alessio Calvelli,"This paper analyzes the pricing of collateralized derivatives, i.e. contracts where counterparties are not only subject to financial derivatives cash flows but also to collateral cash flows arising from a collateral agreement. We do this along the lines of the brilliant approach of the first part of Moreni and Pallavicini (2017): in particular we extend their framework where underlyings are continuous processes driven by a Brownian vector, to a more general setup where underlyings are semimartingales (and hence jump processes). First of all, we briefly derive from scratch the theoretical foundations of the main subsequent achievements, i.e. the extension of the classical No-Arbitrage theory to dividend paying semimartingale assets, where by dividend we mean any cash flow earned/paid from holding the asset. In this part we merge, in the same treatment and under the same notation, the principal known results with some original ones. Then we extend the approach of Moreni and Pallavicini (2017) in different directions and we derive not only the pricing formulae but also the dynamics and forward prices of collateralized derivatives (extending the achievements of the first part of Gabrielli et al. (2019)). Finally, we study some important applications (Repurchase Agreements, Securities Lending and Futures contracts) of previously established theoretical frameworks, obtaining some results that are commonly used in practitioners literature, but often not well understood.",q-fin.PR
On the use of artificial intelligence in financial regulations and the impact on financial stability,https://arxiv.org/abs/2310.11293,,06/07/2024 11:06,randomForestClassifier,"Jon Danielsson, Andreas Uthemann","Artificial intelligence (AI) can undermine financial stability because of malicious use, misinformation, misalignment, and the AI analytics market structure. The low frequency and uniqueness of financial crises, coupled with mutable and unclear objectives, frustrate machine learning. Even if the authorities prefer a conservative approach to AI adoption, it will likely become widely used by stealth, taking over increasingly high-level functions driven by significant cost efficiencies and superior performance. We propose six criteria for judging the suitability of AI.","econ.GN, q-fin.EC, q-fin.RM"
Derivatives of Risk Measures,https://arxiv.org/abs/2404.09646,,06/11/2024 09:02,Manual,Battulga Gankhuu,"This paper provides the first and second order derivatives of any risk measures, including VaR and ES for continuous and discrete portfolio loss random variable variables. Also, we give asymptotic results of the first and second order conditional moments for heavy-tailed portfolio loss random variable.",q-fin.RM
ESG and Behavioral Finance: Why ESG-Investing is Primarily a Psychological Phenomenon,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4786610,2024-04-22 06:28:00,06/07/2024 11:04,Manual,Hersh Shefrin,"Using a behavioral finance framework, I extend traditional portfolio selection theory and traditional asset pricing theory to accommodate ESG-investing. There are two behavioral innovations to behavioral portfolio selection. First, investors have preferences over the sources of their returns, which involves intangible benefits, possibly influenced by financial firms’ marketing efforts. Second, investors are vulnerable to biased judgments about ESG-impact and about return distributions. The first innovation leads to a different notion of diversification than the traditional approach. This innovation also impacts the character of asset pricing, especially the nature of mean-variance efficiency, risk-free securities (green and brown), and arbitrage. I discuss conditions under which ESG-asset pricing features a natural factor pricing structure. In some circumstances, the resulting equilibrium will conform to the CAPM with a single pricing factor, the market portfolio. In other circumstances, there will be more than one factor, and one of the factors will be the market portfolio. In yet other circumstances, there will be more than one factor, but the market portfolio will not be among them. This is especially the case in the presence of heterogeneous judgmental errors, both about returns and about ESG-opacity.",
3d-Pca: Factor Models with Restrictions,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4771237,2024-03-25 09:48:00,06/07/2024 16:38,randomForestClassifier,Martin Lettau,"This paper proposes latent factor models for multidimensional panels called 3D-PCA.  Factor weights are constructed from a small set of dimension-specific building blocks, which give rise to proportionality restrictions of factor weights.  While the set of feasible factors is restricted, factors with long/short structures often found in pricing factors are admissible.  I estimate the model using a 3-dimensional data set of double-sorted portfolios of 11 characteristics.  Factors estimated by 3D-PCA have higher Sharpe ratios and smaller cross-sectional pricing errors than models with PCA or Fama-French factors.  Since factor weights are subject to restrictions, the number of free parameters is small.  Consequently, the model produces robust results in short time series and performs well in recursive out-of-sample estimations.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32261"" target=""_blank"">www.nber.org</a>.<br />",
3D-PCA: Factor Models with Restrictions,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4741223,2024-03-28 11:05:00,06/07/2024 16:38,randomForestClassifier,Martin Lettau,"This paper proposes latent factor models for multidimensional panels called 3D-PCA. Factor weights are constructed from a small set of dimension-specific building blocks, which give rise to proportionality restrictions of factor weights. While the set of feasible factors is restricted, factors with long/short structures often found in pricing factors are admissible. I estimate the model using a 3-dimensional data set of double-sorted portfolios of 11 characteristics. Factors estimated by 3D-PCA have higher Sharpe ratios and smaller cross-sectional pricing errors than models with PCA or Fama-French factors. Since factor weights are subject to restrictions, the number of free parameters is small. Consequently, the model produces robust results in short time series and performs well in recursive out-of-sample estimations.",
How Managers Communicate about Capital Budgeting to Investors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4766530,2024-04-15 14:22:00,06/07/2024 16:32,randomForestClassifier,"Robert H. Battalio, Tim  Loughran, Bill McDonald","We create a lexicon of 45 capital budgeting terms and document manager language usage in earnings conference calls during 2010-2020. Managers often use technical language like cash flow, free cash flow, operating income, return on investment, and return on capital during conference calls. We substantiate the survey evidence of Graham and Harvey (2001) by demonstrating that managers also use concepts like payback period and ROI in conference calls. Capital budgeting counts are associated with larger capitalization, higher fixed assets, and lower R&amp;D intensity firms. We also find that managers mention the non-GAAP term EBITDA significantly more often when a company’s net income is negative.",
Causality Approach Applied to Clean-Tech Equities,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4763031,2024-04-15 12:40:00,06/07/2024 16:34,randomForestClassifier,"Edmond Lezmi, Karl Sawaya, Jiali Xu","The clean-tech industry has experienced remarkable growth, bringing forth groundbreaking technologies and sustainable solutions. This research article delves into the examination of factors that shape the evaluation of net-zero assets in various sectors and themes. Through observational analysis utilizing key financial indicators, it becomes apparent that companies exclusively involved in the clean-tech industry, known as pure players, generally outperform those that have less focus in this area, referred to as non-pure players in terms of financial performance [50]. The transition towards a sustainable energy system is greatly facilitated by comprehensive policies and regulations. For instance, in the United States, the Inflation Reduction Act (IRA) and in Europe, the Net-Zero Industry Act (NZIA) play significant roles in shaping the dynamics of asset valuation. These regulatory frameworks contribute to the valuation dynamics and help drive the growth of clean-tech investments [26]. Additionally, the physical and transitional climate risk exert a substantial influence on the valuation of net-zero assets. To gain a deeper understanding of the drivers behind clean technologies and their causal relationships, our study employs a specific branch of Bayesian probabilistic approach introduced by Judea Pearl, the Ladder of Causation, explained in The Book of Why. This approach enables us to model the dependency structure<br />among these influential factors and evaluate their direct and indirect impacts on cleantech stock returns by manipulating the explanatory variables. By creating coherent scenarios through interventions on these variables, we can address essential what-if questions, aiding investors and policymakers in making more informed decisions in this ever-evolving and dynamic industry. Within the framework of Bayesian analysis, the do-calculus and the counterfactual concept play a pivotal role and make it possible to calculate the probability distribution of a random variable under a hypothetical scenario on the explanatory variables different from the observed data. We not only explore the direct effects of interventions on explanatory variables but also reveal sensitivity groups among clean-tech companies. These sensitivity groups consist of companies that exhibit a similar sensitivity to a specific causal factor. This insight is valuable for pinpointing which clean-tech subsectors or companies are particularly affected by certain changes or interventions, offering a more detailed understanding of the industry’s dynamics.",
Probabilistic models and statistics for electronic financial markets in the digital age,https://arxiv.org/abs/2406.07388,,06/12/2024 09:24,randomForestClassifier,Markus Bibinger,"The scope of this manuscript is to review some recent developments in statistics for discretely observed semimartingales which are motivated by applications for financial markets. Our journey through this area stops to take closer looks at a few selected topics discussing recent literature. We moreover highlight and explain the important role played by some classical concepts of probability and statistics. We focus on three main aspects: Testing for jumps; rough fractional stochastic volatility; and limit order microstructure noise. We review jump tests based on extreme value theory and complement the literature proposing new statistical methods. They are based on asymptotic theory of order statistics and the R\'{e}nyi representation. The second stage of our journey visits a recent strand of research showing that volatility is rough. We further investigate this and establish a minimax lower bound exploring frontiers to what extent the regularity of latent volatility can be recovered in a more general framework. Finally, we discuss a stochastic boundary model with one-sided microstructure noise for high-frequency limit order prices and its probabilistic and statistical foundation.","q-fin.ST, math.ST, stat.TH"
A Century of Profitable Industry Trends,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4857230,2024-06-14 12:56:00,06/14/2024 14:36,randomForestClassifier,"Carlo Zarattini, Gary Antonacci","This paper evaluates the profitability of an industry-based long-only trend-following portfolio. Utilizing 48 industry portfolios from 1926 to 2024, our analysis explores the model's profitability over a century, highlighting its adaptability and effectiveness across diverse market epochs. We assess the overall profitability of the model and examine the distribution of long-term returns and associated risks. Our analysis includes the impact of individual industry contributions on overall portfolio performance, focusing on the frequency and average profitability of trades at both the portfolio and industry levels. The Timing Industry strategy achieves an average annual return of 18.5% with an annual volatility of 12.1%, resulting in a Sharpe Ratio of 1.46, compared to the US equity market's 9.7% return, 17.1% volatility, and 0.63 Sharpe Ratio. The model's outperformance is underscored by an annualized alpha of 11.2%, with the timing strategy reducing drawdown by almost 60% compared to a passive long exposure. Further investigations reveal the active strategy's ability to fully participate during market upswings while significantly limiting exposure during downturns. In the final section, we introduce 31 sector ETFs provided by State Street Global Advisors and backtest the same trading methodology over the last 20 years. The ETFs successfully replicate the model's exposure and returns. We also assess the impact of commissions and slippage, demonstrating that the active timing strategy remains largely profitable even with high trading costs.",
DeepUnifiedMom: Unified Time-series Momentum Portfolio Construction via Multi-Task Learning with Multi-Gate Mixture of Experts,https://arxiv.org/abs/2406.08742,,06/14/2024 14:44,randomForestClassifier,"Joel Ong, Dorien Herremans","This paper introduces DeepUnifiedMom, a deep learning framework that enhances portfolio management through a multi-task learning approach and a multi-gate mixture of experts. The essence of DeepUnifiedMom lies in its ability to create unified momentum portfolios that incorporate the dynamics of time series momentum across a spectrum of time frames, a feature often missing in traditional momentum strategies. Our comprehensive backtesting, encompassing diverse asset classes such as equity indexes, fixed income, foreign exchange, and commodities, demonstrates that DeepUnifiedMom consistently outperforms benchmark models, even after factoring in transaction costs. This superior performance underscores DeepUnifiedMom's capability to capture the full spectrum of momentum opportunities within financial markets. The findings highlight DeepUnifiedMom as an effective tool for practitioners looking to exploit the entire range of momentum opportunities. It offers a compelling solution for improving risk-adjusted returns and is a valuable strategy for navigating the complexities of portfolio management.",q-fin.CP
Implied volatility (also) is path-dependent,https://arxiv.org/abs/2312.15950,,06/14/2024 14:44,randomForestClassifier,"Herv\'e Andr\`es (CERMICS), Alexandre Boumezoued (CERMICS, MATHRISK), Benjamin Jourdain (CERMICS, MATHRISK)","We propose a new model for the coherent forecasting of both the implied volatility surfaces and the underlying asset returns.In the spirit of Guyon and Lekeufack (2023) who are interested in the dependence of volatility indices (e.g. the VIX) on the paths of the associated equity indices (e.g. the S&amp;P 500), we first study how implied volatility can be predicted using the past trajectory of the underlying asset price. Our empirical study reveals that a large part of the movements of the at-the-money-forward implied volatility for up to two years maturities can be explained using the past returns and their squares. Moreover, we show that up to four years of the past evolution of the underlying price should be used for the prediction and that this feedback effect gets weaker when the maturity increases. Building on this new stylized fact, we fit to historical data a parsimonious version of the SSVI parameterization (Gatheral and Jacquier, 2014) of the implied volatility surface relying on only four parameters and show that the two parameters ruling the at-the-money-forward implied volatility as a function of the maturity exhibit a path-dependent behavior with respect to the underlying asset price. Finally, we propose a model for the joint dynamics of the implied volatility surface and the underlying asset price. The latter is modelled using a variant of the path-dependent volatility model of Guyon and Lekeufack and the former is obtained by adding a feedback effect of the underlying asset price onto the two parameters ruling the at-the-money-forward implied volatility in the parsimonious SSVI parameterization and by specifying a hidden semi-Markov diffusion model for the residuals of these two parameters and the two other parameters. Thanks to this model, we are able to simulate highly realistic paths of implied volatility surfaces that are arbitrage-free.",q-fin.CP
Decentralised Finance and Automated Market Making: Predictable Loss and Optimal Liquidity Provision,https://arxiv.org/abs/2309.08431,,06/14/2024 14:44,randomForestClassifier,"\'Alvaro Cartea, Fay\c{c}al Drissi, Marcello Monga","Constant product markets with concentrated liquidity (CL) are the most popular type of automated market makers. In this paper, we characterise the continuous-time wealth dynamics of strategic LPs who dynamically adjust their range of liquidity provision in CL pools. Their wealth results from fee income, the value of their holdings in the pool, and rebalancing costs. Next, we derive a self-financing and closed-form optimal liquidity provision strategy where the width of the LP's liquidity range is determined by the profitability of the pool (provision fees minus gas fees), the predictable losses (PL) of the LP's position, and concentration risk. Concentration risk refers to the decrease in fee revenue if the marginal exchange rate (akin to the midprice in a limit order book) in the pool exits the LP's range of liquidity. When the drift in the marginal rate is stochastic, we show how to optimally skew the range of liquidity to increase fee revenue and profit from the expected changes in the marginal rate. Finally, we use Uniswap v3 data to show that, on average, LPs have traded at a significant loss, and to show that the out-of-sample performance of our strategy is superior to the historical performance of LPs in the pool we consider.","q-fin.MF, q-fin.TR"
Statistical inference for rough volatility: Central limit theorems,https://arxiv.org/abs/2210.01216,,06/17/2024 09:22,randomForestClassifier,"Carsten Chong, Marc Hoffmann, Yanghui Liu, Mathieu Rosenbaum, Gr\'egoire Szymanski","In recent years, there has been a substantive interest in rough volatility models. In this class of models, the local behavior of stochastic volatility is much more irregular than semimartingales and resembles that of a fractional Brownian motion with Hurst parameter $H < 0.5$. In this paper, we derive a consistent and asymptotically mixed normal estimator of $H$ based on high-frequency price observations. In contrast to previous works, we work in a semiparametric setting and do not assume any a priori relationship between volatility estimators and true volatility. Furthermore, our estimator attains a rate of convergence that is known to be optimal in a minimax sense in parametric rough volatility models.","math.ST, q-fin.ST, stat.TH"
"Estimating Changepoints in Extremal Dependence, Applied to Aviation Stock Prices During COVID-19 Pandemic",https://arxiv.org/abs/2308.13895,,06/17/2024 09:22,randomForestClassifier,"Arnab Hazra, Shiladitya Bose","The dependence in the tails of the joint distribution of two random variables is generally assessed using $\chi$-measure, the limiting conditional probability of one variable being extremely high given the other variable is also extremely high. This work is motivated by the structural changes in $\chi$-measure between the daily rate of return (RoR) of the two Indian airlines, IndiGo and SpiceJet, during the COVID-19 pandemic. We model the daily maximum and minimum RoR vectors (potentially transformed) using the bivariate H\""usler-Reiss (BHR) distribution. To estimate the changepoint in the $\chi$-measure of the BHR distribution, we explore two changepoint detection procedures based on the Likelihood Ratio Test (LRT) and Modified Information Criterion (MIC). We obtain critical values and power curves of the LRT and MIC test statistics for low through high values of $\chi$-measure. We also explore the consistency of the estimators of the changepoint based on LRT and MIC numerically. In our data application, for RoR maxima and minima, the most prominent changepoints detected by LRT and MIC are close to the announcement of the first phases of lockdown and unlock, respectively, which are realistic; thus, our study would be beneficial for portfolio optimization in the case of future pandemic situations.",stat.AP
An Algebraic Framework for the Modeling of Limit Order Books,https://arxiv.org/abs/2406.04969,,06/10/2024 09:02,Manual,"Johannes Bleher, Michael Bleher","Introducing an algebraic framework for modeling limit order books (LOBs) with tools from physics and stochastic processes, our proposed framework captures the creation and annihilation of orders, order matching, and the time evolution of the LOB state. It also enables compositional settings, accommodating the interaction of heterogeneous traders and different market structures. We employ Dirac notation and generalized generating functions to describe the state space and dynamics of LOBs. The utility of this framework is shown through simulations of simplified market scenarios, illustrating how variations in trader behavior impact key market observables such as spread, return volatility, and liquidity. The algebraic representation allows for exact simulations using the Gillespie algorithm, providing a robust tool for exploring the implications of market design and policy changes on LOB dynamics. Future research can expand this framework to incorporate more complex order types, adaptive event rates, and multi-asset trading environments, offering deeper insights into market microstructure and trader behavior and estimation of key drivers for market microstructure dynamics.","q-fin.TR, q-fin.MF, q-fin.ST"
The Financial Market Effects of the Federal Reserve's Large-Scale Asset Purchases *,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4858959,2024-06-17 18:19:00,06/17/2024 16:33,randomForestClassifier,"Julie Remache, Joseph Gagnon, Brien Sack, Matthew Raskin",,
Dynamic Asset Allocation with Asset-Specific Regime Forecasts,https://arxiv.org/abs/2406.09578,,06/17/2024 09:22,randomForestClassifier,"Yizhan Shu, Chenyu Yu, John M. Mulvey","This article introduces a novel hybrid regime identification-forecasting framework designed to enhance multi-asset portfolio construction by integrating asset-specific regime forecasts. Unlike traditional approaches that focus on broad economic regimes affecting the entire asset universe, our framework leverages both unsunpervised and supervised learning to generate tailored regime forecasts for individual assets. Initially, we use the statistical jump model, a robust unsupervised regime identification model, to derive regime labels for historical periods, classifying them into bullish or bearish states based on features extracted from an asset return series. Following this, a supervised gradient-boosted decision tree classifier is trained to predict these regimes using a combination of asset-specific return features and cross-asset macro-features. We apply this framework individually to each asset in our universe. Subsequently, return and risk forecasts which incorporate these regime predictions are input into Markowitz mean-variance optimization to determine optimal asset allocation weights. We demonstrate the efficacy of our approach through an empirical study on a multi-asset portfolio comprising twelve risky assets, including global equity, bond, real estate, and commodity indexes spanning from 1991 to 2023. The results consistently show outperformance across various portfolio models, including minimum-variance, mean-variance, and naive-diversified portfolios, highlighting the advantages of integrating asset-specific regime forecasts into dynamic asset allocation.",q-fin.PM
The skew-symmetric-Laplace-uniform distribution,https://arxiv.org/abs/2406.10805,,06/18/2024 10:08,randomForestClassifier,"Raju. K. Lohot, V. U. Dixit","Laplace distribution is popular in the field of economics and finance. Still, data sets often show a lack of symmetry and a tendency of being bounded from either side of their support. In view of this, we introduce a new family of skew distribution using the skewing mechanism of Azzalini (1985), namely, skew-symmetric-Laplace-uniform distribution (SSLUD). Here uniform distribution is used not only to introduce skewness in Laplace distribution but also to restrict distribution support on one side of the real line. This paper provides a comprehensive description of the essential distributional properties of SSLUD. Estimators of the parameter are obtained using the method of moments and the method of maximum likelihood. The finite sample and asymptotic properties of these estimators are studied using simulation. It is observed that the maximum likelihood estimator is better than the moment estimator through a simulation study. Finally, an application of SSLUD to real-life data on the daily percentage change in the price of NIFTY 50, an Indian stock market index, is presented.","math.ST, stat.TH"
Operator Deep Smoothing for Implied Volatility,https://arxiv.org/abs/2406.11520,,06/18/2024 10:08,randomForestClassifier,"Lukas Gonon, Antoine Jacquier, Ruben Wiedemann","We devise a novel method for implied volatility smoothing based on neural operators. The goal of implied volatility smoothing is to construct a smooth surface that links the collection of prices observed at a specific instant on a given option market. Such price data arises highly dynamically in ever-changing spatial configurations, which poses a major limitation to foundational machine learning approaches using classical neural networks. While large models in language and image processing deliver breakthrough results on vast corpora of raw data, in financial engineering the generalization from big historical datasets has been hindered by the need for considerable data pre-processing. In particular, implied volatility smoothing has remained an instance-by-instance, hands-on process both for neural network-based and traditional parametric strategies. Our general operator deep smoothing approach, instead, directly maps observed data to smoothed surfaces. We adapt the graph neural operator architecture to do so with high accuracy on ten years of raw intraday S&amp;P 500 options data, using a single set of weights. The trained operator adheres to critical no-arbitrage constraints and is robust with respect to subsampling of inputs (occurring in practice in the context of outlier removal). We provide extensive historical benchmarks and showcase the generalization capability of our approach in a comparison with SVI, an industry standard parametrization for implied volatility. The operator deep smoothing approach thus opens up the use of neural networks on large historical datasets in financial engineering.",q-fin.CP
Statistical arbitrage in multi-pair trading strategy based on graph clustering algorithms in US equities market,https://arxiv.org/abs/2406.10695,,06/18/2024 10:08,randomForestClassifier,"Adam Korniejczuk, Robert \'Slepaczuk","The study seeks to develop an effective strategy based on the novel framework of statistical arbitrage based on graph clustering algorithms. Amalgamation of quantitative and machine learning methods, including the Kelly criterion, and an ensemble of machine learning classifiers have been used to improve risk-adjusted returns and increase immunity to transaction costs over existing approaches. The study seeks to provide an integrated approach to optimal signal detection and risk management. As a part of this approach, innovative ways of optimizing take profit and stop loss functions for daily frequency trading strategies have been proposed and tested. All of the tested approaches outperformed appropriate benchmarks. The best combinations of the techniques and parameters demonstrated significantly better performance metrics than the relevant benchmarks. The results have been obtained under the assumption of realistic transaction costs, but are sensitive to changes in some key parameters.","q-fin.PM, q-fin.TR, stat.ML"
Volatility Depends on Market Trades and Macro Theory,https://arxiv.org/abs/2008.07907,,06/18/2024 10:08,randomForestClassifier,Victor Olkhov,"We consider the randomness of market trade as the origin of price and return stochasticity. We look at time series of trade values and volumes as random variables during the averaging interval {\Delta} and describe the dependences of market-based volatilities of price and return on the volatilities and correlations of market trade values and volumes. We describe the market-based origin of the lower boundaries of the accuracy of macroeconomic variables and consider, as an example, the accuracy of macroeconomic investments. We highlight that current macroeconomic models describe relations between the 1st order variables determined by sums of trade values or volumes. To predict market-based volatilities of price, return, and volatilities of macroeconomic variables, one should develop econometric methodologies, collect data, and elaborate macroeconomic theories of the 2nd order that model the mutual dependence of the 1st and 2nd order economic variables. The absence of macroeconomic theories of the 2nd order means no economic basis for predictions of market-based volatilities of price and return, as well as volatilities of any macroeconomic variables. In turn, that limits the accuracy of forecasting probabilities of price, return, and the accuracy of macroeconomic variables in the best case by Gaussian distributions.","q-fin.ST, q-fin.PM, q-fin.PR"
Supervised Autoencoder MLP for Financial Time Series Forecasting,https://arxiv.org/abs/2404.01866,,06/19/2024 09:37,randomForestClassifier,"Bartosz Bieganowski, Robert Slepaczuk","This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders, aiming to improve investment strategy performance. It specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns, using the Sharpe and Information Ratios. The study focuses on the S&amp;P 500 index, EUR/USD, and BTC/USD as the traded assets from January 1, 2010, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance, highlighting the importance of precise parameter tuning. This paper also presents a derivation of a novel optimization metric that can be used with triple barrier labeling. The results of this study have substantial policy implications, suggesting that financial institutions and regulators could leverage techniques presented to enhance market stability and investor protection, while also encouraging more informed and strategic investment approaches in various financial sectors.","q-fin.TR, stat.ML"
Semi-parametric financial risk forecasting incorporating multiple realized measures,https://arxiv.org/abs/2402.09985,,06/17/2024 09:22,Manual,"Rangika Peiris, Chao Wang, Richard Gerlach, Minh-Ngoc Tran","A semi-parametric joint Value-at-Risk (VaR) and Expected Shortfall (ES) forecasting framework employing multiple realized measures is developed. The proposed framework extends the realized exponential GARCH model to be semi-parametrically estimated, via a joint loss function, whilst extending existing quantile time series models to incorporate multiple realized measures. A quasi-likelihood is built, employing the asymmetric Laplace distribution that is directly linked to a joint loss function, which enables Bayesian inference for the proposed model. An adaptive Markov Chain Monte Carlo method is used for the model estimation. The empirical section evaluates the performance of the proposed framework with six stock markets from January 2000 to June 2022, covering the period of COVID-19. Three realized measures, including 5- minute realized variance, bi-power variation, and realized kernel, are incorporated and evaluated in the proposed framework. One-step-ahead VaR and ES forecasting results of the proposed model are compared to a range of parametric and semi-parametric models, lending support to the effectiveness of the proposed framework.",q-fin.RM
Stock Price Crashes and Systematic Risk,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4738376,2024-03-26 17:14:00,06/07/2024 11:03,Manual,"Suvra Roy, Ben R. Marshall, Harvey Nguyen, Nuttawat Visaltanachoti","We show that firm systematic risk increases following stock price crashes. This occurs in both low- and high-beta companies and is robust to alternate proxies of systematic risk. Crashed firms face difficulty raising capital or obtaining loans, exacerbating default risk. Our results indicate that the increased systematic risk is due to increased default risk. There is no evidence to support information asymmetry as a channel for higher beta following crashes. We show that the increase in systematic risk results in higher costs for equity financing.",
When Small Wins Big: Classification Tasks Where Compact Models Outperform Original GPT-4,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4780454,2024-04-15 20:05:00,06/07/2024 11:04,Manual,"Baptiste Lefort, Eric Benhamou, Jean-Jacques Ohana, Beatrice Guez, David Saltiel, Damien Challet","This paper evaluates Large Language Models (LLMs) on financial text classification, comparing<br />GPT-4 (1.76 trillion parameters) against FinBERT (110 million parameters) and FinDROBERTA<br />(82.1 million parameters). We achieved a classification task on short financial sentences involving multiple divergent insights with both textual and numerical data. We developed a market-based<br />large dataset that enabled us to fine-tune the models on a real-world ground truth. Utilizing a marketbased dataset for fine-tuning on extensive datasets, we achieved significant enhancements with FinBERT and FinDROBERTA over GPT-4. However, the use of a bagging majority classifier did not yield performance improvements, demonstrating that the principles of Condorcet’s jury Theorem do not apply, suggesting a lack of independence among the models and similar behavior patterns across all evaluated models. Our results indicate that for complex sentiment classification, compact models match larger models, even with fine-tuning. The fine-tuned models are made available as opensource for additional research.",
Earnings to Price Analysis with mOpt Versus Bisquare Robust Regression,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4777975,2024-04-15 14:20:00,06/07/2024 16:34,randomForestClassifier,"R. Douglas Martin, John Guerard, Daniel Xia","Recently Martin et al. (2024) used an optimal bias robust regression estimator, called the mOpt estimator, in Fama-MacBeth cross-section regressions to study the statistical significance of the earnings-to-price (EP) and book-tp-price (BP) factors, among others. An earlier study by Markowitz et al. (2021), and a number of studies referenced therein, used an alternative well-known Tukey Bisquare robust regression estimator. This begs the question of how the Bisquare estimator fares relative to the mOpt robust regression with regard to determining the statistical significance of the EP and BP factors. Here we show that the Bisquare robust regression estimator performs almost as well as mOpt with regard to the size of their significant t-statistics.",
Strategy-proof Selling: a Geometric Approach,https://arxiv.org/abs/2406.12279,,06/19/2024 09:37,Manual,Mridu Prabal Goswami,"We consider one buyer and one seller. For a bundle $(t,q)\in [0,\infty[\times [0,1]=\mathbb{Z}$, $q$ either refers to the wining probability of an object or a share of a good, and $t$ denotes the payment that the buyer makes. We define classical and restricted classical preferences of the buyer on $\mathbb{Z}$; they incorporate quasilinear, non-quasilinear, risk averse preferences with multidimensional pay-off relevant parameters. We define rich single-crossing subsets of the two classes, and characterize strategy-proof mechanisms by using monotonicity of the mechanisms and continuity of the indirect preference correspondences. We also provide a computationally tractable optimization program to compute the optimal mechanism. We do not use revenue equivalence and virtual valuations as tools in our proofs. Our proof techniques bring out the geometric interaction between the single-crossing property and the positions of bundles $(t,q)$s. Our proofs are simple and provide computationally tractable optimization program to compute the optimal mechanism. The extension of the optimization program to the $n-$ buyer environment is immediate.",econ.TH
The Impact of Green Investors on Stock Prices,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4794366,2024-04-15 09:40:00,06/07/2024 16:32,Manual,"Gong Cheng, Eric Jondeau, Beno&icirc;t Mojon, Dimitri  Vayanos","We study the impact of green investors on stock prices in a dynamic equilibrium model where investors are green, passive or active. Green investors track an index that progressively excludes the stocks of the brownest firms; passive investors hold a value-weighted index of all stocks; and active investors hold a mean-variance efficient portfolio of all stocks. Contrary to the literature, we find large drops in the stock prices of the brownest firms and moderate increases for greener firms. These effects occur primarily upon the announcement of the green index&apos;s formation and continue during the exclusion phase. The announcement effects imply a first-mover advantage to early adopters of decarbonisation strategies.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32317"" target=""_blank"">www.nber.org</a>.<br />",
Options Pricing under Bayesian MS-VAR Process,https://arxiv.org/abs/2109.05998,,06/17/2024 09:22,randomForestClassifier,Battulga Gankhuu,"In this paper, we have studied option pricing methods that are based on a Bayesian Markov-Switching Vector Autoregressive (MS--BVAR) process using a risk-neutral valuation approach. A BVAR process, which is a special case of the Bayesian MS--VAR process is widely used to model interdependencies of economic variables and forecast economic variables. Here we assumed that a regime-switching process is generated by a homogeneous Markov process and a residual process follows a conditional heteroscedastic model. With a direct calculation and change of probability measure, for some frequently used options, we derived pricing formulas. An advantage of our model is it depends on economic variables and is easy to use compared to previous option pricing papers, which depend on regime-switching.",q-fin.MF
A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set,https://arxiv.org/abs/2405.20124,,06/03/2024 00:00,Manual,"Man-Chung Yue, Yves Rychener, Daniel Kuhn, Viet Anh Nguyen","The state-of-the-art methods for estimating high-dimensional covariance matrices all shrink the eigenvalues of the sample covariance matrix towards a data-insensitive shrinkage target. The underlying shrinkage transformation is either chosen heuristically - without compelling theoretical justification - or optimally in view of restrictive distributional assumptions. In this paper, we propose a principled approach to construct covariance estimators without imposing restrictive assumptions. That is, we study distributionally robust covariance estimation problems that minimize the worst-case Frobenius error with respect to all data distributions close to a nominal distribution, where the proximity of distributions is measured via a divergence on the space of covariance matrices. We identify mild conditions on this divergence under which the resulting minimizers represent shrinkage estimators. We show that the corresponding shrinkage transformations are intimately related to the geometrical properties of the underlying divergence. We also prove that our robust estimators are efficiently computable and asymptotically consistent and that they enjoy finite-sample performance guarantees. We exemplify our general methodology by synthesizing explicit estimators induced by the Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical experiments based on synthetic and real data show that our robust estimators are competitive with state-of-the-art estimators.","stat.ML, cs.LG, math.OC"
Foreign Economic Policy Uncertainty and the U.S. Equity Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4863263,2024-06-19 13:09:00,06/20/2024 10:08,randomForestClassifier,"Mohammad R. Jahan-Parvar, Yuriy Kitsul, Jamil Rahman, Beth Anne Wilson","We document the predictive ability and economic significance of foreign economic policy uncertainty (EPU F) for U.S. equity returns. We find that it has significant predictive power for aggregate stock returns and returns of portfolios constructed on various pricing factors including but not limited to operating profitability, investment, capital expenditure, and foreign sales in 6 to 12-months-ahead horizons. We find that EPU F shocks operate through firms' cash flow channel, they do not affect discount rates or equity premia, and that an adverse EPU F shock alters the aggregate credit demand and investment outlays, but does not affect labor demand significantly.",
ForecastGrapher: Redefining Multivariate Time Series Forecasting with Graph Neural Networks,https://arxiv.org/abs/2405.18036,,06/03/2024 00:00,Manual,"Wanlin Cai, Kun Wang, Hao Wu, Xiaoxu Chen, Yuankai Wu","The challenge of effectively learning inter-series correlations for multivariate time series forecasting remains a substantial and unresolved problem. Traditional deep learning models, which are largely dependent on the Transformer paradigm for modeling long sequences, often fail to integrate information from multiple time series into a coherent and universally applicable model. To bridge this gap, our paper presents ForecastGrapher, a framework reconceptualizes multivariate time series forecasting as a node regression task, providing a unique avenue for capturing the intricate temporal dynamics and inter-series correlations. Our approach is underpinned by three pivotal steps: firstly, generating custom node embeddings to reflect the temporal variations within each series; secondly, constructing an adaptive adjacency matrix to encode the inter-series correlations; and thirdly, augmenting the GNNs' expressive power by diversifying the node feature distribution. To enhance this expressive power, we introduce the Group Feature Convolution GNN (GFC-GNN). This model employs a learnable scaler to segment node features into multiple groups and applies one-dimensional convolutions with different kernel lengths to each group prior to the aggregation phase. Consequently, the GFC-GNN method enriches the diversity of node feature distribution in a fully end-to-end fashion. Through extensive experiments and ablation studies, we show that ForecastGrapher surpasses strong baselines and leading published techniques in the domain of multivariate time series forecasting.",cs.LG
SAGDFN: A Scalable Adaptive Graph Diffusion Forecasting Network for Multivariate Time Series Forecasting,https://arxiv.org/abs/2406.12282,,06/19/2024 09:37,Manual,"Yue Jiang, Xiucheng Li, Yile Chen, Shuai Liu, Weilong Kong, Antonis F. Lentzakis, Gao Cong","Time series forecasting is essential for our daily activities and precise modeling of the complex correlations and shared patterns among multiple time series is essential for improving forecasting performance. Spatial-Temporal Graph Neural Networks (STGNNs) are widely used in multivariate time series forecasting tasks and have achieved promising performance on multiple real-world datasets for their ability to model the underlying complex spatial and temporal dependencies. However, existing studies have mainly focused on datasets comprising only a few hundred sensors due to the heavy computational cost and memory cost of spatial-temporal GNNs. When applied to larger datasets, these methods fail to capture the underlying complex spatial dependencies and exhibit limited scalability and performance. To this end, we present a Scalable Adaptive Graph Diffusion Forecasting Network (SAGDFN) to capture complex spatial-temporal correlation for large-scale multivariate time series and thereby, leading to exceptional performance in multivariate time series forecasting tasks. The proposed SAGDFN is scalable to datasets of thousands of nodes without the need of prior knowledge of spatial correlation. Extensive experiments demonstrate that SAGDFN achieves comparable performance with state-of-the-art baselines on one real-world dataset of 207 nodes and outperforms all state-of-the-art baselines by a significant margin on three real-world datasets of 2000 nodes.",cs.LG
Financial Assets Dependency Prediction Utilizing Spatiotemporal Patterns,https://arxiv.org/abs/2406.11886,,06/19/2024 09:37,Manual,"Haoren Zhu, Pengfei Zhao, Wilfred Siu Hung NG, Dik Lun Lee","Financial assets exhibit complex dependency structures, which are crucial for investors to create diversified portfolios to mitigate risk in volatile financial markets. To explore the financial asset dependencies dynamics, we propose a novel approach that models the dependencies of assets as an Asset Dependency Matrix (ADM) and treats the ADM sequences as image sequences. This allows us to leverage deep learning-based video prediction methods to capture the spatiotemporal dependencies among assets. However, unlike images where neighboring pixels exhibit explicit spatiotemporal dependencies due to the natural continuity of object movements, assets in ADM do not have a natural order. This poses challenges to organizing the relational assets to reveal better the spatiotemporal dependencies among neighboring assets for ADM forecasting. To tackle the challenges, we propose the Asset Dependency Neural Network (ADNN), which employs the Convolutional Long Short-Term Memory (ConvLSTM) network, a highly successful method for video prediction. ADNN can employ static and dynamic transformation functions to optimize the representations of the ADM. Through extensive experiments, we demonstrate that our proposed framework consistently outperforms the baselines in the ADM prediction and downstream application tasks. This research contributes to understanding and predicting asset dependencies, offering valuable insights for financial market participants.","cs.LG, cs.AI, cs.CE, q-fin.CP"
Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation,https://arxiv.org/abs/2405.19383,,06/03/2024 00:00,Manual,"Bruno Deprez, Toon Vanderschueren, Wouter Verbeke, Bart Baesens, Tim Verdonck","Money laundering presents a pervasive challenge, burdening society by financing illegal activities. To more effectively combat and detect money laundering, the use of network information is increasingly being explored, exploiting that money laundering necessarily involves interconnected parties. This has lead to a surge in literature on network analytics (NA) for anti-money laundering (AML). The literature, however, is fragmented and a comprehensive overview of existing work is missing. This results in limited understanding of the methods that may be applied and their comparative detection power. Therefore, this paper presents an extensive and systematic review of the literature. We identify and analyse 97 papers in the Web of Science and Scopus databases, resulting in a taxonomy of approaches following the fraud analytics framework of Bockel-Rickermann et al.. Moreover, this paper presents a comprehensive experimental framework to evaluate and compare the performance of prominent NA methods in a uniform setup. The framework is applied on the publicly available Elliptic data set and implements manual feature engineering, random walk-based methods, and deep learning GNNs. We conclude from the results that network analytics increases the predictive power of the AML model with graph neural networks giving the best results. An open source implementation of the experimental framework is provided to facilitate researchers and practitioners to extend upon these results and experiment on proprietary data. As such, we aim to promote a standardised approach towards the analysis and evaluation of network analytics for AML.","cs.SI, cs.LG"
SpotV2Net: Multivariate Intraday Spot Volatility Forecasting via Vol-of-Vol-Informed Graph Attention Networks,https://arxiv.org/abs/2401.06249,,06/17/2024 09:22,Manual,"Alessio Brini, Giacomo Toscano","This paper introduces SpotV2Net, a multivariate intraday spot volatility forecasting model based on a Graph Attention Network architecture. SpotV2Net represents assets as nodes within a graph and includes non-parametric high-frequency Fourier estimates of the spot volatility and co-volatility as node features. Further, it incorporates Fourier estimates of the spot volatility of volatility and co-volatility of volatility as features for node edges, to capture spillover effects. We test the forecasting accuracy of SpotV2Net in an extensive empirical exercise, conducted with the components of the Dow Jones Industrial Average index. The results we obtain suggest that SpotV2Net yields statistically significant gains in forecasting accuracy, for both single-step and multi-step forecasts, compared to a panel heterogenous auto-regressive model and alternative machine-learning models. To interpret the forecasts produced by SpotV2Net, we employ GNNExplainer \citep{ying2019gnnexplainer}, a model-agnostic interpretability tool, and thereby uncover subgraphs that are critical to a node's predictions.","q-fin.ST, q-fin.CP"
Resurrecting Earnings-to-Price with Machine Learning Robust Control for Outliers,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4746580,2024-03-25 16:22:00,06/07/2024 16:34,Manual,"R. Douglas Martin, John Guerard, Daniel Xia","We introduce a machine learning optimal robust cross-section regression method (mOpt) to control for outliers. The mOpt method shows that, when used in single and multi-factor models, the earnings-to-price factor (EP), and a composite earnings forecasts, revisions, and breadth factor (CTEF), are statistically significant for the CRSP® , R3000 and R2000 universes for the time periods 1980 - 2007 and 2008 – 2020. Due to adverse influence of outliers, the LS regressions with 1% Winsorization fail to show that EP and CTEF are significant factors. Moreover, the mOpt method is a powerful diagnostic method for assessing overlooked outliers influence on LS results.",
Fama-MacBeth Regression with Asset Pricing Restriction,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4826225,2024-05-14 16:09:00,06/20/2024 14:43,randomForestClassifier,"Yuanqi Yang, Guofu Zhou, Yifeng Zhu","In this paper, we propose a modified Fama-MacBeth regression that incorporates asset pricing restrictions into the estimation. The restrictions require the model to explain both the time series and cross-sectional variations, and also to select factors for sparsity. Solving the estimation via a least angle regression-type algorithm, we find empirically that the new model outperforms existing factor selection methodologies in predicting the cross-sectional stock returns. In addition, we propose new interpretable characteristics-based factors, and our factors outperform classical factors models.",
Hedging of Fixing Exposure,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4796356,2024-04-24 18:26:00,06/20/2024 14:47,randomForestClassifier,"Johannes Muhle-Karbe, Roel C. A. Oomen, Benjamin Weber","FX fixings are an indispensable and widely used reference rate in a market that trades continuously without an official close. Yet, a dealer's handling of fix transactions is a much debated topic. Especially when exposure to the fix is large relative to available market liquidity and hedging may extend to the pre-fix window, an inherent conflict of interest can arise between dealer and client. In this paper we use a model with permanent and transient market impact to characterise a dealer's optimal strategy to hedge fixing exposure. We show that smaller fix exposures are fully hedged over the calculation window, but that larger fix transactions are optimally hedged over a longer horizon that includes the pre-fix window. A client's all-in transaction costs can be lowered by pre-fix hedging when transient impact decays sufficiently quickly and dominates permanent impact.",
Bottom Up vs Top Down: What Does Firm 10-K Tell Us?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4747519,2024-04-04 21:18:00,06/20/2024 14:43,randomForestClassifier,"Landon Ross, Jim Horn, Mert Pilanci, KaiHong Luo, Guofu Zhou","In contrast to the recent increasing focus on large languages model,  we propose a bottom-up approach that exploits the individual predictive power of each word.  Our word dictionary is constructed by using a  data-driven approach, and it is these selected words that are used to build the predictive model with lasso regularized regressions and large panels of word counts. We find that our approach effectively estimates the cross-section of stocks' expected returns,  so that a factor that summarizes the information generates economically and statistically significant returns, and these returns are largely unexplained by standard factor models. However, an inspection of the factor dictionary indicates the element contains many words with possible risk-related interpretations, such as currency, oil, research, and restructuring, which increase a stock's expected return, while the words acquisition, completed, derivatives, and quality decrease the expected return.",
Pricing VIX options under the Heston-Hawkes stochastic volatility model,https://arxiv.org/abs/2406.13508,,06/21/2024 09:48,randomForestClassifier,Oriol Zamora Font,"We derive a semi-analytical pricing formula for European VIX call options under the Heston-Hawkes stochastic volatility model introduced in arXiv:2210.15343. This arbitrage-free model incorporates the volatility clustering feature by adding an independent compound Hawkes process to the Heston volatility. Using the Markov property of the exponential Hawkes an explicit expression of $\text{VIX}^2$ is derived as a linear combination of the variance and the Hawkes intensity. We apply qualitative ODE theory to study the existence of some generalized Riccati ODEs. Thereafter, we compute the joint characteristic function of the variance and the Hawkes intensity exploiting the exponential affine structure of the model. Finally, the pricing formula is obtained by applying standard Fourier techniques.",q-fin.MF
One Factor to Bind the Cross-Section of Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4802579,2024-04-23 10:07:00,06/20/2024 14:40,randomForestClassifier,"Nicola Borri, Denis Chetverikov, Yukun Liu, Aleh Tsyvinski","We propose a new non-linear single-factor asset pricing model. Despite its parsimony, this model represents exactly any non-linear model with an arbitrary number of factors and loadings – a consequence of the Kolmogorov-Arnold representation theorem. It features only one pricing component comprising a nonparametric link function of the time-dependent factor and factor loading that we jointly estimate with sieve-based estimators. Using 171 assets across major classes, our model delivers superior cross-sectional performance with a low-dimensional approximation of the link function. Most known finance and macro factors become insignificant controlling for our single-factor.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32365"" target=""_blank"">www.nber.org</a>.<br />",
Finding value in the U.S. corporate bond market,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4852548,2024-06-05 20:41:00,06/20/2024 14:50,randomForestClassifier,"Liuren Wu, Hashim Zaman","This paper identifies value-investing opportunities in the U.S. corporate bond market through the joint construction of a bond valuation model and a return factor model. The valuation model explains the cross-sectional corporate bond yield variation with a flexible functional form in bond risk characteristics including bond duration, credit rating, historical yield change volatility, bond liquidity, and the optionality-induced yield spread adjustment for callable bonds. The return factor model embeds the residual from the valuation model as a mispricing factor while capturing the stronger co-movements between bonds from the same industry, similar rating classes, and similar duration segments, and accounting for differential pricing of bond return risk, liquidity cost, and the optionality exposure. Historical analysis over the past two decades shows that the valuation model can explain the cross-sectional bond yield variation very well, and the value-investing portfolio constructed from the return factor model generates highly positive average excess returns with low risk.",
Leading Stocks and the Stock Market Expected Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4768908,2024-04-15 07:59:00,06/20/2024 14:43,randomForestClassifier,"Zhuo Chen, Xianfeng Hao, Honghai Yu, Guofu Zhou","We identify leading stocks using machine learning and show that these leaders have closer link to the expected market returns than those from existing methods. We find that the negative leaders, which lead other stocks negatively, have a strong predictive power on the future stock market returns both in- and out-of-sample, whereas the positive leaders do not. The predictability generates significant economic value to a mean-variance investor in asset allocation. Economically, underreaction of the followers appears the driving force for the predictability. Our study provides the first empirical evidence that bridges the lead-lag literature to market predictability.",
No Sparsity in Asset Pricing: Evidence from a Generic Statistical Test,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4730259,2024-03-26 14:51:00,06/20/2024 14:43,randomForestClassifier,"Junnan He, Lingxiao Zhao, Guofu Zhou","We provide a generic statistical test to discern whether there is sparsity in high-dimensional characteristic-based factor models. Applying the test with both industry and ""pseudo"" random portfolios as test assets, we find that the null hypothesis — suggesting fewer than ten factors are capable of explaining the cross-section of equity returns — is rejected. Moreover, a dense model representation outperforms sparse models in pricing the cross-section and as an investment strategy. Furthermore, we explore novel test assets constructed using tree-based models (P-Tree). Our conclusion still holds when a multitude of firm characteristics are used in the construction of P-Tree portfolios. Overall, there is no sparsity in asset pricing in the large space of characteristic-based factors.",
Strong existence and uniqueness of a calibrated local stochastic volatility model,https://arxiv.org/abs/2406.14074,,06/21/2024 09:48,randomForestClassifier,Scander Mustapha,"We study a two-dimensional McKean-Vlasov stochastic differential equation, whose volatility coefficient depends on the conditional distribution of the second component with respect to the first component. We prove the strong existence and uniqueness of the solution, establishing the well-posedness of a two-factor local stochastic volatility (LSV) model calibrated to the market prices of European call options. In the spirit of [Jourdain and Zhou, 2020, Existence of a calibrated regime switching local volatility model.], we assume that the factor driving the volatility of the log-price takes finitely many values. Additionally, the propagation of chaos of the particle system is established, giving theoretical justification for the algorithm [Julien Guyon and Henry-Labord\`ere, 2012, Being particular about calibration.].","math.PR, math.AP, q-fin.MF"
Robust Lambda-quantiles and extreme probabilities,https://arxiv.org/abs/2406.13539,,06/21/2024 09:48,randomForestClassifier,"Xia Han, Peng Liu","In this paper, we investigate the robust models for $\Lambda$-quantiles with partial information regarding the loss distribution, where $\Lambda$-quantiles extend the classical quantiles by replacing the fixed probability level with a probability/loss function $\Lambda$. We find that, under some assumptions, the robust $\Lambda$-quantiles equal the $\Lambda$-quantiles of the extreme probabilities. This finding allows us to obtain the robust $\Lambda$-quantiles by applying the results of robust quantiles in the literature. Our results are applied to uncertainty sets characterized by three different constraints respectively: moment constraints, probability distance constraints via Wasserstein metric, and marginal constraints in risk aggregation. We obtain some explicit expressions for robust $\Lambda$-quantiles by deriving the extreme probabilities for each uncertainty set. Those results are applied to optimal portfolio selection under model uncertainty.",q-fin.MF
Firm Complexity and Information Asymmetry: Evidence from ML-based Complexity to Measure Information Processing Costs,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4763575,2024-03-25 16:13:00,06/20/2024 14:42,randomForestClassifier,"Brian J. Clark, Sai Palepu, Akhtar R. Siddique","We investigate the role of machine learning (ML) model complexity in capturing the information processing costs that lead to information asymmetry in financial markets. The basic idea is that informed traders are better suited to process complex, non-linear relations between observable characteristics and future returns. As such, we propose and compute an ML-derived complexity metric to capture the magnitude of the relative advantage informed traders have over noise traders.  We hypothesize that increased model complexity leads to increased information asymmetry. To this end, we show that our model complexity metric is positively associated with several well-known proxies of information asymmetry. Specifically, we find positive relations between firm complexity and future return volatility, wider bid-ask spreads and elevated probabilities of informed trading (PIN).",
Why Do Mutual Funds Invest in Treasury Futures?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4832424,2024-05-20 11:49:00,06/20/2024 14:54,randomForestClassifier,"Benjamin Iorio, Dan Li, Lubomir Petrasek","Asset managers’ net long positions in Treasury futures have reached their historical highs in recent months, driven in part by mutual funds’ demand for short- and medium-term Treasury futures. Analyzing mutual fund portfolio holdings reports on SEC Form N-PORT, we find that the increase in mutual funds’ futures holdings since 2020 can be attributed to both increased demand for Treasury exposures during a higher interest rate environment and mutual funds’ preference for sourcing these exposures through futures rather than securities.",
Innocuous Noise? Social Media and Asset Prices,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4747878,2024-04-05 21:03:00,06/20/2024 14:47,randomForestClassifier,"Namho Kang, Xiaoxia Lou, Gideon Ozik, Ronnie Sadka, Siyi Shen","This paper demonstrates that intense discussion on the Reddit social media platform reduces stock price informativeness. Increased social discussion reduces pre-earnings abnormal turnover and pre-earnings return drift and higher earnings response coefficients, indicating reduced price informativeness prior to announcements. Social discussion results in a delayed price correction of up to two months of well-documented anomalies; a corresponding trading strategy earns about 1% monthly. Traditional media do not generate similar effects, while the use of emojis intensifies it. Furthermore, firm managers rely less on stock prices in making firm real decisions when the stock is heavily discussed on social media. The findings suggest reduced production of value-relevant information in the presence of intense social discussion, highlighting the importance of understanding the emergence of such discussion.",
Matrix-based Prediction Approach for Intraday Instantaneous Volatility Vector,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4747889,2024-04-01 16:53:00,06/20/2024 14:51,randomForestClassifier,"Sung Hoon Choi, Donggyu Kim","In this paper, we introduce a novel method for predicting intraday instantaneous volatility based on Ito semimartingale models using high-frequency financial data. Several studies have highlighted stylized volatility time series features, such as interday auto-regressive dynamics and the intraday U-shaped pattern. To accommodate these volatility features, we propose an interday-by-intraday instantaneous volatility matrix process that can be decomposed into low-rank conditional expected instantaneous volatility and noise matrices. To predict the low-rank conditional expected instantaneous volatility matrix, we propose the Two-sIde Projected-PCA (TIP-PCA) procedure. We establish asymptotic properties of the proposed estimators and conduct a simulation study to assess the finite sample performance of the proposed prediction method. Finally, we apply the TIP-PCA method to an out-of-sample instantaneous volatility vector prediction study using high-frequency data from the S&amp;P 500 index and 11 sector index funds.",
Regime-Based Strategic Asset Allocation,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4801115,2024-04-22 20:09:00,06/20/2024 14:40,randomForestClassifier,"Eric Bouy&eacute;, Jerome Teiletche","What should investors do in the presence of economic regimes? Researchers and practitioners usually address this topic from a tactical asset allocation point of view. In this article, we depart from the literature by tackling the issue strategically and analytically. Modeling economic regimes as a mixture of distributions, we first investigate what happens to moments of the distribution of returns. We next deduct the implications for portfolios built under popular asset allocation methodologies (mean-variance-optimization, risk budgeting). Using these analytical results, we define new portfolio construction methodologies seeking to exploit the information in macroeconomic (macro) regimes through the composition of optimal portfolios for each regime, the risk structure of these portfolios, and the long-term probability of the regimes. We empirically show that macro regime-based portfolios can outperform traditional asset-based portfolios, for both multi-asset and equity factor universes, over a sample of more than fifty years.",
Liquidity Dynamics in RFQ Markets and Impact on Pricing,https://arxiv.org/abs/2309.04216,,06/21/2024 09:48,randomForestClassifier,"Philippe Bergault, Olivier Gu\'eant","To assign a value to a portfolio, it is common to use Mark-to-Market prices. However, how should one proceed when the securities are illiquid? When transaction prices are scarce, how can one use all the available real-time information? In this article, we address these questions for over-the-counter (OTC) markets based on requests for quotes (RFQs). We extend the concept of micro-price, which was recently introduced for assets exchanged through limit order books in the market microstructure literature, and incorporate ideas from the recent literature on OTC market making. To account for liquidity imbalances in RFQ markets, we use an approach based on bidimensional Markov-modulated Poisson processes. Beyond extending the concept of micro-price to RFQ markets, we introduce the new concept of Fair Transfer Price. Our concepts of price can be used to value securities fairly, even when the market is relatively illiquid and/or tends to be one-sided.","q-fin.TR, q-fin.ST"
Emotions and Stock Returns during the GameStop Bubble,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4795372,2024-04-16 18:25:00,06/20/2024 14:44,randomForestClassifier,"Adrian Fernandez-Perez, Ivan Indriawan, Marta Khomyn","We investigate the role of emotions in driving the stock returns of GameStop (GME) during the GME price bubble in January-February 2021. Our analysis encompasses the eight basic emotions (anger, anticipation, disgust, fear, joy, sadness, surprise, and trust) referred to as the profile of mood states (POMS). Using the textual analysis of Reddit posts, we find that fear strongly predicts the intraday GME return. We also find that the predictive relation from emotion to returns varies in the time series: joy has the strongest relation just before the GME bubble peaks, fear at the bubble’s peak, and anger just after the bubble bursts. These findings shed light on the psychological underpinnings of trading surrounding the stock bubbles.",
"Utility maximization in constrained and unbounded financial markets: Applications to indifference valuation, regime switching, consumption and Epstein-Zin recursive utility",https://arxiv.org/abs/1707.00199,,06/21/2024 09:48,randomForestClassifier,"Ying Hu, Gechun Liang, Shanjian Tang","This memoir presents a systematic study of utility maximization problems for an investor in constrained and unbounded financial markets. Building upon the foundational work of Hu et al. (2005) [Ann. Appl. Probab., 15, 1691--1712] in a bounded framework, we extend our analysis to more challenging unbounded cases. Our methodology combines quadratic backward stochastic differential equations with unbounded solutions and convex duality methods. Central to our approach is the verification of the finite entropy condition, which plays a pivotal role in solving the underlying utility maximization problems and establishing the martingale property and convex duality representation of the value processes. Through four distinct applications, we first study utility indifference valuation of financial derivatives with unbounded payoffs, uncovering novel asymptotic behavior as the risk aversion parameter approaches zero or infinity. Furthermore, we study the regime switching market model with unbounded random endowments and consumption-investment problems with unbounded random endowments, both constrained to portfolios chosen from a convex and closed set. Finally, we investigate investment-consumption problems involving an investor with Epstein-Zin recursive utility in an unbounded financial market.","math.PR, q-fin.MF"
The Inconsistency between Model R2 and Portfolio Sharpe Ratio: A Perspective from Imbalanced Learning,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4769748,2024-04-15 17:28:00,06/20/2024 14:46,randomForestClassifier,"Xinjie Wang, Suyang Zhao","It is a common practice to evaluate asset pricing models by model R2. We show that optimizing R2 does not necessarily lead to the highest Sharpe ratio of long-short portfolios, especially in high-dimensional settings. This inconsistency stems from the conflict between the skewed distribution of stock returns and investors’ stock allocation preference. We introduce resample-based methods to address the inconsistency and the out-of-sample Sharpe ratio is significantly improved. The resample-based methods improve the pricing accuracy of stocks in long-short portfolios and perform well during crisis periods. The performance improvement is likely due to more exposure on small stocks and capturing near-arbitrage opportunities.",
A Collection of Wisdom in Predicting Sector Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4837127,2024-05-22 02:20:00,06/20/2024 14:43,Manual,"Hsiu-Lang Chen, Jolana Stejskalova","This study investigates whether the aggregate investor information demand for all stocks in a sector demonstrated in Google search volume index (SVI) can predict the sector’s performance. The evidence shows that a sector’s abnormal SVI can predict the sector’s performance next month, even after controlling for the sector’s contemporaneous standardized unexpected earnings and lagged returns on both the market and the sector. A partial reversal in the sector’s long-run performance performance is not consistent with the price pressure hypothesis. This indicates that some fundamental information about a sector can be captured by the sector’s abnormal SVI on a timely basis.",
Approximate Factor Models for Functional Time Series,https://arxiv.org/abs/2201.02532,,06/03/2024 00:00,Manual,"Sven Otto, Nazarii Salish",We propose a novel approximate factor model tailored for analyzing time-dependent curve data. Our model decomposes such data into two distinct components: a low-dimensional predictable factor component and an unpredictable error term. These components are identified through the autocovariance structure of the underlying functional time series. The model parameters are consistently estimated using the eigencomponents of a cumulative autocovariance operator and an information criterion is proposed to determine the appropriate number of factors. The methodology is applied to yield curve modeling and forecasting. Our results indicate that more than three factors are required to characterize the dynamics of the term structure of bond yields.,"econ.EM, stat.ME"
Decomposing Informed Trading in Equity Options,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4765294,2024-03-30 11:51:00,06/20/2024 14:51,randomForestClassifier,"Felipe Asencio, Alejandro Bernales, Daniel Gonz&aacute;lez, Richard Holowczak, Thanos Verousis","We develop a multi-asset model to decompose informed trading into the components concerning the underlying stock value and the volatility in equity options. We isolate the stock value and volatility components by characterizing their distinct intraday price responses in contracts with different option deltas and vegas, respectively. The stock value (volatility) component represents on average 40.5% (19.0%) of the option spread. In daily empirical applications, we also show that informed trading components anticipate a 'Volmageddon' high-volatility event, and an increase in straddle trades is associated with a reduction (growth) in the relative contribution of the stock value (volatility) informed trading.",
Matrix-Based Prediction Approach for Intraday Instantaneous Volatility Vector,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4777395,2024-03-29 02:23:00,06/20/2024 14:51,randomForestClassifier,"Sung Hoon Choi, Donggyu Kim","In this paper, we introduce a novel method for predicting intraday instantaneous volatility based on Itˆo semimartingale models using high-frequency financial data. Several studies have highlighted stylized volatility time series features, such as interday auto-regressive dynamics and the intraday U-shaped pattern. To accommodate these volatility features, we propose an interday-by-intraday instantaneous volatility matrix process that can be decomposed into low-rank conditional expected instantaneous volatility and noise matrices. To predict the low-rank conditional expected instantaneous volatility matrix, we propose the Two-sIde Projected-PCA (TIP-PCA) procedure. We establish asymptotic properties of the proposed estimators and conduct a simulation study to assess the finite sample performance of the proposed prediction method. Finally, we apply the TIP-PCA method to an out-of-sample instantaneous volatility vector prediction study using high-frequency data from the S&amp;P 500 index and 11 sector index funds.",
Beta Uncertainty as an Arbitrage Barrier and the Level of Anomaly Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4778064,2024-04-15 14:36:00,06/20/2024 14:49,randomForestClassifier,"Ronald J. Balvers, Yufeng  Han, Ou Hu, Zhaodan Huang","When facing uncertainty surrounding the risk loading, or beta uncertainty, arbi- trageurs allocate less arbitrage capital to anomalies. In this paper, we introduce a Beysian stochastic CAPM that explicitly accommodates separate random processes in beta and idiosyncratic volatility to estimate beta uncertainty in anomaly portfolios. We provide both theoretical and empirical evidence that beta uncertainty serves as arbitrage barriers to slow down arbitrage activities and thus is positively associated with future anomaly returns. We extend the analysis to firm level and show that beta uncertainty amplifies the effect of mispricing score on stock returns and reduces short selling activities. We also discuss the high correlation between beta uncertainty and idiosyncratic risk and the pitfalls of conventional estimation.",
Do Hedge Funds Shape  Merger Payment?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4850548,2024-05-31 23:18:00,06/20/2024 14:50,randomForestClassifier,"Ning Gao, Olga Kolokolova, Achim Mattes, Lijie Yu","Using a sample of mergers and acquisitions along with hedge fund holdings from 2000 to 2019, we find that pre-merger hedge fund holdings in target firms increase the proportion of the payment made in cash and decrease the premium, shorten the deal duration, and predict better post-merger performance of the combined firm. The trade-off between cash payment and premium is predominantly pronounced when hedge funds&apos; preference for cash is aligned with bidders&apos; willingness to accommodate it. In cases where bidders have a stronger preference to pay in stock due to its high overvaluation, hedge fund holdings do not increase the fraction of cash, which would have been beneficial for other target investors.",
Detecting asset price bubbles using deep learning,https://arxiv.org/abs/2210.01726,,06/21/2024 09:48,randomForestClassifier,"Francesca Biagini, Lukas Gonon, Andrea Mazzon, Thilo Meyer-Brandis","In this paper we employ deep learning techniques to detect financial asset bubbles by using observed call option prices. The proposed algorithm is widely applicable and model-independent. We test the accuracy of our methodology in numerical experiments within a wide range of models and apply it to market data of tech stocks in order to assess if asset price bubbles are present. Under a given condition on the pricing of call options under asset price bubbles, we are able to provide a theoretical foundation of our approach for positive and continuous stochastic asset price processes. When such a condition is not satisfied, we focus on local volatility models. To this purpose, we give a new necessary and sufficient condition for a process with time-dependent local volatility function to be a strict local martingale.",q-fin.MF
Predict Stock Return Variance Across the Information Cycle,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4743522,2024-02-29 20:26:00,06/20/2024 14:50,randomForestClassifier,"Liuren Wu, Yaofei Xu","This paper uses historical variance term structures to characterize the different phases of a company’s information cycle, and shows that the up and down phases of the information cycle experience different durations, with the up phase fast but the down phase slow. The paper proposes a conditional variance dynamics to capture the dynamics variation across the information cycle, and develops a two-dimensional conditional pooling estimation approach that balances the needs for reducing estimation errors and accommodating conditional dynamics variation. As an application, the paper finds that classic asset pricing relations can vary strongly across the information cycle.",
Option Expected Hedging Demand,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4729672,2024-03-07 13:16:00,06/20/2024 14:43,randomForestClassifier,"Xiaoxiao Tang, Guofu Zhou, Zhaoque (Chosen) Zhou","The increasing option volume and ratio of option volume to stock volume in recent year indicate that options market makers' delta hedging has a growing impact on underlying stock prices. We introduce a novel approach utilizing real-time options information to calculate the spot elasticity of delta (ED) and expected hedging demand (EHD). Empirical results show that the EHD significantly predicts future stock returns in the cross section and such a positive impact on stock prices lasts up to five trading days and then a reversal follows. The empirical evidence of heterogeneous EHD-return relationship, influenced by ED, leads to varied options market maker behaviors and is consistent with conventional economic theory. Finally, we conclude that EHD has a minimal correlation with other popular firm characteristics.",
Empirical Asset Pricing with Probability Forecasts,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4717935,2024-02-28 19:14:00,06/20/2024 14:43,randomForestClassifier,"Songrun He, Linying Lv, Guofu Zhou","We study probability forecasts in the context of cross-sectional asset pricing with a large number of firm characteristics. Empirically, we find that a simple probability forecast model can surprisingly perform as well as a sophisticated probability forecast model, and all of which deliver long-short portfolios whose Sharpe ratios are comparable to those of the widely used return forecasts. Moreover, we show that combining probability forecasts with return forecasts yields superior portfolio performance versus using each type of forecast individually, suggesting that probability forecasts provide valuable information beyond return forecasts for our understanding of the cross-section of stock returns.",
Information Transmission in Stock and Bond Markets,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4728568,2024-03-05 13:59:00,06/07/2024 11:03,randomForestClassifier,"Allaudeen Hameed, Sheridan  Titman, Jason Zhanshun Wei, Huiping Zhang","Using a comprehensive dataset covering all U.S. corporate bonds, we study the informational efficiency of the stock prices manifested in the cross-market lead-lag relationship in bond and stock returns at the firm level. We find a robust predictive content of bond returns for future monthly stock returns, which is stronger in distressed market states, in firms with low credit quality, smaller size, poor liquidity and higher idiosyncratic risk. We attribute the slow adjustment in stock prices to information in bond prices to underreaction arising from overconfidence and limited attention of investors in the stock market.",
Quantifying Treasury Cash-Futures Basis Trades,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4759855,2024-03-15 12:11:00,06/20/2024 14:54,randomForestClassifier,"Jonathan Glicoes, Benjamin Iorio, Phillip Monin, Lubomir Petrasek","The Treasury cash-futures basis trade exploits the difference in prices between a Treasury security and a related Treasury futures contract – the so-called cash-futures basis – by purchasing the asset that is relatively undervalued and selling the other in a bet that the prices will converge. Basis traders support Treasury market functioning by keeping the prices of Treasury futures near their fair value relative to Treasury securities and by serving as an important source of demand for Treasury securities, including during the 2017-2019 period of quantitative tightening when basis traders absorbed much of the increased Treasury supply.",
Speculating on Higher Order Beliefs,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4728936,2024-03-14 19:14:00,06/07/2024 16:35,randomForestClassifier,"Paul Schmidt-Engelbertz, Kaushik Vasudevan","Higher order beliefs - beliefs about others' beliefs - may be important for trading behavior and asset prices, but have received little systematic empirical examination. We study more than twenty years of evidence from the Robert Shiller Investor Confidence surveys, which directly elicit details on investors' higher order beliefs about the U.S. stock market. We find that investors' higher order beliefs provide substantial motivations for non-fundamental speculation, e.g., to buy into a stock market perceived to be overvalued. To explore the general equilibrium implications, we construct a model of level k thinking that matches the evidence, where investors believe that asset price movements are driven by other, less sophisticated investors. The model reveals that investors' higher order beliefs amplify stock market overreaction and excess volatility. These phenomena persist in equilibrium due to investors' limited strategic reasoning.",
Does Peer-Reviewed Research Help Predict Stock Returns?,https://arxiv.org/abs/2212.10317,,06/24/2024 10:11,randomForestClassifier,"Andrew Y. Chen, Alejandro Lopez-Lira, Tom Zimmermann","Mining 29,000 accounting ratios for t-statistics over 2.0 leads to cross-sectional return predictability similar to the peer review process. For both methods, about 50% of predictability remains after the original sample periods. Predictors supported by peer-reviewed risk explanations or equilibrium models underperform other predictors post-sample, suggesting peer review systematically mislabels mispricing as risk, though only 20% of predictors are labelled as risk. Data mining generates other features of peer review including the rise in returns as original sample periods end and the speed of post-sample decay. It also uncovers themes like investment, issuance, and accruals -- decades before they are published.",q-fin.GN
Extrapolative Expectations and Corporate Risk Management,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4709420,2024-02-26 19:37:00,06/07/2024 16:35,randomForestClassifier,"Haibo Jiang, Nishad Kapadia, Yuhang Xing, YIFAN ZHANG","Aggregate gold hedging by producers more than doubled over the 1990s and declined by 90% over the 2000s. We find that extrapolative expectations explain this pattern -- hedging varies inversely with past gold returns. Consistent with manager price expectations influencing hedging, measures of expected gold returns and the futures basis predict hedge ratios. Analysts and investors also act as if their expectations are extrapolative. Hedging losses result in greater forced CEO turnover, consistent with shareholders attributing these losses to lack of skill. Standard motivations for risk management -- distress, investment, taxes, or financial constraints cannot explain the time-series of gold hedging.",
Analysis of Rare Events Using Multidimensional Liquidity Measures,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4751085,2024-03-15 20:05:00,06/07/2024 16:33,Manual,"Margarita Zaika, Dragos Bozdog, Ionut Florescu",In this paper we develop a framework for the analysis of high-frequency financial transaction data focused on the estimation of the multidimensional intraday liquidity measures and rare events analysis. A large number of liquidity measures based on Trade and Quote (TAQ) and Limit Order Book (LOB) datasets are consolidated to keep the most important characteristics through dimensionality reduction techniques.  Several outlier methods are implemented to identify rare liquidity events. The framework is applied to a sample transaction level data covering the beginning of COVID-19 outbreak period. A new measure is developed to assess and visualize extreme liquidity intensity.,
Securities Lending and Information Acquisition,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4752643,2024-03-08 11:30:00,06/07/2024 11:05,randomForestClassifier,"Stefan Greppmair, Stephan Jank, Pedro Saffi, Jason Sturgess","Using microdata on stock-level lending positions from German mutual funds, we show that active funds use the equity lending market to obtain information about short sale demand. Funds reduce long positions in response to these demand signals, which allows fund managers to front-run public disclosure of big short positions and avoid future losses. Fund managers exploit this information advantage across funds they manage, but do not share it within their fund family, consistent with short demand signals providing an information advantage. Our results suggest a new motive for securities lending and an information aggregation role for the equity lending market.",
Simulation of a Financial Market: The Possibility of Catastrophic Disequilibrium,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3823466,2024-03-13 15:40:00,06/07/2024 16:31,randomForestClassifier,Amit K. Sinha,"We use kinetic Monte Carlo simulations to produce solutions of an agent-based, rate equation model of an informationally efficient, closed financial market. The simulations produce a crash in the market that is forewarned through the observation of a market instability from which the market temporarily recovers. The market remained in a quasi-stable state for a relatively large amount of time between the warning and the crash, raising the prospect that some mitigating action can be taken in time to avert the impending crash. This result has strong ramifications for the future of predicting calamitous market events, especially if some observable aspect of financial markets can be positively identified and associated with simulation parameters.",
Dimensionality reduction techniques to support insider trading detection (Tecniche per la riduzione dimensionale dei dati a supporto del rilevamento dei casi di insider trading) Consob - Scuola Normale Superiore di Pisa,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4742484,2024-03-01 00:51:00,06/07/2024 16:37,randomForestClassifier,"Adele Ravagnani, Fabrizio Lillo, Paola Deriu, Piero Mazzarisi, Francesca Medda, Antonio Russo","<b>English Abstract</b>: Identification of market abuse is an extremely complicated activity that requires the analysis of large and complex datasets. We propose an unsupervised machine learning method for contextual anomaly detection, which allows to support market surveillance aimed at identifying potential insider trading activities. This method lies in the reconstruction-based paradigm and employs principal component analysis and autoencoders as dimensionality reduction techniques. The only input of this method is the trading position of each investor active on the asset for which we have a price sensitive event (PSE). After determining reconstruction errors related to the trading profiles, several conditions are imposed in order to identify investors whose behavior could be suspicious of insider trading related to the PSE. As a case study, we apply our method to investor resolved data of Italian stocks around takeover bids. <br /><br /><b>Italian Abstract</b>: L'identificazione degli abusi di mercato è un'attività estremamente complessa che richiede l'analisi di insiemi di dati grandi e complessi. Lo studio propone un metodo di apprendimento automatico non supervisionato per il rilevamento di anomalie contestuali, che fornisce un supporto alla vigilanza sui mercati finalizzata all'identificazione di potenziali attività di insider trading. Nello specifico, lo studio - basato su un data set anonimizzato - affronta il problema di identificazione di potenziali casi di insider trading e propone un metodo diverso rispetto ai precedenti studi che hanno fatto uso di tecniche di unsupervised machine learning: in questo caso, infatti, viene applicata la tecnica di decomposizione e successiva ricostruzione di una serie temporale di dati attraverso l’analisi delle “componenti principali” (PCA, Principal Component Analysis) e l’uso di autoencoders, in relazione alle posizioni assunte da gruppi di investitori in un determinato titolo azionario in prossimità di un evento price sensitive. L'unico input del metodo è la posizione di trading di ciascun investitore attivo sull'asset per il quale si è verificato un evento price sensitive (PSE). Dopo aver determinato gli errori di ricostruzione relativi ai profili di profili di trading, vengono imposte diverse condizioni al fine di identificare gli investitori il cui comportamento potrebbe essere sospetto di insider trading in relazione al PSE. In termini intuitivi, la logica che viene seguita nella procedura di identificazione di comportamenti anomali da parte degli investitori considera la posizione media ricostruita attraverso la tecnica PCA come rappresentativa di un’operatività normale. Qualsiasi scostamento nell’operatività di un singolo investitore dal comportamento medio ricostruito nel periodo di osservazione (che sia superiore ad una certa soglia di sensitività) viene segnalato dall’algoritmo come anomalo e potenzialmente meritevole di approfondimenti ulteriori attraverso tecniche di indagine “tradizionali”. Un risultato particolarmente significativo di questo studio è la soddisfacente convergenza dei risultati ottenuti con quelli derivati dall’applicazione delle tecniche di unsupervised machine learning descritte nel precedente paper “A machine learning approach to support decision in insider trading detection”, anch’esso frutto della collaborazione tra l’Istituto e la Scuola Normale Superiore di Pisa.",
Computing the SSR,https://arxiv.org/abs/2406.16131,,06/25/2024 10:07,randomForestClassifier,"Peter K. Friz, Jim Gatheral","The skew-stickiness-ratio (SSR), examined in detail by Bergomi in his book, is critically important to options traders, especially market makers. We present a model-free expression for the SSR in terms of the characteristic function. In the diffusion setting, it is well-known that the short-term limit of the SSR is 2; a corollary of our results is that this limit is $H+3/2$ where $H$ is the Hurst exponent of the volatility process. The general formula for the SSR simplifies and becomes particularly tractable in the affine forward variance case. We explain the qualitative behavior of the SSR with respect to the shape of the forward variance curve, and thus also path-dependence of the SSR.","q-fin.MF, q-fin.CP"
Stochastic Path-Dependent Volatility Models for Price-Storage Dynamics in Natural Gas Markets and Discrete-Time Swing Option Pricing,https://arxiv.org/abs/2406.16400,,06/25/2024 10:07,randomForestClassifier,"Jinniao Qiu, Antony Ware, Yang Yang","This paper is devoted to the price-storage dynamics in natural gas markets. A novel stochastic path-dependent volatility model is introduced with path-dependence in both price volatility and storage increments. Model calibrations are conducted for both the price and storage dynamics. Further, we discuss the pricing problem of discrete-time swing options using the dynamic programming principle, and a deep learning-based method is proposed for numerical approximations. A numerical algorithm is provided, followed by a convergence analysis result for the deep-learning approach.",q-fin.MF
Graphical copula GARCH modeling with dynamic conditional dependence,https://arxiv.org/abs/2406.15582,,06/25/2024 10:08,randomForestClassifier,"Lupe Shun Hin Chan, Amanda Man Ying Chu, Mike Ka Pui So","Modeling returns on large portfolios is a challenging problem as the number of parameters in the covariance matrix grows as the square of the size of the portfolio. Traditional correlation models, for example, the dynamic conditional correlation (DCC)-GARCH model, often ignore the nonlinear dependencies in the tail of the return distribution. In this paper, we aim to develop a framework to model the nonlinear dependencies dynamically, namely the graphical copula GARCH (GC-GARCH) model. Motivated from the capital asset pricing model, to allow modeling of large portfolios, the number of parameters can be greatly reduced by introducing conditional independence among stocks given some risk factors. The joint distribution of the risk factors is factorized using a directed acyclic graph (DAG) with pair-copula construction (PCC) to enhance the modeling of the tails of the return distribution while offering the flexibility of having complex dependent structures. The DAG induces topological orders to the risk factors, which can be regarded as a list of directions of the flow of information. The conditional distributions among stock returns are also modeled using PCC. Dynamic conditional dependence structures are incorporated to allow the parameters in the copulas to be time-varying. Three-stage estimation is used to estimate parameters in the marginal distributions, the risk factor copulas, and the stock copulas. The simulation study shows that the proposed estimation procedure can estimate the parameters and the underlying DAG structure accurately. In the investment experiment of the empirical study, we demonstrate that the GC-GARCH model produces more precise conditional value-at-risk prediction and considerably higher cumulative portfolio returns than the DCC-GARCH model.","stat.ME, stat.AP, stat.CO"
Hedging in Sequential Experiments,https://arxiv.org/abs/2406.15867,,06/25/2024 10:07,randomForestClassifier,"Thomas Cook, Patrick Flaherty","Experimentation involves risk. The investigator expends time and money in the pursuit of data that supports a hypothesis. In the end, the investigator may find that all of these costs were for naught and the data fail to reject the null. Furthermore, the investigator may not be able to test other hypotheses with the same data set in order to avoid false positives due to p-hacking. Therefore, there is a need for a mechanism for investigators to hedge the risk of financial and statistical bankruptcy in the business of experimentation.
  In this work, we build on the game-theoretic statistics framework to enable an investigator to hedge their bets against the null hypothesis and thus avoid ruin. First, we describe a method by which the investigator's test martingale wealth process can be capitalized by solving for the risk-neutral price. Then, we show that a portfolio that comprises the risky test martingale and a risk-free process is still a test martingale which enables the investigator to select a particular risk-return position using Markowitz portfolio theory. Finally, we show that a function that is derivative of the test martingale process can be constructed and used as a hedging instrument by the investigator or as a speculative instrument by a risk-seeking investor who wants to participate in the potential returns of the uncertain experiment wealth process. Together, these instruments enable an investigator to hedge the risk of ruin and they enable a investigator to efficiently hedge experimental risk.","q-fin.RM, stat.ME"
A Simple Responsive Covariance Matrix Forecaster for Multiple Horizons and Asset Classes,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4854248,2024-06-25 16:04:00,06/27/2024 08:54,randomForestClassifier,"Jorge Guijarro-Ordonez, Misha van Beek, Amandeep Dhaliwal","Forecasting covariance matrices across different investment horizons and asset classes is central for portfolio construction and risk analysis. However, the industry-standard methods have limitations when producing multi-horizon forecasts which are responsive, numerically stable, and consistently handle different asset classes. This paper proposes a simple solution to this problem through linearly blending basic time-series and cross-sectional forecasts, where the blending weights are statistically optimal and may depend on features. The resulting forecasts are economically intuitive, easy to compute at scale, and have strong theoretical guarantees. Empirically, our simple methodology substantially outperforms industry-standard methods across multiple asset classes, horizons, and time periods.",
LSTM-ARIMA as a Hybrid Approach in Algorithmic Investment Strategies,https://arxiv.org/abs/2406.18206,,06/27/2024 08:56,randomForestClassifier,"Kamil Kashif, Robert \'Slepaczuk","This study focuses on building an algorithmic investment strategy employing a hybrid approach that combines LSTM and ARIMA models referred to as LSTM-ARIMA. This unique algorithm uses LSTM to produce final predictions but boosts the results of this RNN by adding the residuals obtained from ARIMA predictions among other inputs. The algorithm is tested across three equity indices (S&amp;P 500, FTSE 100, and CAC 40) using daily frequency data from January 2000 to August 2023. The testing architecture is based on the walk-forward procedure for the hyperparameter tunning phase that uses Random Search and backtesting the algorithms. The selection of the optimal model is determined based on adequately selected performance metrics focused on risk-adjusted return measures. We considered two strategies for each algorithm: Long-Only and Long-Short to present the situation of two various groups of investors with different investment policy restrictions. For each strategy and equity index, we compute the performance metrics and visualize the equity curve to identify the best strategy with the highest modified information ratio. The findings conclude that the LSTM-ARIMA algorithm outperforms all the other algorithms across all the equity indices which confirms the strong potential behind hybrid ML-TS (machine learning - time series) models in searching for the optimal algorithmic investment strategies.",q-fin.TR
"Great year, bad Sharpe? A note on the joint distribution of performance and risk-adjusted return",https://arxiv.org/abs/2302.08829,,06/27/2024 08:56,randomForestClassifier,Matteo Smerlak,"Returns distributions are heavy-tailed across asset classes. In this note, I examine the implications of this well-known stylized fact for the joint statistics of performance (absolute return) and Sharpe ratio (risk-adjusted return). Using both synthetic and real data, I show that, all other things being equal, the investments with the best in-sample performance are never associated with the best in-sample Sharpe ratios (and vice versa). This counter-intuitive effect is unrelated to the risk-return tradeoff familiar from portfolio theory: it is, rather, a consequence of asymptotic correlations between the sample mean and sample standard deviation of heavy-tailed variables. In addition to its large sample noise, this non-monotonic association of the Sharpe ratio with performance puts into question its status as the gold standard metric of investment quality.","q-fin.ST, physics.soc-ph, q-fin.GN, q-fin.PM"
Augmented Dynamic Gordon Growth Model,https://arxiv.org/abs/2201.06012,,06/27/2024 08:56,randomForestClassifier,Battulga Gankhuu,"In this paper, we introduce a dynamic Gordon growth model, which is augmented by a time--varying spot interest rate and the Gordon growth model for dividends. Using the risk--neutral valuation method and locally risk--minimizing strategy, we obtain pricing and hedging formulas for the dividend--paying European call and put options and equity--linked life insurance products. Also, we provide ML estimator of the model.",q-fin.MF
Introducing P-CAPE: Incorporating the Dividend Payout Ratio Improves Investors' Favorite Estimator of Stock Market Returns,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4874559,2024-06-28 11:51:00,06/28/2024 16:37,randomForestClassifier,"James White, Victor Haghani","The Cyclically-Adjusted Price Earnings ratio, known as CAPE, is the most commonly used metric for estimating the long-term expected real return of the stock market.&nbsp; The reciprocal of CAPE (1/CAPE), known as the Cyclically-Adjusted Earnings Yield (CAEY), is the metric many investors use to estimate the long-term expected real return of the stock market. A shortcoming of Shiller and Campbell’s definition of cyclically-adjusted earnings is that it doesn’t take account of the fact that, in general, companies don’t pay out all their earnings as dividends each year. The fraction of earnings not paid out in dividends is either reinvested in the business or paid out via stock buybacks. Reinvesting earnings in the business is done in the expectation of growing future earnings, and this earnings growth should ideally be accounted for when smoothing earnings over the previous ten years for the purpose of predicting long-term future earnings. Buying back stock doesn’t grow top line earnings, but it does reduce shares outstanding and hence increases earnings per share. We believe a better measure of cyclically-adjusted earnings should directly account for the logic that retained earnings should increase earnings per share over time in addition to the inflation adjustment already part of Campbell and Shiller’s measure. We show that such an adjustment is simple to implement and, when used to compute earnings yield, should and does provide a better measure of the long-term expected real return of the stock market. Note that, for dividend payout ratios of less than 100% and for positive earnings yields, P-CAE will be higher than Shiller and Campbell’s cyclically-adjusted earnings, which are only adjusted for inflation. Those who were attracted to the logic of Campbell and Shiller’s CAPE to begin with should find their measure adjusted for dividend payouts an adjustment worth adopting.",
TTP-Based Cyber Resilience Index: A Probabilistic Quantitative Approach to Measure Defence Effectiveness Against Cyber Attacks,https://arxiv.org/abs/2406.19374,,06/28/2024 16:45,randomForestClassifier,"Lampis Alevizos, Vinh-Thong Ta","In the dynamic cyber threat landscape, effective decision-making under uncertainty is crucial for maintaining robust information security. This paper introduces the Cyber Resilience Index (CRI), a TTP-based probabilistic approach to quantifying an organisation's defence effectiveness against cyber-attacks (campaigns). Building upon the Threat-Intelligence Based Security Assessment (TIBSA) methodology, we present a mathematical model that translates complex threat intelligence into an actionable, unified metric similar to a stock market index, that executives can understand and interact with while teams can act upon. Our method leverages Partially Observable Markov Decision Processes (POMDPs) to simulate attacker behaviour considering real-world uncertainties and the latest threat actor tactics, techniques, and procedures (TTPs). This allows for dynamic, context-aware evaluation of an organization's security posture, moving beyond static compliance-based assessments. As a result, decision-makers are equipped with a single metric of cyber resilience that bridges the gap between quantitative and qualitative assessments, enabling data-driven resource allocation and strategic planning. This can ultimately lead to more informed decision-making, mitigate under or overspending, and assist in resource allocation.",cs.CR
Finding Value in Sustainable and Responsible Investments,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4875140,2024-06-28 12:20:00,06/28/2024 16:41,randomForestClassifier,"Sebastian Lobe, Gerhard Halbritter","This paper assesses the characteristics and financial performance of a comprehensive set of passive sustainable and responsible investments (SRI) around the world. We contribute the novel finding that from a financial perspective, SRI portfolios pursue first and foremost a pure value strategy when using an undistorted value measure. This result holds irrespective of the index provider, the screening, and the weighting approach. It is also robust across international markets and to various asset pricing anomalies such as size, momentum, short-term reversal, betting-against-beta, and quality-minus-junk. We corroborate that SRI’s financial performance is neutral with slight indications that score-weighting or a combined approach using positive and negative environmental, social and governance (ESG) screens fare better. 
<br />",
ETF flows and the index effect,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4875607,2024-06-28 12:25:00,06/28/2024 16:39,randomForestClassifier,Clint Howard,"This paper examines the impact of exchange-traded fund (ETF) flows on the index effect using the 2009 launch of the first ETF tracking the S&amp;P/ASX 300 index in Australia as a natural experiment. Using a difference-indifferences design, I find that the ETF's introduction increased cumulative abnormal returns for index additions by 5.86%, from 2.37% to 8.23%. This effect is unique to the S&amp;P/ASX 300 and absent in other Australian indexes. Further analyses confirm ETF flows as the mechanism, with abnormal flow differentials between ETFs strongly predicting returns around index changes. My findings highlight a novel channel through which ETF growth is shaping stock price dynamics, with the increase in passive ETF assets altering the index effect.",
Forecasting and Backtesting Gradient Allocations of Expected Shortfall,https://arxiv.org/abs/2401.11701,,06/28/2024 16:45,randomForestClassifier,"Takaaki Koike, Cathy W. S. Chen, Edward M. H. Lin","Capital allocation is a procedure for quantifying the contribution of each source of risk to aggregated risk. The gradient allocation rule, also known as the Euler principle, is a prevalent rule of capital allocation under which the allocated capital captures the diversification benefit of the marginal risk as a component of overall risk. This research concentrates on Expected Shortfall (ES) as a regulatory standard and focuses on the gradient allocations of ES, also called ES contributions (ESCs). We present the comprehensive treatment of backtesting the tuple of ESCs in the framework of the traditional and comparative backtests based on the concepts of joint identifiability and multi-objective elicitability. For robust forecast evaluation against the choice of scoring function, we also extend the Murphy diagram, a graphical tool to check whether one forecast dominates another under a class of scoring functions, to the case of ESCs. Finally, leveraging the recent concept of multi-objective elicitability, we propose a novel semiparametric model for forecasting dynamic ESCs based on a compositional regression model. In an empirical analysis of stock returns we evaluate and compare a variety of models for forecasting dynamic ESCs and demonstrate the outstanding performance of the proposed model.",q-fin.RM
Dynamical Analysis of Autobidding Systems,https://arxiv.org/abs/2406.19350,,06/28/2024 16:45,randomForestClassifier,"Renato Paes Leme, Georgios Piliouras, Jon Schneider, Kelly Spendlove, Song Zuo","It has become the default in markets such as ad auctions for participants to bid in an auction through automated bidding agents (autobidders) which adjust bids over time to satisfy return-over-spend constraints. Despite the prominence of such systems for the internet economy, their resulting dynamical behavior is still not well understood. Although one might hope that such relatively simple systems would typically converge to the equilibria of their underlying auctions, we provide a plethora of results that show the emergence of complex behavior, such as bi-stability, periodic orbits and quasi periodicity. We empirically observe how the market structure (expressed as motifs) qualitatively affects the behavior of the dynamics. We complement it with theoretical results showing that autobidding systems can simulate both linear dynamical systems as well logical boolean gates.",cs.GT
Factor multivariate stochastic volatility models of high dimension,https://arxiv.org/abs/2406.19033,,06/28/2024 16:45,randomForestClassifier,"Benjamin Poignard, Manabu Asai","Building upon the pertinence of the factor decomposition to break the curse of dimensionality inherent to multivariate volatility processes, we develop a factor model-based multivariate stochastic volatility (fMSV) framework that relies on two viewpoints: sparse approximate factor model and sparse factor loading matrix. We propose a two-stage estimation procedure for the fMSV model: the first stage obtains the estimators of the factor model, and the second stage estimates the MSV part using the estimated common factor variables. We derive the asymptotic properties of the estimators. Simulated experiments are performed to assess the forecasting performances of the covariance matrices. The empirical analysis based on vectors of asset returns illustrates that the forecasting performances of the fMSV models outperforms competing conditional covariance models.",econ.EM
Benchmarking M6 Competitors: An Analysis of Financial Metrics and Discussion of Incentives,https://arxiv.org/abs/2406.19105,,06/28/2024 16:45,randomForestClassifier,"Matthew J. Schneider, Rufus Rankin, Prabir Burman, Alexander Aue","The M6 Competition assessed the performance of competitors using a ranked probability score and an information ratio (IR). While these metrics do well at picking the winners in the competition, crucial questions remain for investors with longer-term incentives. To address these questions, we compare the competitors' performance to a number of conventional (long-only) and alternative indices using standard industry metrics. We apply factor models to the competitors' returns and show the difficulty for any competitor to demonstrate a statistically significant value-add above industry-standard benchmarks within the short timeframe of the competition. We also uncover that most competitors generated lower risk-adjusted returns and lower maximum drawdowns than randomly selected portfolios, and that most competitors could not generate significant out-performance in raw returns. We further introduce two new strategies by picking the competitors with the best (Superstars) and worst (Superlosers) recent performance and show that it is challenging to identify skill amongst investment managers. Overall, our findings highlight the difference in incentives for competitors over professional investors, where the upside of winning the competition dwarfs the potential downside of not winning to maximize fees over an extended period of time.","q-fin.PM, q-fin.RM, stat.AP"
Computing the SSR,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4872776,2024-06-27 17:14:00,06/28/2024 16:44,randomForestClassifier,"Peter Friz, Jim Gatheral","The skew-stickiness-ratio (SSR), examined in detail by Bergomi in his book, is critically important to options traders, especially market makers. We present a modelfree expression for the SSR in terms of the characteristic function. In the diffusion setting, it is well-known that the short-term limit of the SSR is 2; a corollary of our results is that this limit is H + 3/2 where H is the Hurst exponent of the volatility process. The general formula for the SSR simplifies and becomes particularly tractable in the affine forward variance case. We explain the qualitative behavior of the SSR with respect to the shape of the forward variance curve, and thus also path-dependence of the SSR.",
Uncovering the Sino-US dynamic risk spillovers effects: Evidence from agricultural futures markets,https://arxiv.org/abs/2403.01745,,07/01/2024 09:18,randomForestClassifier,"Han-Yu Zhu, Peng-Fei Dai, Wei-Xing Zhou","Agricultural products play a critical role in human development. With economic globalization and the financialization of agricultural products continuing to advance, the interconnections between different agricultural futures have become closer. We utilize a TVP-VAR-DY model combined with the quantile method to measure the risk spillover between 11 agricultural futures on the futures exchanges of US and China from July 9,2014, to December 31,2022. This study yielded several significant findings. Firstly, CBOT corn, soybean, and wheat were identified as the primary risk transmitters, with DCE corn and soybean as the main risk receivers. Secondly, sudden events or increased economic uncertainty can increase the overall risk spillovers. Thirdly, there is an aggregation of risk spillovers amongst agricultural futures based on the dynamic directional spillover results. Lastly, the central agricultural futures under the conditional mean are CBOT corn and soybean, while CZCE hard wheat and long-grained rice are the two risk spillover centers in extreme cases, as per the results of the spillover network and minimum spanning tree. Based on these results, decision-makers are advised to safeguard against the price risk of agricultural futures under sudden economic events, and investors can utilize the results to construct a superior investment portfolio by taking different agricultural product futures as risk-leading indicators according to various situations.","econ.GN, q-fin.EC, q-fin.RM"
Test for symmetry and confidence interval of the parameter {\mu} of skew-symmetric-Laplace-uniform distribution,https://arxiv.org/abs/2406.20090,,07/01/2024 09:18,randomForestClassifier,"Raju. K. Lohot, V. U. Dixit","The skew symmetric Laplace uniform distribution SSLUD({\mu}) is introduced in Lohot, R. K. and Dixit, V. U. (2024) using the skewing mechanism of Azzalini (1985). Here we derive the most powerful (MP) test for symmetry of the SSLUD({\mu}). Since the form of the test statistic is complicated and it is difficult to obtain its exact distribution, critical values and the power of MP test are obtained using simulation. Further, we construct a confidence interval (CI) for parameter {\mu} assuming asymptotic normality and empirical distribution of the maximum likelihood estimator of {\mu}. These two methods are compared based on the average length and coverage probability of the CI. Finally, the CI of the parameter {\mu} is constructed using data on the transformed daily percentage change in the price of NIFTY 50, an Indian stock market index given in Lohot, R. K. and Dixit, V. U. (2024).","math.ST, stat.TH"
Portfolio Optimization in a Market with Hidden Gaussian Drift and Randomly Arriving Expert Opinions: Modeling and Theoretical Results,https://arxiv.org/abs/2308.02049,,07/01/2024 09:18,randomForestClassifier,"Abdelali Gabih, Ralf Wunderlich",This paper investigates the optimal selection of portfolios for power utility maximizing investors in a financial market where stock returns depend on a hidden Gaussian mean reverting drift process. Information on the drift is obtained from returns and expert opinions in the form of noisy signals about the current state of the drift arriving randomly over time. The arrival dates are modeled as the jump times of a homogeneous Poisson process. Applying Kalman filter techniques we derive estimates of the hidden drift which are described by the conditional mean and covariance of the drift given the observations. The utility maximization problem is solved with dynamic programming methods. We derive the associated dynamic programming equation and study regularization arguments for a rigorous mathematical justification.,q-fin.PM
Electricity Spot Prices Forecasting Using Stochastic Volatility Models,https://arxiv.org/abs/2406.19405,,07/01/2024 09:18,randomForestClassifier,Andrei Renatovich Batyrov,"There are several approaches to modeling and forecasting time series as applied to prices of commodities and financial assets. One of the approaches is to model the price as a non-stationary time series process with heteroscedastic volatility (variance of price). The goal of the research is to generate probabilistic forecasts of day-ahead electricity prices in a spot marker employing stochastic volatility models. A typical stochastic volatility model - that treats the volatility as a latent stochastic process in discrete time - is explored first. Then the research focuses on enriching the baseline model by introducing several exogenous regressors. A better fitting model - as compared to the baseline model - is derived as a result of the research. Out-of-sample forecasts confirm the applicability and robustness of the enriched model. This model may be used in financial derivative instruments for hedging the risk associated with electricity trading. Keywords: Electricity spot prices forecasting, Stochastic volatility, Exogenous regressors, Autoregression, Bayesian inference, Stan","q-fin.ST, q-fin.TR"
Power Utility Maximization with Expert Opinions at Fixed Arrival Times in a Market with Hidden Gaussian Drift,https://arxiv.org/abs/2301.06847,,07/01/2024 09:18,randomForestClassifier,"Abdelali Gabih, Hakam Kondakji, Ralf Wunderlich","In this paper we study optimal trading strategies in a financial market in which stock returns depend on a hidden Gaussian mean reverting drift process. Investors obtain information on that drift by observing stock returns. Moreover, expert opinions in the form of signals about the current state of the drift arriving at fixed and known dates are included in the analysis. Drift estimates are based on Kalman filter techniques. They are used to transform a power utility maximization problem under partial information into an optimization problem under full information where the state variable is the filter of the drift. The dynamic programming equation for this problem is studied and closed-form solutions for the value function and the optimal trading strategy of an investor are derived. They allow to quantify the monetary value of information delivered by the expert opinions. We illustrate our theoretical findings by results of extensive numerical experiments.",q-fin.PM
Dynamically Consistent Analysis of Realized Covariations in Term Structure Models,https://arxiv.org/abs/2406.19412,,07/01/2024 09:18,randomForestClassifier,Dennis Schroers,"In this article we show how to analyze the covariation of bond prices nonparametrically and robustly, staying consistent with a general no-arbitrage setting. This is, in particular, motivated by the problem of identifying the number of statistically relevant factors in the bond market under minimal conditions. We apply this method in an empirical study which suggests that a high number of factors is needed to describe the term structure evolution and that the term structure of volatility varies over time.","q-fin.ST, econ.EM, q-fin.MF"
Modeling a Financial System with Memory via Fractional Calculus and Fractional Brownian Motion,https://arxiv.org/abs/2406.19408,,07/01/2024 09:18,randomForestClassifier,Patrick Geraghty,"Financial markets have long since been modeled using stochastic methods such as Brownian motion, and more recently, rough volatility models have been built using fractional Brownian motion. This fractional aspect brings memory into the system. In this project, we describe and analyze a financial model based on the fractional Langevin equation with colored noise generated by fractional Brownian motion. Physics-based methods of analysis are used to examine the phase behavior and dispersion relations of the system upon varying input parameters. A type of anomalous marginal glass phase is potentially seen in some regions, which motivates further exploration of this model and expanded use of phase behavior and dispersion relation methods to analyze financial models.",q-fin.ST
Does internalization impact quote competition?&nbsp;,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4891227,2024-07-12 13:30:00,07/22/2024 09:54,randomForestClassifier,"Amber Anand, Dmitriy Muravyev","Traditionally, market makers compete on bid and ask prices to attract marketable orders, facilitating price discovery and liquidity in markets. However, internalization mechanisms allow market makers an ex-post option to trade without posting competitive quotes. We study the effects of this ex-post option on quote competition using on-exchange auctions in the options markets. Consistent with the use of auctions as an ex-post trading option, auction trades are 48 percentage points more likely when the relevant exchange is not quoting the best price; additionally, trades within auctions are 15 percentage points more likely to match the best quotes, rather than be price improved, when the exchange is not at the best quote. Exchanges that include auctions are 12 percentage points less likely to quote at the best prices and 30 percentage points less likely to set the best price. The non-competitive quoting effects of auctions spill over to a non-auction exchange for a market-maker. Our finding that internalization reduces quote competition suggests an added dimension to the understanding of internalization and complements the existing focus on price improvement.",
Robust Stock Index Return Predictions Using Deep Learning *,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4890466,2024-07-12 13:17:00,07/22/2024 09:42,randomForestClassifier,"Ravi Jagannathan, Yuan Liao, Andreas Neuhierl","We introduce a conditional machine learning approach to forecast the stock index return. Our approach is designed to work well for short-horizon forecasts to address the well-documented instability in predicting aggregate stock returns in long panels. We formally characterize the forecast standard errors to assess the uncertainty associated with our cross-sectional neural network predictions, which also enables us to explain the predictability of our model. The explainability covers both correctly and incorrectly assumed forecasting models, and stems from the forecast standard errors and out-of-sample R square. To explain the economic impacts of the economy's stability on the forecast quality, we introduce a ""CDI"" index defined as the correlation between firms' market value share and sales share, and show that it can well explain the forecast uncertainties, thus provides economic insights of the success and failure of machine learning based forecasting models.",
CAESar: Conditional Autoregressive Expected Shortfall,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4886158,2024-07-11 13:28:00,07/22/2024 09:51,randomForestClassifier,"Federico Gatta, Fabrizio Lillo, Piero Mazzarisi","In financial risk management, Value at Risk (VaR) is widely used to estimate potential portfolio losses. VaR's limitation is its inability to account for the magnitude of losses beyond a certain threshold. Expected Shortfall (ES) addresses this by providing the conditional expectation of such exceedances, offering a more comprehensive measure of tail risk. Despite its benefits, ES is not elicitable on its own, complicating its direct estimation. However, joint elicitability with VaR allows for their combined estimation. Building on this, we propose a new methodology named Conditional Autoregressive Expected Shortfall (CAESar), inspired by the CAViaR model. CAESar handles dynamic patterns flexibly and includes heteroskedastic effects for both VaR and ES, with no distributional assumption on price returns. CAESar involves a three-step process: estimating VaR via CAViaR regression, formulating ES in an autoregressive manner, and jointly estimating VaR and ES while ensuring a monotonicity constraint to avoid crossing quantiles. By employing various backtesting procedures, we show the effectiveness of CAESar through extensive simulations and empirical testing on daily financial data. Our results demonstrate that CAESar outperforms existing regression methods in terms of forecasting performance, making it a robust tool for financial risk management.",
Pricing and Calibration in the 4-Factor Path-Dependent Volatility Model,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4853419,2024-07-03 15:38:00,07/22/2024 09:54,randomForestClassifier,"Guido Gazzani, Julien Guyon","We consider the path-dependent volatility (PDV) model of Guyon and Lekeufack (2023), where the instantaneous volatility is a linear combination of a weighted sum of past returns and the square root of a weighted sum of past squared returns. We discuss the influence of an additional parameter that unlocks enough volatility on the upside to reproduce the implied volatility smiles of P 500 and VIX options. This PDV model, motivated by empirical studies, comes with computational challenges, especially in relation to VIX options pricing and calibration. We propose an accurate neural network approximation of the VIX which leverages on the Markovianity of the 4-factor version of the model. The VIX is learned as a function of the Markovian factors and the model parameters. We use this approximation to tackle the joint calibration of P 500 and VIX options.",
Can Day Trading Really Be Profitable?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4898296,2024-07-18 03:18:00,07/22/2024 09:52,randomForestClassifier,"Andrew Aziz, Carlo Zarattini","In this paper, we investigate the profitability of the well-known Opening Range Breakout (ORB) day trading strategy from 2016 to 2023. Our results suggest that with the proper use of leverage or leveraged products (such as 3x leveraged ETFs), day trading can empirically produce significant returns when compared to a standard buy and hold strategy on benchmark indexes in the US public equity markets. We introduced the use of TQQQ, a leveraged ETF of QQQ nd resulting portfolio would have earned an outstanding return of 1,484%, while an investment in the QQQ ETF would have earned only 169%.",
Currency Return Dynamics: What Is the Role of U.S. Macroeconomic Regimes?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4888163,2024-07-12 12:34:00,07/22/2024 09:46,randomForestClassifier,"Guanhao Feng, Jingyu He, Junye Li, Lucio Sarno, Qianshu Zhang","This paper investigates whether U.S. macroeconomic regimes affect the set of characteristics that drive currency return dynamics, resulting in time-varying specified risk premia. The study adopts a tree-based Bayesian regime-switching model that detects regime shifts in currency return dynamics instrumented by macroeconomic variables. The tree growth process is guided by marginal likelihood improvements, accounting for model and parameter uncertainty within each regime. The findings reveal strong evidence of regime changes in currency risk-return relationships determined by U.S. inflation and interest rates interactively. The Carry factor is identified as a common factor across all regimes, showing strong risk premia and selection probability, while other factors are regime-specific.",
Portfolio Alignment and Net Zero Investing,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4891271,2024-07-12 13:30:00,07/22/2024 09:54,randomForestClassifier,Thierry Roncalli,<span>This chapter introduces the concepts of portfolio alignment and net zero investing and how they are implemented by asset owners and managers.</span>,
Construction and Hedging of Equity Index Options Portfolios,https://arxiv.org/abs/2407.13908,,07/22/2024 09:55,randomForestClassifier,"Maciej Wysocki, Robert \'Slepaczuk","This research presents a comprehensive evaluation of systematic index option-writing strategies, focusing on S&amp;P500 index options. We compare the performance of hedging strategies using the Black-Scholes-Merton (BSM) model and the Variance-Gamma (VG) model, emphasizing varying moneyness levels and different sizing methods based on delta and the VIX Index. The study employs 1-minute data of S&amp;P500 index options and index quotes spanning from 2018 to 2023. The analysis benchmarks hedged strategies against buy-and-hold and naked option-writing strategies, with a focus on risk-adjusted performance metrics including transaction costs. Portfolio delta approximations are derived using implied volatility for the BSM model and market-calibrated parameters for the VG model. Key findings reveal that systematic option-writing strategies can potentially yield superior returns compared to buy-and-hold benchmarks. The BSM model generally provided better hedging outcomes than the VG model, although the VG model showed profitability in certain naked strategies as a tool for position sizing. In terms of rehedging frequency, we found that intraday hedging in 130-minute intervals provided both reliable protection against adverse market movements and a satisfactory returns profile.","q-fin.PM, q-fin.RM, q-fin.TR"
Forecasting Mutual Fund Performance – Combining&nbsp;<span>Return-Based with Portfolio Holdings-Based&nbsp;</span>Predictors,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4887900,2024-07-12 12:29:00,07/22/2024 09:42,randomForestClassifier,"Sebastian M&uuml;ller, Nikolay Pugachyov, Florian Weigert",We propose that individual mutual fund performance predictors can be combined&nbsp;<span>into a composite predictor to forecast fund performance. The composite&nbsp;</span><span>predictor aggregates information across 19 prominent return-based and portfolio&nbsp;</span><span>holdings-based predictors from the literature. It selects top decile funds&nbsp;</span><span>that outperform bottom decile funds by risk-adjusted 4.56% per annum. Information&nbsp;</span><span>from both return-based predictors (such as fund’s alpha and t-statistic&nbsp;</span><span>of alpha) as well as holding-based predictors (such as characteristic selectivity&nbsp;</span><span>and active weight) contribute equally to the success of the composite predictor.</span>,
Measuring and testing tail equivalence,https://arxiv.org/abs/2407.14349,,07/22/2024 09:55,randomForestClassifier,"Takaaki Koike, Shogo Kato, Toshinao Yoshiba","We call two copulas tail equivalent if their first-order approximations in the tail coincide. As a special case, a copula is called tail symmetric if it is tail equivalent to the associated survival copula. We propose a novel measure and statistical test for tail equivalence. The proposed measure takes the value of zero if and only if the two copulas share a pair of tail order and tail order parameter in common. Moreover, taking the nature of these tail quantities into account, we design the proposed measure so that it takes a large value when tail orders are different, and a small value when tail order parameters are non-identical. We derive asymptotic properties of the proposed measure, and then propose a novel statistical test for tail equivalence. Performance of the proposed test is demonstrated in a series of simulation studies and empirical analyses of financial stock returns in the periods of the world financial crisis and the COVID-19 recession. Our empirical analysis reveals non-identical tail behaviors in different pairs of stocks, different parts of tails, and the two periods of recessions.",stat.ME
"Asset Pricing with Affect Investing, Gambling, and Overconfidence: Theory and Evidence",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4887111,2024-07-11 13:46:00,07/22/2024 09:40,randomForestClassifier,"Jiang Luo, Shuoge Qian, Zheng Qiao, Avanidhar Subrahmanyam","Asset Pricing with Affect Investing, Gambling, and Overconfidence: Theory and Evidence We present a multi-asset model with three investor types: Gamblers, who derive direct utility from large stock positions, overconfident investors, who underestimate the precision of public information (that they do not produce themselves), and affect investors, whose attitude towards a firm's products impacts their investment in the firm's stock. We consider the joint impact of these investors on trading activity, measured systematic risk, and expected returns. We find that gambling amplifies trading volume and mitigates overconfidence-induced excess return co-movement and underreaction. Further, risk-adjusted returns decrease in the strength of the affect heuristic; but this relation attenuates when gambling propensity is high. Empirical evidence supports these implications.",
Firms' Perceived Cost of Capital,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4888476,2024-07-09 12:48:00,07/22/2024 09:47,randomForestClassifier,"Niels Joachim Gormsen, Kilian Huber","We study hand-collected data on firms’ perceptions of their cost of capital. Firms with higher perceived cost of capital earn higher returns on invested capital and invest less, suggesting that the perceived cost of capital shapes long-run capital allocation. The perceived cost of capital is partially related to the true cost of capital, which is determined by risk premia and interest rates, but there are also large deviations between the perceived and true cost of capital. Only 20% of the variation in the perceived cost of capital is justified by variation in the true cost of capital. The remaining 80% reflects deviations that are consistent with managers making mistakes. These deviations lead to misallocation of capital that lowers long-run aggregate productivity by 5% in a benchmark model. Forcing all firms to apply the same cost of capital would improve the allocation of capital relative to current corporate practice. The deviations in the perceived cost of capital challenge standard models, in particular the production-based asset pricing paradigm, and lead us to reject the “Investment CAPM.” We describe actionable methods that allow firms to improve their perceptions and capital allocation.",
Nash Equilibrium between Brokers and Traders,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4894757,2024-07-18 16:02:00,07/22/2024 09:48,randomForestClassifier,"&Aacute;lvaro Cartea, Sebastian Jaimungal, Leandro S&aacute;nchez-Betancourt","We study the perfect information Nash equilibrium between a broker and her clients -- an informed trader, and an uniformed trader. In our model, the broker trades in the lit exchange where trades have instantaneous and transient price impact with exponential resilience, while both clients trade with the broker. The informed trader and the broker maximise expected wealth subject to inventory penalties, while the uninformed trader is not strategic and sends the broker random buy and sell orders. We characterise the Nash equilibrium of the trading strategies with the solution to a coupled system of forward-backward stochastic differential equations (FBSDEs). We solve this system explicitly and study the effect of information in the trading strategies of the broker and the informed trader.",
Identifying Shocks to Systematic Risk in Times of Crisis,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4894687,2024-07-15 17:57:00,07/22/2024 09:44,randomForestClassifier,"Jacob Boudoukh, Yukun Liu, Tobias J. Moskowitz, Matthew P. Richardson","We characterize how risk evolves during a crisis. Using high-frequency data, we find that the first two principal components (PCs) of the covariance matrix of global asset returns experience large, sudden, and temporary spikes coinciding with well-known crises – Covid-19 pandemic, Global Financial Crisis, and Brexit. Despite the origin of these crises being very different, the risk dynamics share remarkably common features: PC1 shocks come solely from asset volatility, while PC2 shocks come from changing loadings/composition, effectively making it a “crisis” factor. Using the exogenous nature of Covid-19, we provide novel identification of risk dynamics by linking these changes to news about the virus and epidemiological model forecast errors over time and across countries. We conclude with investment implications, where shocks to systematic risk sharply reduce diversification benefits and ex ante attempts to hedge it are futile, which may be a defining characteristic of a crisis – that it is unavoidable.<br /><br />Institutional subscribers to the NBER working paper series, and residents of developing countries may download this paper without additional charge at <a href=""http://www.nber.org/papers/&#119;32693"" target=""_blank"">www.nber.org</a>.<br />",
Does Economic Policy Uncertainty Matter for Hedge Fund Returns?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4882292,2024-07-02 02:17:00,07/22/2024 09:45,randomForestClassifier,"Bing Liang, Songtao Wang, Chunyang Zhou","In this paper, we investigate the impact of economic policy uncertainty (EPU) on the performance of hedge funds. We observe that high EPU beta funds exhibit an average annual return of 6.36% lower than that of low EPU beta funds. This negative relation holds even after accounting for conventional risk factors and is robust to controlling for fund-specific characteristics. Subsequently, we delve into potential reasons behind the underperformance of high EPU beta funds. Our findings indicate that high EPU beta funds display less proficiency in predicting and capitalizing on EPU fluctuations, leading to lower returns.",
"Sustainability Matters: Company SDG Scores Need Not Have Size, Location, and ESG Disclosure Biases",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4886097,2024-07-11 13:27:00,07/22/2024 09:53,randomForestClassifier,"Lewei He, Harald Lohre, Jan Anton van Zanten","We investigate whether SDG scores, which evaluate companies' alignment with the 17 UN Sustainable Development Goals, exhibit similar biases that affect ESG ratings. Specifically, we document that SDG scores need not be influenced by size, location, and disclosure biases. Consequently, SDG-aligned investment portfolios would avoid undesirable biases stemming from the way company SDG scores are constructed. Our findings dispel the notion that company size, location, and the availability of resources for ESG disclosure drive corporate sustainability performance.",
A Bayesian workflow for securitizing casualty insurance risk,https://arxiv.org/abs/2407.14666,,07/23/2024 09:39,randomForestClassifier,"Nathaniel Haines, Conor Goold, J. Mark Shoun","Casualty insurance-linked securities (ILS) are appealing to investors because the underlying insurance claims, which are directly related to resulting security performance, are uncorrelated with most other asset classes. Conversely, casualty ILS are appealing to insurers as an efficient capital managment tool. However, securitizing casualty insurance risk is non-trivial, as it requires forecasting loss ratios for pools of insurance policies that have not yet been written, in addition to estimating how the underlying losses will develop over time within future accident years. In this paper, we lay out a Bayesian workflow that tackles these complexities by using: (1) theoretically informed time-series and state-space models to capture how loss ratios develop and change over time; (2) historic industry data to inform prior distributions of models fit to individual programs; (3) stacking to combine loss ratio predictions from candidate models, and (4) both prior predictive simulations and simulation-based calibration to aid model specification. Using historic Schedule P filings, we then show how our proposed Bayesian workflow can be used to assess and compare models across a variety of key model performance metrics evaluated on future accident year losses.","stat.ME, stat.AP"
Is the difference between deep hedging and delta hedging a statistical arbitrage?,https://arxiv.org/abs/2407.14736,,07/23/2024 09:39,randomForestClassifier,"Pascal Fran\c{c}ois, Genevi\`eve Gauthier, Fr\'ed\'eric Godin, Carlos Octavio P\'erez Mendoza","The recent work of Horikawa and Nakagawa (2024) explains that there exist complete market models in which the difference between the hedging position provided by deep hedging and that of the replicating portfolio is a statistical arbitrage. This raises concerns as it entails that deep hedging can include a speculative component aimed simply at exploiting the structure of the risk measure guiding the hedging optimisation problem. We test whether such finding remains true in a GARCH-based market model. We observe that the difference between deep hedging and delta hedging can be a statistical arbitrage if the risk measure considered does not put sufficient relative weight on adverse outcomes. Nevertheless, a suitable choice of risk measure can prevent the deep hedging agent from including a speculative overlay within its hedging strategy.","q-fin.CP, q-fin.RM"
Credibility Theory Based on Winsorizing,https://arxiv.org/abs/2306.09507,,07/23/2024 09:39,randomForestClassifier,"Qian Zhao, Chudamani Poudyal","The classical B\""{u}hlmann credibility model has been widely applied to premium estimation for group insurance contracts and other insurance types. In this paper, we develop a robust B\""{u}hlmann credibility model using the winsorized version of loss data, also known as the winsorized mean (a robust alternative to the traditional individual mean). This approach assumes that the observed sample data come from a contaminated underlying model with a small percentage of contaminated sample data. This framework provides explicit formulas for the structural parameters in credibility estimation for scale-shape distribution families, location-scale distribution families, and their variants, commonly used in insurance risk modeling. Using the theory of \(L\)-estimators (different from the influence function approach), we derive the asymptotic properties of the proposed method and validate them through a comprehensive simulation study, comparing their performance to credibility based on the trimmed mean. By varying the winsorizing/trimming thresholds in several parametric models, we find that all structural parameters derived from the winsorized approach are less volatile than those from the trimmed approach. Using the winsorized mean as a robust risk measure can reduce the influence of parametric loss assumptions on credibility estimation. Additionally, we discuss non-parametric estimations in credibility. Finally, a numerical illustration from the Wisconsin Local Government Property Insurance Fund indicates that the proposed robust credibility approach mitigates the impact of model mis-specification and captures the risk behavior of loss data from a broader perspective.","stat.AP, math.ST, stat.CO, stat.ME, stat.TH"
Geometric insights into robust portfolio construction,https://arxiv.org/abs/2107.06194,,07/23/2024 09:39,randomForestClassifier,"Lara Dalmeyer, Tim Gebbie",We investigate and extend the result that an alpha-weight angle from unconstrained quadratic portfolio optimisations has an upper bound dependent on the condition number of the covariance matrix. This is known to imply that better conditioned covariance matrices produce weights from unconstrained mean-variance optimisations that are better aligned with each assets expected return. Here we relate the inequality between the alpha-weight angle and the condition number to extend the result to include portfolio optimisations with gearing constraints to provide an extended family of robust optimisations. We use this to argue that in general the equally weighted portfolio is not preferable to the mean-variance portfolio even with poor forecast ability and a badly conditioned covariance matrix. We confirm the distribution free theoretical arguments with a simple Gaussian simulation.,"q-fin.PM, math.OC, q-fin.GN"
Analyzing selected cryptocurrencies spillover effects on global financial indices: Comparing risk measures using conventional and eGARCH-EVT-Copula approaches,https://arxiv.org/abs/2407.15766,,07/23/2024 09:39,randomForestClassifier,"Shafique Ur Rehman, Touqeer Ahmad, Wu Dash Desheng, Amirhossein Karamoozian","This study examines the interdependence between cryptocurrencies and international financial indices, such as MSCI World and MSCI Emerging Markets. We compute the value at risk, expected shortfall (ES), and range value at risk (RVaR) and investigate the dynamics of risk spillover. We employ a hybrid approach to derive these risk measures that integrate GARCH models, extreme value models, and copula functions. This framework uses a bivariate portfolio approach involving cryptocurrency data and traditional financial indices. To estimate the above risks of these portfolio structures, we employ symmetric and asymmetric GARCH and both tail flexible EVT models as marginal to model the marginal distribution of each return series and apply different copula functions to connect the pairs of marginal distributions into a multivariate distribution. The empirical findings indicate that the eGARCH EVT-based copula model adeptly captures intricate dependencies, surpassing conventional methodologies like Historical simulations and t-distributed parametric in VaR estimation. At the same time, the HS method proves superior for ES, and the t-distributed parametric method outperforms RVaR. Eventually, the Diebold-Yilmaz approach will be applied to compute risk spillovers between four sets of asset sequences. This phenomenon implies that cryptocurrencies reveal substantial spillover effects among themselves but minimal impact on other assets. From this, it can be concluded that cryptocurrencies propose diversification benefits and do not provide hedging advantages within an investor's portfolio. Our results underline RVaR superiority over ES regarding regulatory arbitrage and model misspecification. The conclusions of this study will benefit investors and financial market professionals who aspire to comprehend digital currencies as a novel asset class and attain perspicuity in regulatory arbitrage.",q-fin.RM
Weak convergence implies convergence in mean within GGC,https://arxiv.org/abs/2407.15105,,07/23/2024 09:39,randomForestClassifier,Hasanjan Sayit,We prove that weak convergence within generalized gamma convolution (GGC) distributions implies convergence in the mean value. We use this fact to show the robustness of the expected utility maximizing optimal portfolio under exponential utility function when return vectors are modelled by hyperbolic distributions.,q-fin.MF
Localized Neural Network Modelling of Time Series: A Case Study on US Monetary Policy,https://arxiv.org/abs/2306.05593,,07/23/2024 09:39,randomForestClassifier,"Jiti Gao, Fei Liu, Bin Peng, Yanrong Yang","In this paper, we investigate a semiparametric regression model under the context of treatment effects via a localized neural network (LNN) approach. Due to a vast number of parameters involved, we reduce the number of effective parameters by (i) exploring the use of identification restrictions; and (ii) adopting a variable selection method based on the group-LASSO technique. Subsequently, we derive the corresponding estimation theory and propose a dependent wild bootstrap procedure to construct valid inferences accounting for the dependence of data. Finally, we validate our theoretical findings through extensive numerical studies. In an empirical study, we revisit the impacts of a tightening monetary policy action on a variety of economic variables, including short-/long-term interest rate, inflation, unemployment rate, industrial price and equity return via the newly proposed framework using a monthly dataset of the US.",econ.EM
Nash Equilibrium between Brokers and Traders,https://arxiv.org/abs/2407.10561,,07/23/2024 09:39,randomForestClassifier,"\'Alvaro Cartea, Sebastian Jaimungal, Leandro S\'anchez-Betancourt","We study the perfect information Nash equilibrium between a broker and her clients -- an informed trader and an uniformed trader. In our model, the broker trades in the lit exchange where trades have instantaneous and transient price impact with exponential resilience, while both clients trade with the broker. The informed trader and the broker maximise expected wealth subject to inventory penalties, while the uninformed trader is not strategic and sends the broker random buy and sell orders. We characterise the Nash equilibrium of the trading strategies with the solution to a coupled system of forward-backward stochastic differential equations (FBSDEs). We solve this system explicitly and study the effect of information, profitability, and inventory control in the trading strategies of the broker and the informed trader.",q-fin.TR
Joint calibration to SPX and VIX options with signature-based models,https://arxiv.org/abs/2301.13235,,07/24/2024 11:39,randomForestClassifier,"Christa Cuchiero, Guido Gazzani, Janka M\""oller, Sara Svaluto-Ferro","We consider a stochastic volatility model where the dynamics of the volatility are described by a linear function of the (time extended) signature of a primary process which is supposed to be a polynomial diffusion. We obtain closed form expressions for the VIX squared, exploiting the fact that the truncated signature of a polynomial diffusion is again a polynomial diffusion. Adding to such a primary process the Brownian motion driving the stock price, allows then to express both the log-price and the VIX squared as linear functions of the signature of the corresponding augmented process. This feature can then be efficiently used for pricing and calibration purposes. Indeed, as the signature samples can be easily precomputed, the calibration task can be split into an offline sampling and a standard optimization. We also propose a Fourier pricing approach for both VIX and SPX options exploiting that the signature of the augmented primary process is an infinite dimensional affine process. For both the SPX and VIX options we obtain highly accurate calibration results, showing that this model class allows to solve the joint calibration problem without adding jumps or rough volatility.","q-fin.MF, math.PR"
The Negative Drift of a Limit Order Fill,https://arxiv.org/abs/2407.16527,,07/24/2024 11:39,randomForestClassifier,Timothy DeLise,"Market making refers to a form of trading in financial markets characterized by passive orders which add liquidity to limit order books. Market makers are important for the proper functioning of financial markets worldwide. Given the importance, financial mathematics has endeavored to derive optimal strategies for placing limit orders in this context. This paper identifies a key discrepancy between popular model assumptions and the realities of real markets, specifically regarding the dynamics around limit order fills. Traditionally, market making models rely on an assumption of low-cost random fills, when in reality we observe a high-cost non-random fill behavior. Namely, limit order fills are caused by and coincide with adverse price movements, which create a drag on the market maker's profit and loss. We refer to this phenomenon as ""the negative drift"" associated with limit order fills. We describe a discrete market model and prove theoretically that the negative drift exists. We also provide a detailed empirical simulation using one of the most traded financial instruments in the world, the 10 Year US Treasury Bond futures, which also confirms its existence. To our knowledge, this is the first paper to describe and prove this phenomenon in such detail.","q-fin.MF, q-fin.ST, q-fin.TR"
Counter-monotonic risk allocations and distortion risk measures,https://arxiv.org/abs/2407.16099,,07/24/2024 11:39,randomForestClassifier,"Mario Ghossoub, Qinghua Ren, Ruodu Wang","In risk-sharing markets with aggregate uncertainty, characterizing Pareto-optimal allocations when agents might not be risk averse is a challenging task, and the literature has only provided limited explicit results thus far. In particular, Pareto optima in such a setting may not necessarily be comonotonic, in contrast to the case of risk-averse agents. In fact, when market participants are risk-seeking, Pareto-optimal allocations are counter-monotonic. Counter-monotonicity of Pareto optima also arises in some situations for quantile-optimizing agents. In this paper, we provide a systematic study of efficient risk sharing in markets where allocations are constrained to be counter-monotonic. The preferences of the agents are modelled by a common distortion risk measure, or equivalently, by a common Yaari dual utility. We consider three different settings: risk-averse agents, risk-seeking agents, and those with an inverse S-shaped distortion function. In each case, we provide useful characterizations of optimal allocations, for both the counter-monotonic market and the unconstrained market. To illustrate our results, we consider an application to a portfolio choice problem for a portfolio manager tasked with managing the investments of a group of clients, with varying levels of risk aversion or risk seeking. We determine explicitly the optimal investment strategies in this case. Our results confirm the intuition that a manager investing on behalf of risk-seeking agents tends to invest more in risky assets than a manager acting on behalf of risk-averse agents.",q-fin.RM
Short-maturity asymptotics for VIX and European options in local-stochastic volatility models,https://arxiv.org/abs/2407.16813,,07/25/2024 09:05,randomForestClassifier,"Dan Pirjol, Xiaoyu Wang, Lingjiong Zhu","We derive the short-maturity asymptotics for European and VIX option prices in local-stochastic volatility models where the volatility follows a continuous-path Markov process. Both out-of-the-money (OTM) and at-the-money (ATM) asymptotics are considered. Using large deviations theory methods, the asymptotics for the OTM options are expressed as a two-dimensional variational problem, which is reduced to an extremal problem for a function of two real variables. This extremal problem is solved explicitly in an expansion in log-moneyness. We derive series expansions for the implied volatility for European and VIX options which should be useful for model calibration. We give explicit results for two classes of local-stochastic volatility models relevant in practice, with Heston-type and SABR-type stochastic volatility. The leading-order asymptotics for at-the-money options are computed in closed-form. The asymptotic results reproduce known results in the literature for the Heston and SABR models and for the uncorrelated local-stochastic volatility model. The asymptotic results are tested against numerical simulations for a local-stochastic volatility model with bounded local volatility.",q-fin.PR
Well Posedness of Utility Maximization Problems Under Partial Information in a Market with Gaussian Drift,https://arxiv.org/abs/2205.08614,,07/25/2024 09:05,randomForestClassifier,"Abdelali Gabih, Hakam Kondakji, Ralf Wunderlich","This paper investigates well posedness of utility maximization problems for financial markets where stock returns depend on a hidden Gaussian mean reverting drift process. Since that process is potentially unbounded, well posedness cannot be guaranteed for utility functions which are not bounded from above. For power utility with relative risk aversion smaller than that of log-utility this leads to restrictions on the choice of model parameters such as the investment horizon and parameters controlling the variance of the asset price and drift processes. We derive sufficient conditions to the model parameters leading to bounded maximum expected utility of terminal wealth for models with full and partial information.",q-fin.PM
A semi-parametric marginalized dynamic conditional correlation framework,https://arxiv.org/abs/2207.04595,,07/26/2024 09:19,randomForestClassifier,"Giuseppe Storti, Chao Wang","We develop a novel multivariate semi-parametric framework for joint portfolio Value-at-Risk and Expected Shortfall forecasting. Unlike existing univariate semi-parametric approaches, the proposed framework explicitly models the dependence structure among portfolio asset returns through a marginalized dynamic conditional correlation (DCC) parameterization. To estimate the model, a two-step procedure based on the minimization of a strictly consistent scoring function derived from the Asymmetric Laplace distribution is developed. This procedure allows to simultaneously estimate the marginalized DCC parameters and the portfolio risk factors. The performance of the proposed model in risk forecasting and portfolio allocation is evaluated by means of a forecasting study on the components of the Dow Jones index for an out-of-sample period from December 2016 to September 2021. The empirical results support effectiveness of the proposed framework compared to a variety of existing approaches.","q-fin.RM, q-fin.PM"
Generative model for financial time series trained with MMD using a signature kernel,https://arxiv.org/abs/2407.19848,,07/30/2024 10:48,randomForestClassifier,"Lu Chung I, Julian Sester","Generating synthetic financial time series data that accurately reflects real-world market dynamics holds tremendous potential for various applications, including portfolio optimization, risk management, and large scale machine learning. We present an approach for training generative models for financial time series using the maximum mean discrepancy (MMD) with a signature kernel. Our method leverages the expressive power of the signature transform to capture the complex dependencies and temporal structures inherent in financial data. We employ a moving average model to model the variance of the noise input, enhancing the model's ability to reproduce stylized facts such as volatility clustering. Through empirical experiments on S&amp;P 500 index data, we demonstrate that our model effectively captures key characteristics of financial time series and outperforms a comparable GAN-based approach. In addition, we explore the application of the synthetic data generated to train a reinforcement learning agent for portfolio management, achieving promising results. Finally, we propose a method to add robustness to the generative model by tweaking the noise input so that the generated sequences can be adjusted to different market environments with minimal data.",q-fin.MF
Introducao a otimizacao de Portfolio,https://arxiv.org/abs/2208.07909,,07/30/2024 10:48,randomForestClassifier,"Orizon P. Ferreira, Guilherme. A. Franca, Max V. Lemes","In this work, we introduce Modern Portfolio Theory using basic concepts from linear algebra, differential calculus, statistics, and optimization. This theory allows us to measure the return and risk of an investment portfolio, serving as a basis for decision-making in the financial market. As an application, we will present four very simple investment strategies that aim to minimize the risk of investing in only two assets, outperforming the CDI (Interbank Deposit Certificate) yield.",math.OC
Risk management in multi-objective portfolio optimization under uncertainty,https://arxiv.org/abs/2407.19936,,07/30/2024 10:48,randomForestClassifier,"Yannick Becker, Pascal Halffmann, Anita Sch\""obel","In portfolio optimization, decision makers face difficulties from uncertainties inherent in real-world scenarios. These uncertainties significantly influence portfolio outcomes in both classical and multi-objective Markowitz models. To address these challenges, our research explores the power of robust multi-objective optimization. Since portfolio managers frequently measure their solutions against benchmarks, we enhance the multi-objective min-regret robustness concept by incorporating these benchmark comparisons.
  This approach bridges the gap between theoretical models and real-world investment scenarios, offering portfolio managers more reliable and adaptable strategies for navigating market uncertainties. Our framework provides a more nuanced and practical approach to portfolio optimization under real-world conditions.","q-fin.PM, math.OC"
Value-at-Risk constrained portfolios in incomplete markets: a dynamic programming approach to Heston's model,https://arxiv.org/abs/2208.14152,,07/30/2024 10:48,randomForestClassifier,"Marcos Escobar-Anel, Yevhen Havrylenko, Rudi Zagst","We solve an expected utility-maximization problem with a Value-at-risk constraint on the terminal portfolio value in an incomplete financial market due to stochastic volatility. To derive the optimal investment strategy, we use the dynamic programming approach. We demonstrate that the value function in the constrained problem can be represented as the expected modified utility function of a vega-neutral financial derivative on the optimal terminal wealth in the unconstrained utility-maximization problem. Via the same financial derivative, the optimal wealth and the optimal investment strategy in the constrained problem are linked to the optimal wealth and the optimal investment strategy in the unconstrained problem. In numerical studies, we substantiate the impact of risk aversion levels and investment horizons on the optimal investment strategy. We observe a 20% relative difference between the constrained and unconstrained allocations for average parameters in a low-risk-aversion short-horizon setting.","q-fin.PM, math.OC"
Relative Arbitrage Opportunities with Interactions among $N$ Investors,https://arxiv.org/abs/2006.15158,,07/30/2024 10:48,randomForestClassifier,"Tomoyuki Ichiba, Nicole Tianjiao Yang","The relative arbitrage portfolio outperforms a benchmark portfolio over a given time-horizon with probability one. With market price of risk processes depending on the market portfolio and investors, this paper analyzes the multi-agent optimization of relative arbitrage opportunities in the coupled system of market and wealth dynamics. We construct a well-posed market dynamical system of McKean-Vlasov type under an empirical measure of investors, where each investor seeks for relative arbitrage with respect to a benchmark dependent on market and all the agents. We show the conditions to guarantee relative arbitrage opportunities among competitive investors through the Fichera drift. Under mild conditions, we derive the optimal strategies for investors and the unique Nash equilibrium that depends on the smallest nonnegative solution of a Cauchy problem.","q-fin.MF, math.PR"
"Security Issuance, Institutional Investors and Quid Pro Quo",https://arxiv.org/abs/2211.16643,,07/30/2024 10:48,randomForestClassifier,"Gaurab Aryal, Zhaohui Chen, Yuchi Yao, Chris Yung","Securities issuance through intermediaries is subject to agency problems and informational frictions. We examine these effects using SPAC data. We identify ``premium'' investors whose participation is linked to lower liquidation risk, higher returns, and lower redemption rates, consistent with both informational rents and agency frictions. In contrast, ``non-premium'' investors engage in non-agency quid pro quo relationships. Specifically, they receive high returns from an intermediary (quid) in exchange for a tacit agreement to participate in weaker future deals (quo). These relationships serve as insurance for issuers and intermediaries, enabling more issuers to access markets.","q-fin.GN, econ.GN, q-fin.EC"
The Democratization of Wealth Management: Hedged Mutual Fund Blockchain Protocol,https://arxiv.org/abs/2405.02302,,07/30/2024 10:48,randomForestClassifier,Ravi Kashyap,"We develop several innovations to bring the best practices of traditional investment funds to the blockchain landscape. Specifically, we illustrate how: 1) fund prices can be updated regularly like mutual funds; 2) performance fees can be charged like hedge funds; 3) mutually hedged blockchain investment funds can operate with investor protection schemes, such as high water marks; and 4) measures to offset trading related slippage costs when redemptions happen. Using our concepts - and blockchain technology - traditional funds can calculate performance fees in a simplified manner and alleviate several operational issues. Blockchain can solve many problems for traditional finance, while tried and tested wealth management techniques can benefit decentralization, speeding its adoption. We provide detailed steps - including mathematical formulations and instructive pointers - to implement these ideas and discuss how our designs overcome several blockchain bottlenecks, making smart contracts smarter. We provide numerical illustrations of several scenarios related to our mechanisms.","cs.CR, q-fin.CP, q-fin.PM, q-fin.RM, q-fin.TR"
Reaching for Duration and Leverage in the Treasury Market,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4873142,2024-06-23 10:55:00,08/05/2024 09:02,randomForestClassifier,"Daniel Barth, R. Jay Kahn, Phillip Monin, Oleg Sokolinskiy","We show substantial variation in mutual funds&#039; use of Treasury futures, both over time and across funds. This variation from mutual funds drives much of the time series variation in aggregate Treasury futures open interest, including over 60% of the recent rise in Treasury futures positions. We provide evidence these Treasury futures positions are largely attributable to mutual funds â€œreaching for durationâ€  in order to track the duration of a benchmark index with high cash Treasury exposure. Specifically, we show mutual funds use futures to fill the gap between their portfolio and the index that results when they tilt their cash positions towardhigher return but lower duration assets, such as mortgage-backed securities and equities, and away from cash Treasuries. Treasury futures positions are more common in mutual funds which indicate a focus on dual objectives of duration management and total return whose style has a higher allocation to Treasuries. Reaching for duration allows funds to track their index better at lower cost, but increases leverage in the Treasury market both through mutual funds long Treasury futures positions and through the leverage of hedge funds who take thecorresponding short positions in Treasury futures.",
Bubbles in Asset Markets and the Heterogeneity of Beliefs,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4790546,2024-04-10 19:18:00,06/20/2024 14:50,randomForestClassifier,"Eizo Akiyama, Ryuichiro Ishikawa, Yukihiko Funaki, Yaron Lahave, Charles Noussair Noussair","We examine the relationship between information about trader expectations and pricing in asset markets. In a laboratory experiment, we elicit long-term beliefs from traders about future prices, and make different subsets of the belief information common knowledge, depending on the treatment. As hypothesized, there is a strong tendency for traders to adjust their beliefs toward the median belief in their market. Surprisingly, we find that making the median price prediction for the entire future time horizon common knowledge eliminates mispricing.",
"Presentation Slides for ""A Financing-Based Misvaluation Factor and the Cross Section of Expected Returns""",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4863609,2024-06-20 20:08:00,06/21/2024 09:39,randomForestClassifier,"David  Hirshleifer, Danling Jiang",,
Speculating on Higher Order Beliefs,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4908492,2024-07-31 16:04:00,08/05/2024 09:05,randomForestClassifier,"Paul Schmidt-Engelbertz, Kaushik Vasudevan","Higher order beliefs – beliefs about others’ beliefs – may be important for trading behaviour and asset prices, but have received little systematic empirical examination. We study more than twenty years of evidence from the Robert Shiller Investor Confidence surveys, which directly elicit details on investors’ higher order beliefs about the U.S. stock market. We find that investors’ higher order beliefs provide substantial motivations for non-fundamental speculation, e.g., to buy into a stock market perceived to be overvalued. To explore the equilibrium implications, we construct a model of level k thinking that matches the evidence, where some speculative investors mistakenly believe that asset price movements are driven by other, less sophisticated investors. The model reveals that speculators’ higher order beliefs amplify stock market overreaction and excess volatility; these phenomena persist in equilibrium due to investors’ limited strategic reasoning.",
Common Noise by Random Measures: Mean-Field Equilibria for Competitive Investment and Hedging,https://arxiv.org/abs/2408.01175,,08/05/2024 09:14,Manual,"Dirk Becherer, Stefanie Hesse","We study mean-field games where common noise dynamics are described by integer-valued random measures, for instance Poisson random measures, in addition to Brownian motions. In such a framework, we describe Nash equilibria for mean-field portfolio games of both optimal investment and hedging under relative performance concerns with respect to exponential (CARA) utility preferences. Agents have independent individual risk aversions, competition weights and initial capital endowments, whereas their liabilities are described by contingent claims which can depend on both common and idiosyncratic risk factors. Liabilities may incorporate, e.g., compound Poisson-like jump risks and can only be hedged partially by trading in a common but incomplete financial market, in which prices of risky assets evolve as It\^{o}-processes. Mean-field equilibria are fully characterized by solutions to suitable McKean-Vlasov forward-backward SDEs with jumps, for whose we prove existence and uniqueness of solutions, without restricting competition weights to be small.",math.OC
Reaching for Duration and Leverage in the Treasury Market,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4816018,2024-05-07 14:36:00,08/05/2024 09:02,randomForestClassifier,"Daniel Barth, R. Jay Kahn, Phillip Monin, Oleg Sokolinskiy","We show substantial variation in mutual funds' use of Treasury futures, both over time and across funds. This variation from mutual funds drives much of the time series variation in aggregate Treasury futures open interest, including over 60% of the recent rise in Treasury futures positions. We provide evidence these Treasury futures positions are largely attributable to mutual funds ""reaching for duration"" in order to track the duration of a benchmark index with high cash Treasury exposure. Specifically, we show mutual funds use futures to fill the gap between their portfolio and the index that results when they tilt their cash positions toward higher return but lower duration assets, such as mortgage-backed securities and equities, and away from cash Treasuries. Treasury futures positions are more common in mutual funds which indicate a focus on dual objectives of duration management and total return whose style has a higher allocation to Treasuries. Reaching for duration allows funds to track their index better at lower cost, but increases leverage in the Treasury market both through mutual funds long Treasury futures positions and through the leverage of hedge funds who take the corresponding short positions in Treasury futures.",
ETFs and the Wash Sale Loophole,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4900564,2024-07-31 10:50:00,08/05/2024 09:08,randomForestClassifier,"Michael Dambra, Andrew Glover, Charles M.C. Lee, Phillip J. Quinn","Tax wash sale rules prohibit investors from recognizing capital losses when they sell and immediately repurchase substantially identical securities within short windows. This study examines whether institutional investors use ETFs to circumvent the wash sale rule. We find incumbent ETFs experience more trading volume upon the introduction of nearly identical ETFs, particularly when recent returns are negative. Tax-sensitive institutions' investment in highly correlated ETFs has proliferated in recent years, exceeding a quarter of AUM. Further, we find that tax-sensitive institutions holding more ETFs are significantly more likely to engage in swapping near-identical ETFs. This swapping behavior has become widespread, with tax-sensitive institutional investors swapping $417 billion of near-identical ETFs since 2001. Overall, we estimate that a one standard deviation increase in ETF swapping results in an incremental $138 billion of aggregate losses harvested for tax-sensitive institutional investors.",
Generation of Random (Generalized) Orthogonal Matrices,https://arxiv.org/abs/2406.18963,,06/28/2024 16:45,Manual,Ali Saraeb,"This paper presents an algorithmic method for generating random orthogonal matrices \(A\) that satisfy the property \(A^t S A = S\), where \(S\) is a fixed real invertible symmetric or skew-symmetric matrix. This method is significant as it generalizes the procedures for generating orthogonal matrices that fix a general fixed symmetric or skew-symmetric bilinear form. These include orthogonal matrices that fall to groups such as the symplectic group, Lorentz group, Poincar\'e group, and more generally the indefinite orthogonal group, to name a few. These classes of matrices play crucial roles in diverse fields such as theoretical physics, where they are used to describe symmetries and conservation laws, as well as in computational geometry, numerical analysis, and number theory, where they are integral to the study of quadratic forms and modular forms. The implementation of our algorithms can be accomplished using standard linear algebra libraries.","math.NA, cs.NA, math.NT, math.PR"
Factor Selection and Structural Breaks,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4796413,2024-04-16 18:31:00,08/05/2024 09:09,randomForestClassifier,"Siddhartha Chib, Simon Smith","We develop a new approach to select factors, allowing the set to change at multiple unknown break dates.  In a six-factor model since 1963, we document a marked shift towards parsimonious models in the last two decades.  Prior to 2005, either five or six factors are selected, but just two are selected thereafter.  This finding offers a simple implication for the factor zoo literature: ignoring breaks detects additional factors that are no longer relevant.  Moreover, all omitted factors are priced by the selected factors in every regime.  Finally, the selected factors outperform popular factor models as an investment strategy.",
Conditional correlation estimation and serial dependence identification,https://arxiv.org/abs/2406.14650,,06/24/2024 10:11,Manual,"Kewin P\k{a}czek, Damian Jelito, Marcin Pitera, Agnieszka Wy{\l}oma\'nska","It has been recently shown in Jaworski, P., Jelito, D. and Pitera, M. (2024), 'A note on the equivalence between the conditional uncorrelation and the independence of random variables', Electronic Journal of Statistics 18(1), that one can characterise the independence of random variables via the family of conditional correlations on quantile-induced sets. This effectively shows that the localized linear measure of dependence is able to detect any form of nonlinear dependence for appropriately chosen conditioning sets. In this paper, we expand this concept, focusing on the statistical properties of conditional correlation estimators and their potential usage in serial dependence identification. In particular, we show how to estimate conditional correlations in generic and serial dependence setups, discuss key properties of the related estimators, define the conditional equivalent of the autocorrelation function, and provide a series of examples which prove that the proposed framework could be efficiently used in many practical econometric applications.",stat.ME
Factor Selection and Structural Breaks,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4857699,2024-06-11 13:36:00,08/05/2024 09:09,Manual,"Siddhartha Chib, Simon Smith","We develop a new approach to select risk factors in an asset pricing model that allows the set to change at multiple unknown break dates. Using the six factors displayed in Table 1 since 1963, we document a marked shift towards parsimonious models in the last two decades.  Prior to 2005, five or six factors are selected, but just two are selected thereafter. This finding offers a simple implication for the factor zoo literature: ignoring breaks detects additional factors that are no longer relevant.  Moreover, all omitted factors are priced by the selected factors in every regime.  Finally, the selected factors outperform popular factor models as an investment strategy.",
Deep reinforcement learning with positional context for intraday trading,https://arxiv.org/abs/2406.08013,,06/13/2024 09:09,randomForestClassifier,"Sven Golu\v{z}a, Tomislav Kova\v{c}evi\'c, Tessa Bauman, Zvonko Kostanj\v{c}ar","Deep reinforcement learning (DRL) is a well-suited approach to financial decision-making, where an agent makes decisions based on its trading strategy developed from market observations. Existing DRL intraday trading strategies mainly use price-based features to construct the state space. They neglect the contextual information related to the position of the strategy, which is an important aspect given the sequential nature of intraday trading. In this study, we propose a novel DRL model for intraday trading that introduces positional features encapsulating the contextual information into its sparse state space. The model is evaluated over an extended period of almost a decade and across various assets including commodities and foreign exchange securities, taking transaction costs into account. The results show a notable performance in terms of profitability and risk-adjusted metrics. The feature importance results show that each feature incorporating contextual information contributes to the overall performance of the model. Additionally, through an exploration of the agent's intraday trading activity, we unveil patterns that substantiate the effectiveness of our proposed model.",q-fin.TR
Hedging in Isolation: Trick or Trap?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4852658,2024-07-03 13:33:00,08/05/2024 09:11,Manual,"Shu Li, Philip H. Dybvig","In special cases, the optimal hedge of nontraded wealth is a projection that can be computed in isolation from the rest of the choice problem. This is generally true if the unhedged nontraded wealth is independent of market returns and completely unknown before the horizon. If there is intermediate information arrival about the unhedged nontraded wealth, even with independence, only CARA and backwards CARA preferences have isolation, because all other utility functions have wealth effects. Outside these cases, computing the hedge in isolation can do more damage than ignoring the nontraded wealth.",
Evaluating Microscopic and Macroscopic Models for Derivative Contracts on Commodity Indices,https://arxiv.org/abs/2408.00784,,08/05/2024 09:14,Manual,"Alberto Manzano, Emanuele Nastasi, Andrea Pallavicini, Carlos V\'azquez","In this article, we analyze two modeling approaches for the pricing of derivative contracts on a commodity index. The first one is a microscopic approach, where the components of the index are modeled individually, and the index price is derived from their combination. The second one is a macroscopic approach, where the index is modeled directly. While the microscopic approach offers greater flexibility, its calibration results to be more challenging, thus leading practitioners to favor the macroscopic approach. However, in the macroscopic model, the lack of explicit futures curve dynamics raises questions about its ability to accurately capture the behavior of the index and its sensitivities. In order to investigate this, we calibrate both models using derivatives of the S\&amp;P GSCI Crude Oil excess-return index and compare their pricing and sensitivities on path-dependent options, such as autocallable contracts. This research provides insights into the suitability of macroscopic models for pricing and hedging purposes in real scenarios.",q-fin.CP
Coarse graining correlation matrices according to macrostructures: Financial markets as a paradigm,https://arxiv.org/abs/2402.05364,,06/27/2024 08:56,randomForestClassifier,"M. Mija\'il Mart\'inez-Ramos, Parisa Majari, Andres R. Cruz-Hern\'andez, Hirdesh K. Pharasi, Manan Vyas","We analyze correlation structures in financial markets by coarse graining the Pearson correlation matrices according to market sectors to obtain Guhr matrices using Guhr's correlation method according to Ref. [P. Rinn {\it et. al.}, Europhysics Letters 110, 68003 (2015)]. We compare the results for the evolution of market states and the corresponding transition matrices with those obtained using Pearson correlation matrices. The behavior of market states is found to be similar for both the coarse grained and Pearson matrices. However, the number of relevant variables is reduced by orders of magnitude.","q-fin.ST, physics.data-an, stat.AP"
"Existence, uniqueness and positivity of solutions to the Guyon-Lekeufack path-dependent volatility model with general kernels",https://arxiv.org/abs/2408.02477,,08/06/2024 10:35,randomForestClassifier,"Herv\'e Andr\`es (CERMICS), Benjamin Jourdain (CERMICS, MATHRISK)","We show the existence and uniqueness of a continuous solution to a path-dependent volatility model introduced by Guyon and Lekeufack (2023) to model the price of an equity index and its spot volatility. The considered model for the trend and activity features can be written as a Stochastic Volterra Equation (SVE) with non-convolutional and non-bounded kernels as well as non-Lipschitz coefficients. We first prove the existence and uniqueness of a solution to the SVE under integrability and regularity assumptions on the two kernels and under a condition on the second kernel weighting the past squared returns which ensures that the activity feature is bounded from below by a positive constant. Then, assuming in addition that the kernel weighting the past returns is of exponential type and that an inequality relating the logarithmic derivatives of the two kernels with respect to their second variables is satisfied, we show the positivity of the volatility process which is obtained as a non-linear function of the SVE's solution. We show numerically that the choice of an exponential kernel for the kernel weighting the past returns has little impact on the quality of model calibration compared to other choices and the inequality involving the logarithmic derivatives is satisfied by the calibrated kernels. These results extend those of Nutz and Valdevenito (2023).",q-fin.CP
A Note on Optimal Liquidation with Linear Price Impact,https://arxiv.org/abs/2402.14100,,08/06/2024 10:35,randomForestClassifier,"Yan Dolinsky, Doron Greenstein","In this note we consider the maximization of the expected terminal wealth for the setup of quadratic transaction costs. First, we provide a very simple probabilistic solution to the problem. Although the problem was largely studied, as far as we know up to date this simple and probabilistic form of the solution has not appeared in the literature.
  Next, we apply the general result for the numerical study of the case where the risky asset is given by a fractional Brownian Motion and the information flow of the investor can be diversified.","q-fin.CP, math.PR"
SABR/LIBOR market models: pricing and calibration for some interest rate derivatives,https://arxiv.org/abs/2408.01470,,08/06/2024 10:35,randomForestClassifier,"A. M. Ferreiro, J. A. Garc\'ia, J. G. L\'opez-Salas, C. V\'azquez","In order to overcome the drawbacks of assuming deterministic volatility coefficients in the standard LIBOR market models to capture volatility smiles and skews in real markets, several extensions of LIBOR models to incorporate stochastic volatilities have been proposed. The efficient calibration to market data of these more complex models becomes a relevant target in practice. The main objective of the present work is to efficiently calibrate some recent SABR/LIBOR market models to real market prices of caplets and swaptions. For the calibration we propose a parallelized version of the simulated annealing algorithm for multi-GPUs. The numerical results clearly illustrate the advantages of using the proposed multi-GPUs tools when applied to real market data and popular SABR/LIBOR models.",q-fin.PR
Neural Term Structure of Additive Process for Option Pricing,https://arxiv.org/abs/2408.01642,,08/06/2024 10:35,randomForestClassifier,"Jimin Lin, Guixin Liu","The additive process generalizes the L\'evy process by relaxing its assumption of time-homogeneous increments and hence covers a larger family of stochastic processes. Recent research in option pricing shows that modeling the underlying log price with an additive process has advantages in easier construction of the risk-neural measure, an explicit option pricing formula and characteristic function, and more flexibility to fit the implied volatility surface. Still, the challenge of calibrating an additive model arises from its time-dependent parameterization, for which one has to prescribe parametric functions for the term structure. For this, we propose the neural term structure model to utilize feedforward neural networks to represent the term structure, which alleviates the difficulty of designing parametric functions and thus attenuates the misspecification risk. Numerical studies with S\&amp;P 500 option data are conducted to evaluate the performance of the neural term structure.","q-fin.CP, q-fin.MF, q-fin.PR, stat.ML"
A nonparametric test for diurnal variation in spot correlation processes,https://arxiv.org/abs/2408.02757,,08/07/2024 09:01,randomForestClassifier,"Kim Christensen, Ulrich Hounyo, Zhi Liu","The association between log-price increments of exchange-traded equities, as measured by their spot correlation estimated from high-frequency data, exhibits a pronounced upward-sloping and almost piecewise linear relationship at the intraday horizon. There is notably lower-on average less positive-correlation in the morning than in the afternoon. We develop a nonparametric testing procedure to detect such deterministic variation in a correlation process. The test statistic has a known distribution under the null hypothesis, whereas it diverges under the alternative. It is robust against stochastic correlation. We run a Monte Carlo simulation to discover the finite sample properties of the test statistic, which are close to the large sample predictions, even for small sample sizes and realistic levels of diurnal variation. In an application, we implement the test on a monthly basis for a high-frequency dataset covering the stock market over an extended period. The test leads to rejection of the null most of the time. This suggests diurnal variation in the correlation process is a nontrivial effect in practice.","econ.EM, math.ST, stat.TH"
Efficient simulation of the SABR model,https://arxiv.org/abs/2408.01898,,08/06/2024 10:35,randomForestClassifier,"Jaehyuk Choi, Lilian Hu, Yue Kuen Kwok","We propose an efficient and reliable simulation scheme for the stochastic-alpha-beta-rho (SABR) model. The two challenges of the SABR simulation lie in sampling (i) the integrated variance conditional on terminal volatility and (ii) the terminal price conditional on terminal volatility and integrated variance. For the first sampling procedure, we analytically derive the first four moments of the conditional average variance, and sample it from the moment-matched shifted lognormal approximation. For the second sampling procedure, we approximate the conditional terminal price as a constant-elasticity-of-variance (CEV) distribution. Our CEV approximation preserves the martingale condition and precludes arbitrage, which is a key advantage over Islah's approximation used in most SABR simulation schemes in the literature. Then, we adopt the exact sampling method of the CEV distribution based on the shifted-Poisson-mixture Gamma random variable. Our enhanced procedures avoid the tedious Laplace inversion algorithm for sampling integrated variance and non-efficient inverse transform sampling of the forward price in some of the earlier simulation schemes. Numerical results demonstrate our simulation scheme to be highly efficient, accurate, and reliable.","q-fin.CP, q-fin.MF"
Existence and uniqueness of quadratic and linear mean-variance equilibria in general semimartingale markets,https://arxiv.org/abs/2408.03134,,08/07/2024 09:01,randomForestClassifier,"Christoph Czichowsky, Martin Herdegen, David Martins","We revisit the classical topic of quadratic and linear mean-variance equilibria with both financial and real assets. The novelty of our results is that they are the first allowing for equilibrium prices driven by general semimartingales and hold in discrete as well as continuous time. For agents with quadratic utility functions, we provide necessary and sufficient conditions for the existence and uniqueness of equilibria. We complement our analysis by providing explicit examples showing non-uniqueness or non-existence of equilibria. We then study the more difficult case of linear mean-variance preferences. We first show that under mild assumptions, a linear mean-variance equilibrium corresponds to a quadratic equilibrium (for different preference parameters). We then use this link to study a fixed-point problem that establishes existence (and uniqueness in a suitable class) of linear mean-variance equilibria. Our results rely on fine properties of dynamic mean-variance hedging in general semimartingale markets.","q-fin.MF, econ.GN, q-fin.EC"
Investment strategies based on forecasts are (almost) useless,https://arxiv.org/abs/2408.01772,,08/06/2024 10:35,randomForestClassifier,Michael Weba,"Several studies on portfolio construction reveal that sensible strategies essentially yield the same results as their nonsensical inverted counterparts; moreover, random portfolios managed by Malkiel's dart-throwing monkey would outperform the cap-weighted benchmark index. Forecasting the future development of stock returns is an important aspect of portfolio assessment. Similar to the ostensible arbitrariness of portfolio selection methods, it is shown that there is no substantial difference between the performances of ``best'' and ``trivial'' forecasts - even under euphemistic model assumptions on the underlying price dynamics. A certain significance of a predictor is found only in the following special case: the best linear unbiased forecast is used, the planning horizon is small, and a critical relation is not satisfied.",q-fin.PM
How is Credit Risk Priced in the German Market for Structured Products?,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4911534,2024-08-06 10:05:00,08/06/2024 10:27,randomForestClassifier,"Falk Jensen, Rainer Baule",,
Competitive optimal portfolio selection in a non-Markovian financial market: A backward stochastic differential equation study,https://arxiv.org/abs/2408.02286,,08/06/2024 10:35,randomForestClassifier,"Guangchen Wang, Zuo Quan Xu, Panpan Zhang","This paper studies a competitive optimal portfolio selection problem in a model where the interest rate, the appreciation rate and volatility rate of the risky asset are all stochastic processes, thus forming a non-Markovian financial market. In our model, all investors (or agents) aim to obtain an above-average wealth at the end of the common investment horizon. This competitive optimal portfolio problem is indeed a non-zero stochastic differential game problem. The quadratic BSDE theory is applied to tackle the problem and Nash equilibria in suitable spaces are found. We discuss both the CARA and CRRA utility cases. For the CARA utility case, there are three possible scenarios depending on market and competition parameters: a unique Nash equilibrium, no Nash equilibrium, and infinite Nash equilibria. The Nash equilibrium is given by the solutions of a quadratic BSDE and a linear BSDE with unbounded coefficient when it is unique. Different from the wealth-independent Nash equilibria in the existing literature, the equilibrium in our paper is of feedback form of wealth. For the CRRA utility case, the issue is a bit more complicated than the CARA utility case. We prove the solvability of a new kind of quadratic BSDEs with unbounded coefficients. A decoupling technology is used to relate the Nash equilibrium to a series of 1-dimensional quadratic BSDEs. With the help of this decoupling technology, we can even give the limiting strategies for both cases when the number of agent tends to be infinite.",math.OC
Revisiting Elastic String Models of Forward Interest Rates,https://arxiv.org/abs/2403.18126,,08/06/2024 10:35,randomForestClassifier,"Victor Le Coz, Jean-Philippe Bouchaud","Twenty five years ago, several authors proposed to describe the forward interest rate curve (FRC) as an elastic string along which idiosyncratic shocks propagate, accounting for the peculiar structure of the return correlation across different maturities. In this paper, we revisit the specific ""stiff'' elastic string field theory of Baaquie and Bouchaud (2004) in a way that makes its micro-foundation more transparent. Our model can be interpreted as capturing the effect of market forces that set the rates of nearby tenors in a self-referential fashion. The model is parsimonious and accurately reproduces the whole correlation structure of the FRC over the time period 1994-2023, with an error around 1% and with only one adjustable parameter, the value of which being very stable across the last three decades. The dependence of correlation on time resolution (also called the Epps effect) is also faithfully reproduced within the model and leads to a cross-tenor information propagation time on the order of 30 minutes. Finally, we confirm that the perceived time in interest rate markets is a strongly sub-linear function of real time, as surmised by Baaquie and Bouchaud (2004). In fact, our results are fully compatible with hyperbolic discounting, in line with the recent behavioral Finance literature (Farmer and Geanakoplos, 2009).",q-fin.ST
Forecasting High Frequency Order Flow Imbalance,https://arxiv.org/abs/2408.03594,,08/08/2024 16:35,randomForestClassifier,"Aditya Nittur Anantha, Shashi Jain","Market information events are generated intermittently and disseminated at high speeds in real-time. Market participants consume this high-frequency data to build limit order books, representing the current bids and offers for a given asset. The arrival processes, or the order flow of bid and offer events, are asymmetric and possibly dependent on each other. The quantum and direction of this asymmetry are often associated with the direction of the traded price movement. The Order Flow Imbalance (OFI) is an indicator commonly used to estimate this asymmetry. This paper uses Hawkes processes to estimate the OFI while accounting for the lagged dependence in the order flow between bids and offers. Secondly, we develop a method to forecast the near-term distribution of the OFI, which can then be used to compare models for forecasting OFI. Thirdly, we propose a method to compare the forecasts of OFI for an arbitrarily large number of models. We apply the approach developed to tick data from the National Stock Exchange and observe that the Hawkes process modeled with a Sum of Exponential's kernel gives the best forecast among all competing models.",q-fin.TR
Social Interaction Intensity and Investor Behavior,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4904530,2024-08-08 13:48:00,08/08/2024 16:23,randomForestClassifier,"Michael Gelman, David  Hirshleifer, Yaron Levi, Liron Reiter Gavish","We document a causal effect of social interactions on investor behavior using the number of local soccer games as a measure of social interaction intensity. Social transmission is identifiable in buy but not sell trades. The effect of Social Interaction Intensity (SII) on the sensitivity of buying to past buys is greater for riskier and high-return stocks. Social interactions cause an extremity shift wherein existing shareholders increase their positions, especially within demographically homogeneous communities. There is suggestive evidence that investor mood may modulate the effectiveness of transmission. Higher social interaction intensity increases the sensitivity of investors' trading volume, and portfolio riskiness to past trades. SII also increases the sensitivity of stock trading volume and retail ownership percentage to past buys.",
Robust changepoint detection in the variability of multivariate functional data,https://arxiv.org/abs/2112.01611,,08/08/2024 16:35,randomForestClassifier,"Kelly Ramsay, Shoja'eddin Chenouri","We consider the problem of robustly detecting changepoints in the variability of a sequence of independent multivariate functions. We develop a novel changepoint procedure, called the functional Kruskal--Wallis for covariance (FKWC) changepoint procedure, based on rank statistics and multivariate functional data depth. The FKWC changepoint procedure allows the user to test for at most one changepoint (AMOC) or an epidemic period, or to estimate the number and locations of an unknown amount of changepoints in the data. We show that when the ``signal-to-noise'' ratio is bounded below, the changepoint estimates produced by the FKWC procedure attain the minimax localization rate for detecting general changes in distribution in the univariate setting (Theorem 1). We also provide the behavior of the proposed test statistics for the AMOC and epidemic setting under the null hypothesis (Theorem 2) and, as a simple consequence of our main result, these tests are consistent (Corollary 1). In simulation, we show that our method is particularly robust when compared to similar changepoint methods. We present an application of the FKWC procedure to intraday asset returns and f-MRI scans. As a by-product of Theorem 1, we provide a concentration result for integrated functional depth functions (Lemma 2), which may be of general interest.",stat.ME
Endogenous distress contagion in a dynamic interbank model: how possible future losses may spell doom today,https://arxiv.org/abs/2211.15431,,08/12/2024 09:10,randomForestClassifier,"Zachary Feinstein, Andreas Sojmark","We introduce a dynamic and stochastic interbank model with an endogenous notion of distress contagion, arising from rational worries about future defaults and ensuing losses. This entails a mark-to-market valuation adjustment for interbank claims, leading to a forward-backward approach to the equilibrium dynamics whereby future default probabilities are needed to determine today's balance sheets. Distinct from earlier models, the resulting distress contagion acts, endogenously, as a stochastic volatility term that exhibits clustering and down-market spikes. Furthermore, by incorporating multiple maturities, we provide a novel framework for constructing systemic interbank term structures, reflecting the intertemporal risk of contagion. We present the analysis in two parts: first, the simpler single maturity setting that extends the classical interbank network literature and, then, the multiple maturity setting for which we can examine how systemic risk materialises in the shape of the resulting term structures.","q-fin.MF, math.PR, q-fin.GN, q-fin.RM"
Monotonic mean-deviation risk measures,https://arxiv.org/abs/2312.01034,,08/12/2024 09:10,randomForestClassifier,"Xia Han, Ruodu Wang, Qinyu Wu","Mean-deviation models, along with the existing theory of coherent risk measures, are well studied in the literature. In this paper, we characterize monotonic mean-deviation (risk) measures from a general mean-deviation model by applying a risk-weighting function to the deviation part. The form is a combination of the deviation-related functional and the expectation, and such measures belong to the class of consistent risk measures. The monotonic mean-deviation measures admit an axiomatic foundation via preference relations. By further assuming the convexity and linearity of the risk-weighting function, the characterizations for convex and coherent risk measures are obtained, giving rise to many new explicit examples of convex and nonconvex consistent risk measures. Further, we specialize in the convex case of the monotonic mean-deviation measure and obtain its dual representation. The worst-case values of the monotonic mean-deviation measures are analyzed under two popular settings of model uncertainty. Further, we establish asymptotic consistency and normality of the natural estimators of the monotonic mean-deviation measures.Finally, the monotonic mean-deviation measures are applied to a problem of portfolio selection using financial data.","q-fin.RM, q-fin.MF"
Joint calibration to SPX and VIX Derivative Markets with Composite Change of Time Models,https://arxiv.org/abs/2404.16295,,08/12/2024 09:10,randomForestClassifier,"Liexin Cheng, Xue Cheng, Xianhua Peng","The Chicago Board Options Exchange Volatility Index (VIX) is calculated from SPX options and derivatives of VIX are also traded in market, which leads to the so-called ""consistent modeling"" problem. This paper proposes a time-changed L\'evy model for log price with a composite change of time structure to capture both features of the implied SPX volatility and the implied volatility of volatility. Consistent modeling is achieved naturally via flexible choices of jumps and leverage effects, as well as the composition of time changes. Many celebrated models are covered as special cases. From this model, we derive an explicit form of the characteristic function for the asset price (SPX) and the pricing formula for European options as well as VIX options. The empirical results indicate great competence of the proposed model in the problem of joint calibration of the SPX/VIX Markets.","q-fin.MF, q-fin.PR"
Recurrent Stochastic Fluctuations with Financial Speculation,https://arxiv.org/abs/2408.05047,,08/12/2024 09:10,randomForestClassifier,Tomohiro Hirano,"Throughout history, many countries have repeatedly experienced large swings in asset prices, which are usually accompanied by large fluctuations in macroeconomic activity. One of the characteristics of the period before major economic fluctuations is the emergence of new financial products; the situation prior to the 2008 financial crisis is a prominent example of this. During that period, a variety of structured bonds, including securitized products, appeared. Because of the high returns on such financial products, many economic agents were involved in them for speculative purposes, even if they were riskier, producing macro-scale effects.
  With this motivation, we present a simple macroeconomic model with financial speculation. Our model illustrates two points. First, stochastic fluctuations in asset prices and macroeconomic activity are driven by the repeated appearance and disappearance of risky financial assets, rather than expansions and contractions in credit availability. Second, in an economy with sufficient borrowing and lending, the appearance of risky financial assets leads to decreased productive capital, while in an economy with severely limited borrowing and lending, it leads to increased productive capital.",econ.TH
Lower bounds of uncertainty and upper limits on the accuracy of forecasts of macroeconomic variables,https://arxiv.org/abs/2408.04644,,08/12/2024 09:10,randomForestClassifier,Victor Olkhov,"We consider the randomness of values and volumes of market deals as a major factor that describes lower bounds of uncertainty and upper limits on the accuracy of the forecasts of macroeconomic variables, prices, and returns. We introduce random macroeconomic variables, whose average values coincide with usual macroeconomic variables, and describe their uncertainty by coefficients of variation that depend on the volatilities, correlations, and coefficients of variation of random values or volumes of trades. The same approach describes bounds of uncertainty and limits on the accuracy of forecasts for growth rates, inflation, interest rates, etc. Limits on the accuracy of forecasts of macroeconomic variables depend on the certainty of predictions of their probabilities. The number of predicted statistical moments determines the veracity of macroeconomic probability. To quantify macroeconomic 2nd statistical moments, one needs additional econometric methodologies, data, and calculations of variables determined as sums of squares of values or volumes of market trades. Forecasting of macroeconomic 2nd statistical moments requires 2nd order economic theories. All of that is absent and for many years to come, the accuracy of forecasts of the probabilities of random macroeconomic variables, prices, and returns will be limited by the Gaussian approximations, which are determined by the first two statistical moments.","econ.GN, q-fin.EC, q-fin.GN, q-fin.ST"
Quantities and Covered-Interest Parity,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4920349,2024-08-09 11:59:00,08/12/2024 08:58,randomForestClassifier,"Tobias J. Moskowitz, Chase P. Ross, Kaushik Vasudevan, Sharon Y. Ross","Studies of intermediated arbitrage argue that bank balance sheets are an important consideration, yet little evidence exists on banks’ positioning in this context. Using confidential supervisory data (covering $25 trillion in daily notional exposures) we examine banks’ positions in connection with covered-interest parity (CIP) deviations. Exploiting cross-sectional variation in CIP deviations that have largely challenged existing theories, we document three novel forces that drive bases: 1) foreign safe asset scarcity, 2) market power and segmentation of banks specializing in different markets, and 3) concentration of demand. Our findings shed empirical light on the interplay of frictions influencing banks’ provision of dollar funding.",
Hedge Fund Portfolio Construction Using PolyModel Theory and iTransformer,https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4908476,2024-08-12 20:06:00,08/13/2024 09:35,randomForestClassifier,"Zeyu Cao, Siqiao Zhao, Raphael Douady, Zhikang Dong",,
A GCN-LSTM Approach for ES-mini and VX Futures Forecasting,https://arxiv.org/abs/2408.05659,,08/13/2024 09:39,randomForestClassifier,"Nikolas Michael, Mihai Cucuringu, Sam Howison","We propose a novel data-driven network framework for forecasting problems related to E-mini S\&amp;P 500 and CBOE Volatility Index futures, in which products with different expirations act as distinct nodes. We provide visual demonstrations of the correlation structures of these products in terms of their returns, realized volatility, and trading volume. The resulting networks offer insights into the contemporaneous movements across the different products, illustrating how inherently connected the movements of the future products belonging to these two classes are. These networks are further utilized by a multi-channel Graph Convolutional Network to enhance the predictive power of a Long Short-Term Memory network, allowing for the propagation of forecasts of highly correlated quantities, combining the temporal with the spatial aspect of the term structure.",q-fin.ST
The fundamental theorem of asset pricing with and without transaction costs,https://arxiv.org/abs/2307.00571,,08/13/2024 09:39,randomForestClassifier,"Christoph K\""uhn","We prove a version of the fundamental theorem of asset pricing (FTAP) in continuous time that is based on the strict no-arbitrage condition and that is applicable to both frictionless markets and markets with proportional transaction costs. We consider a market with a single risky asset whose ask price process is higher than or equal to its bid price process. Neither the concatenation property of the set of wealth processes, that is used in the proof of the frictionless FTAP, nor some boundedness property of the trading volume of admissible strategies usually argued with in models with a nonvanishing bid-ask spread need to be satisfied in our model.","q-fin.MF, math.PR"
Risk-Aware Security-Constrained Unit Commitment: Taming the Curse of Real-Time Volatility and Consumer Exposure,https://arxiv.org/abs/2311.17254,,08/13/2024 09:39,randomForestClassifier,"Daniel Bienstock, Yury Dvorkin, Cheng Guo, Robert Mieth, Jiayi Wang","We propose an enhancement to wholesale electricity markets whereby the exposure of consumers to increasingly large and volatile consumer payments arising as a byproduct of volatile real-time net loads -- i.e., loads minus renewable outputs -- and prices, both compared to day-ahead cleared values. We incorporate a robust estimate of such excess payments into the day-ahead computation and specifically seek to account for volatility in real-time net loads and renewable generation. Our model features a data-driven uncertainty set based on principal component analysis, which accommodates both load and wind production volatility and captures locational correlation of uncertain data. To solve the model more efficiently, we develop a decomposition algorithm that can handle nonconvex subproblems. Our extensive experiments on a realistic NYISO data set show that the risk-aware model protects the consumers from potential high costs caused by adverse circumstances.",math.OC
An unbounded intensity model for point processes,https://arxiv.org/abs/2408.06519,,08/14/2024 09:10,randomForestClassifier,"Kim Christensen, Alexei Kolokolov","We develop a model for point processes on the real line, where the intensity can be locally unbounded without inducing an explosion. In contrast to an orderly point process, for which the probability of observing more than one event over a short time interval is negligible, the bursting intensity causes an extreme clustering of events around the singularity. We propose a nonparametric approach to detect such bursts in the intensity. It relies on a heavy traffic condition, which admits inference for point processes over a finite time interval. With Monte Carlo evidence, we show that our testing procedure exhibits size control under the null, whereas it has high rejection rates under the alternative. We implement our approach on high-frequency data for the EUR/USD spot exchange rate, where the test statistic captures abnormal surges in trading activity. We detect a nontrivial amount of intensity bursts in these data and describe their basic properties. Trading activity during an intensity burst is positively related to volatility, illiquidity, and the probability of observing a drift burst. The latter effect is reinforced if the order flow is imbalanced or the price elasticity of the limit order book is large.","econ.EM, math.ST, stat.TH"
The McCormick martingale optimal transport,https://arxiv.org/abs/2401.15552,,08/14/2024 09:10,randomForestClassifier,"Erhan Bayraktar, Bingyan Han, Dominykas Norgilas","Martingale optimal transport (MOT) often yields broad price bounds for options, constraining their practical applicability. In this study, we extend MOT by incorporating causality constraints among assets, inspired by the nonanticipativity condition of stochastic processes. However, this introduces a computationally challenging bilinear program. To tackle this issue, we propose McCormick relaxations to ease the bicausal formulation and refer to it as McCormick MOT. The primal attainment and strong duality of McCormick MOT are established under standard assumptions. Empirically, using the lower and upper bounds derived from marginal constraints, the McCormick relaxations reduce the price gap by an average of 1% for stocks with liquid option markets and 4% for those with moderately liquid markets. When tighter bounds on probability masses are applied, the average reduction increases to 12.66%.",q-fin.MF
The Efficient Tail Hypothesis: An Extreme Value Perspective on Market Efficiency,https://arxiv.org/abs/2408.06661,,08/14/2024 09:10,randomForestClassifier,"Junshu Jiang, Jordan Richards, Rapha\""el Huser, David Bolin","In econometrics, the Efficient Market Hypothesis posits that asset prices reflect all available information in the market. Several empirical investigations show that market efficiency drops when it undergoes extreme events. Many models for multivariate extremes focus on positive dependence, making them unsuitable for studying extremal dependence in financial markets where data often exhibit both positive and negative extremal dependence. To this end, we construct regular variation models on the entirety of $\mathbb{R}^d$ and develop a bivariate measure for asymmetry in the strength of extremal dependence between adjacent orthants. Our directional tail dependence (DTD) measure allows us to define the Efficient Tail Hypothesis (ETH) -- an analogue of the Efficient Market Hypothesis -- for the extremal behaviour of the market. Asymptotic results for estimators of DTD are described, and we discuss testing of the ETH via permutation-based methods and present novel tools for visualization. Empirical study of China's futures market leads to a rejection of the ETH and we identify potential profitable investment opportunities. To promote the research of microstructure in China's derivatives market, we open-source our high-frequency data, which are being collected continuously from multiple derivative exchanges.",q-fin.ST
Endogenous Crashes as Phase Transitions,https://arxiv.org/abs/2408.06433,,08/14/2024 09:10,randomForestClassifier,"Revant Nayar, Minhajul Islam","This paper explores the mechanisms behind extreme financial events, specifically market crashes, by employing the theoretical framework of phase transitions. We focus on endogenous crashes, driven by internal market dynamics, and model these events as first-order phase transitions critical, stochastic, and dynamic. Through a comparative analysis of early warning signals associated with each type of transition, we demonstrate that dynamic phase transitions (DPT) offer a more accurate representation of market crashes than critical (CPT) or stochastic phase transitions (SPT). Unlike existing models, such as the Log-Periodic Power Law (LPPL) model, which often suffers from overfitting and false positives, our approach grounded in DPT provides a more robust prediction framework. Empirical findings, based on an analysis of S&amp;P 500 stocks from 2019 to 2024, reveal significant trends in volatility and anomalous dimensions before crashes, supporting the superiority of the DPT model. This work contributes to a deeper understanding of the predictive signals preceding market crashes and offers a novel perspective on their underlying dynamics.",q-fin.MF
SSAAM: Sentiment Signal-based Asset Allocation Method with Causality Information,https://arxiv.org/abs/2408.06585,,08/14/2024 09:10,randomForestClassifier,"Rei Taguchi, Hiroki Sakaji, Kiyoshi Izumi","This study demonstrates whether financial text is useful for tactical asset allocation using stocks by using natural language processing to create polarity indexes in financial news. In this study, we performed clustering of the created polarity indexes using the change-point detection algorithm. In addition, we constructed a stock portfolio and rebalanced it at each change point utilizing an optimization algorithm. Consequently, the asset allocation method proposed in this study outperforms the comparative approach. This result suggests that the polarity index helps construct the equity asset allocation method.",cs.CE
Predicting the distributions of stock returns around the globe in the era of big data and learning,https://arxiv.org/abs/2408.07497,,08/15/2024 09:29,randomForestClassifier,"Jozef Barunik, Martin Hronec, Ondrej Tobek","This paper presents a method for accurately predicting the full distribution of stock returns, given a comprehensive set of 194 stock characteristics and market variables. Such distributions, learned from rich data using a machine learning algorithm, are not constrained by restrictive model assumptions and allow the exploration of non-Gaussian, heavy-tailed data and their non-linear interactions. The method uses a two-stage quantile neural network combined with spline interpolation. The results show that the proposed approach outperforms alternative models in terms of out-of-sample losses. Furthermore, we show that the moments derived from such distributions can be useful as alternative empirical estimates in many cases, including mean estimation and forecasting. Finally, we examine the relationship between cross-sectional returns and several distributional characteristics. The results are robust to a wide range of US and international data.","q-fin.GN, q-fin.PM"
Portfolio and reinsurance optimization under unknown market price of risk,https://arxiv.org/abs/2408.07432,,08/15/2024 09:29,randomForestClassifier,"Claudia Ceci, Katia Colaneri","We investigate the optimal investment-reinsurance problem for insurance company with partial information on the market price of the risk. Through the use of filtering techniques we convert the original optimization problem involving different filtrations, into an equivalent stochastic control problem under the observation filtration only, the so-called separated problem. The Markovian structure of the separated problem allows us to apply a classical approach to stochastic optimization based on the Hamilton-Jacobi-Bellman equation, and to provide explicit formulas for the value function and the optimal investment-reinsurance strategy. We finally discuss some comparisons between the optimal strategies pursued by a partially informed insurer and that followed by a fully informed insurer, and we evaluate the value of information using the idea of indifference pricing. These results are also supported by numerical experiments.",q-fin.PM
Stylized facts in Web3,https://arxiv.org/abs/2408.07653,,08/15/2024 09:29,randomForestClassifier,"A. Christian Silva, Shen-Ning Tung, Wwi-Ru Chen","This paper presents a comprehensive statistical analysis of the Web3 ecosystem, comparing various Web3 tokens with traditional financial assets across multiple time scales. We examine probability distributions, tail behaviors, and other key stylized facts of the returns for a diverse range of tokens, including decentralized exchanges, liquidity pools, and centralized exchanges. Despite functional differences, most tokens exhibit well-established empirical facts, including unconditional probability density of returns with heavy tails gradually becoming Gaussian and volatility clustering. Furthermore, we compare assets traded on centralized (CEX) and decentralized (DEX) exchanges, finding that DEXs exhibit similar stylized facts despite different trading mechanisms and often divergent long-term performance. We propose that this similarity is attributable to arbitrageurs striving to maintain similar centralized and decentralized prices. Our study contributes to a better understanding of the dynamics of Web3 tokens and the relationship between CEX and DEX markets, with important implications for risk management, pricing models, and portfolio construction in the rapidly evolving DeFi landscape. These results add to the growing body of literature on cryptocurrency markets and provide insights that can guide the development of more accurate models for DeFi markets.",q-fin.ST
